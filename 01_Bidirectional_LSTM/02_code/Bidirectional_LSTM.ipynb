{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                       Adj Close       Close        High         Low  \\\n",
      "Date                                                                        \n",
      "2022-01-03 00:00:00+00:00  179.273605  182.009995  182.880005  177.710007   \n",
      "2022-01-04 00:00:00+00:00  176.998337  179.699997  182.940002  179.119995   \n",
      "2022-01-05 00:00:00+00:00  172.290222  174.919998  180.169998  174.639999   \n",
      "2022-01-06 00:00:00+00:00  169.414093  172.000000  175.300003  171.639999   \n",
      "2022-01-07 00:00:00+00:00  169.581558  172.169998  174.139999  171.029999   \n",
      "\n",
      "Price                            Open     Volume  \n",
      "Date                                              \n",
      "2022-01-03 00:00:00+00:00  177.830002  104487900  \n",
      "2022-01-04 00:00:00+00:00  182.630005   99310400  \n",
      "2022-01-05 00:00:00+00:00  179.610001   94537600  \n",
      "2022-01-06 00:00:00+00:00  172.699997   96904000  \n",
      "2022-01-07 00:00:00+00:00  172.889999   86709100  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2022-01-03\"\n",
    "end_date   = \"2024-11-01\"\n",
    "\n",
    "data = yf.download(\"AAPL\", start=start_date, end=end_date)\n",
    "data.columns = data.columns.get_level_values(0) # from multi index to single index\n",
    "print(data.head())\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['days_range'] = data['High'] - data['Low']   # calculating the range of the day\n",
    "# data['yesterdays_close'] = data['Adj Close'].shift(1)\n",
    "# data['jump_from_yesterday'] = data['Open']- data['yesterdays_close']\n",
    "# data['days_movement'] = data['Adj Close']-data['Open']\n",
    "# data = data.drop(columns=['yesterdays_close','Close','High','Low','Open'])\n",
    "\n",
    "# data_v1 = data.copy()\n",
    "# del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_copy.copy()\n",
    "\n",
    "data['target'] = data['Adj Close'].shift(-1)\n",
    "data = data[data['target'].notnull()]\n",
    "data = data.drop(columns=['Close','High','Low','Open'])\n",
    "data = data.reset_index()\n",
    "data['Date'] = data['Date'].dt.strftime('%Y-%m-%d')\n",
    "data['Date'] = pd.to_datetime(data['Date']).dt.date\n",
    "data.set_index('Date', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>179.273605</td>\n",
       "      <td>104487900</td>\n",
       "      <td>176.998337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>176.998337</td>\n",
       "      <td>99310400</td>\n",
       "      <td>172.290222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>172.290222</td>\n",
       "      <td>94537600</td>\n",
       "      <td>169.414093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>169.414093</td>\n",
       "      <td>96904000</td>\n",
       "      <td>169.581558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>169.581558</td>\n",
       "      <td>86709100</td>\n",
       "      <td>169.601242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        Adj Close     Volume      target\n",
       "Date                                         \n",
       "2022-01-03  179.273605  104487900  176.998337\n",
       "2022-01-04  176.998337   99310400  172.290222\n",
       "2022-01-05  172.290222   94537600  169.414093\n",
       "2022-01-06  169.414093   96904000  169.581558\n",
       "2022-01-07  169.581558   86709100  169.601242"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume start_date and end_date are defined, and data is your DataFrame\n",
    "a = pd.date_range(start=start_date, end=end_date, freq=\"D\")  # continuous dates\n",
    "b = data.index  # our time series\n",
    "diff_dates = a.difference(b)  # finds what in 'a' is not in 'b'\n",
    "\n",
    "# Ensure diff_dates remains as Timestamps for compatibility with DataFrame index\n",
    "# (no need to convert to string and back to datetime)\n",
    "diff_dates = pd.to_datetime(diff_dates).date\n",
    "\n",
    "# Ensure `td` is defined correctly\n",
    "td = pd.Timedelta(days=1)  # Adjust according to your needs\n",
    "\n",
    "for date in diff_dates:\n",
    "    prev_date = date - td  # Previous date\n",
    "    # Check if the previous date exists in the index\n",
    "    if prev_date in data.index:  # prev_date is still a Timestamp\n",
    "        prev_val = data.loc[prev_date]  # Access using loc\n",
    "        data.loc[date] = prev_val  # Impute previous value\n",
    "    else:\n",
    "        print(f\"Previous date {prev_date} not found in index.\")  # Debug message or handling\n",
    "\n",
    "data.sort_index(inplace=True)  # Sort the index\n",
    "data.freq = \"D\"  # Set the time index frequency as daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split date and convert to date-only format to match the index\n",
    "val_split_date = pd.to_datetime('2023-12-31').date()\n",
    "test_split_date = pd.to_datetime('2024-06-30').date()\n",
    "\n",
    "# Split the data\n",
    "train = data[:val_split_date]  # Data up to and including 2023-12-31\n",
    "val = data[val_split_date:test_split_date]   # Data from 2023-12-31 onward\n",
    "test = data[test_split_date:]   # Data from 2023-12-31 onward\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler_train = MinMaxScaler()\n",
    "values = scaler_train.fit_transform(train[['Volume', 'Adj Close']])\n",
    "\n",
    "\n",
    "# Define the window size\n",
    "WINDOW = 30  # Window size of 14 days\n",
    "\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(values) # Create a TensorFlow Dataset from the array\n",
    "train_data = train_data.window(WINDOW + 1, shift=1, drop_remainder=True) # Create windowed dataset with the specified window size\n",
    "train_data = train_data.flat_map(lambda x: x.batch(WINDOW + 1)) # Flatten the windowed dataset by batching\n",
    "\n",
    "# Create features and target tuple\n",
    "train_data = train_data.map(lambda x: (x[:-1], x[-1, 1]))  # x[:-1] for features, x[-1, 1] for target 'Adj Close' # Here, we use all columns for features, but only the 'Adj Close' (index 1) as the target\n",
    "train_data = train_data.batch(32).prefetch(1) # Create batches of windows\n",
    "\n",
    "\n",
    "\n",
    "scaler_val = MinMaxScaler()\n",
    "val_values = scaler_val.fit_transform(val[['Volume', 'Adj Close']])\n",
    "\n",
    "# Convert to TensorFlow Datasets similarly as before\n",
    "#val_values = val[['Volume', 'Adj Close']].values\n",
    "val_data = tf.data.Dataset.from_tensor_slices(val_values)\n",
    "val_data = val_data.window(WINDOW + 1, shift=1, drop_remainder=True).flat_map(lambda x: x.batch(WINDOW + 1))\n",
    "val_data = val_data.map(lambda x: (x[:-1], x[-1, 1])).batch(32).prefetch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Conda_3_12_7/lib/python3.12/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_20                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">134,144</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_21                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_20                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m134,144\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_21                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m394,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">594,433</span> (2.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m594,433\u001b[0m (2.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">594,433</span> (2.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m594,433\u001b[0m (2.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Custom callback\n",
    "class CustomCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('mae') < 0.1:\n",
    "            print(\"MAE under 0.1... Stopping training\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "my_callback = CustomCallback()\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return lr * 0.99\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# LSTM model definition\n",
    "lstm_model = Sequential([\n",
    "    Bidirectional(LSTM(128, return_sequences=True), input_shape=[WINDOW, 2]),\n",
    "    Dropout(0.2),\n",
    "    #BatchNormalization(),\n",
    "    Bidirectional(LSTM(128)),\n",
    "    Dropout(0.2),\n",
    "    #BatchNormalization(),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.2),  # Experiment with different dropout rates\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "lstm_model.compile(\n",
    "    loss=Huber(),\n",
    "    optimizer=Adam(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Model summary\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "     22/Unknown \u001b[1m2s\u001b[0m 34ms/step - loss: 1.6200 - mae: 0.4798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Conda_3_12_7/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - loss: 1.5935 - mae: 0.4739 - val_loss: 0.3779 - val_mae: 0.3386 - learning_rate: 0.0100\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.2323 - mae: 0.1803 - val_loss: 0.0834 - val_mae: 0.2346 - learning_rate: 0.0100\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0496 - mae: 0.1476 - val_loss: 0.0798 - val_mae: 0.3357 - learning_rate: 0.0099\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0262 - mae: 0.1527 - val_loss: 0.1535 - val_mae: 0.4820 - learning_rate: 0.0098\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0383 - mae: 0.1993 - val_loss: 0.3466 - val_mae: 0.7707 - learning_rate: 0.0097\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0688 - mae: 0.2545 - val_loss: 0.0742 - val_mae: 0.3097 - learning_rate: 0.0096\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0335 - mae: 0.1499 - val_loss: 0.4313 - val_mae: 0.8748 - learning_rate: 0.0095\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0815 - mae: 0.2523 - val_loss: 0.2819 - val_mae: 0.6400 - learning_rate: 0.0094\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0782 - mae: 0.2432 - val_loss: 0.1554 - val_mae: 0.4677 - learning_rate: 0.0093\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0445 - mae: 0.1926 - val_loss: 0.1905 - val_mae: 0.5313 - learning_rate: 0.0092\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0680 - mae: 0.2777 - val_loss: 0.0661 - val_mae: 0.2628 - learning_rate: 0.0091\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0463 - mae: 0.1924 - val_loss: 0.0489 - val_mae: 0.2474 - learning_rate: 0.0090\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0281 - mae: 0.1753 - val_loss: 0.0472 - val_mae: 0.2583 - learning_rate: 0.0090\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0263 - mae: 0.1793 - val_loss: 0.0455 - val_mae: 0.2544 - learning_rate: 0.0089\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0244 - mae: 0.1739 - val_loss: 0.0485 - val_mae: 0.2650 - learning_rate: 0.0088\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0249 - mae: 0.1755 - val_loss: 0.0482 - val_mae: 0.2654 - learning_rate: 0.0087\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0252 - mae: 0.1773 - val_loss: 0.0473 - val_mae: 0.2623 - learning_rate: 0.0086\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0252 - mae: 0.1786 - val_loss: 0.0484 - val_mae: 0.2670 - learning_rate: 0.0085\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0241 - mae: 0.1744 - val_loss: 0.0470 - val_mae: 0.2626 - learning_rate: 0.0084\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0228 - mae: 0.1702 - val_loss: 0.0470 - val_mae: 0.2629 - learning_rate: 0.0042\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0227 - mae: 0.1702 - val_loss: 0.0468 - val_mae: 0.2622 - learning_rate: 0.0041\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0226 - mae: 0.1699 - val_loss: 0.0467 - val_mae: 0.2619 - learning_rate: 0.0041\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0225 - mae: 0.1698 - val_loss: 0.0466 - val_mae: 0.2615 - learning_rate: 0.0040\n",
      "Epoch 24/100\n",
      "\u001b[1m 1/22\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0030 - mae: 0.0614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 22:35:01.660063: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0225 - mae: 0.1697 - val_loss: 0.0466 - val_mae: 0.2615 - learning_rate: 0.0040\n"
     ]
    }
   ],
   "source": [
    "# lstm_history = lstm_model.fit(\n",
    "#     train_data,\n",
    "#     epochs=100,\n",
    "#     callbacks=[lr_scheduler, my_callback]\n",
    "# )\n",
    "\n",
    "# Fit the model with training data\n",
    "lstm_history = lstm_model.fit(\n",
    "    train_data,\n",
    "    epochs=100,\n",
    "    validation_data=val_data,  # Ensure you define val_data appropriately\n",
    "    callbacks=[lr_scheduler, my_callback, early_stopping, reduce_lr],\n",
    "    batch_size=32  # Optional: specify batch size if it's not handled in your Dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /Users/monilshah/Documents/02_NWU/09_MSDS_458_DL/99_group_project/StockPricePrediction/01_Bidirectional_LSTM/01_Models/bidirecttional_lstm.keras\n"
     ]
    }
   ],
   "source": [
    "# Assuming lstm_model is your trained model\n",
    "model_save_path = '/Users/monilshah/Documents/02_NWU/09_MSDS_458_DL/99_group_project/StockPricePrediction/01_Bidirectional_LSTM/01_Models/bidirecttional_lstm.keras'  # Specify your desired path here\n",
    "\n",
    "# Save the model\n",
    "lstm_model.save(model_save_path)\n",
    "\n",
    "print(f'Model saved to {model_save_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'test' is your test DataFrame and scaler_train is your fitted MinMaxScaler\n",
    "\n",
    "# Scale the test data\n",
    "test_values = scaler_val.transform(test[['Volume', 'Adj Close']])  # Use only the features for scaling\n",
    "\n",
    "# Define the window size\n",
    "WINDOW = 30  # Same window size as used for training\"\n",
    "\n",
    "# Create a TensorFlow Dataset from the scaled test data\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_values)\n",
    "\n",
    "# Create windowed dataset with the specified window size\n",
    "test_data = test_data.window(WINDOW + 1, shift=1, drop_remainder=True)\n",
    "\n",
    "# Flatten the windowed dataset by batching\n",
    "test_data = test_data.flat_map(lambda x: x.batch(WINDOW + 1))\n",
    "\n",
    "# Create features and target tuple (for evaluation, you can use the last value as target)\n",
    "test_data = test_data.map(lambda x: (x[:-1], x[-1, 1]))  # Here, x[-1, 1] corresponds to the 'Adj Close' price\n",
    "\n",
    "# Create batches of windows\n",
    "test_data = test_data.batch(32).prefetch(1)  # Adjust batch size as necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Conda_3_12_7/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    }
   ],
   "source": [
    "predictions = lstm_model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5081593 ],\n",
       "       [0.5081597 ],\n",
       "       [0.5081599 ],\n",
       "       [0.5081601 ],\n",
       "       [0.50816005],\n",
       "       [0.5081599 ],\n",
       "       [0.5081599 ],\n",
       "       [0.5081599 ],\n",
       "       [0.50815994],\n",
       "       [0.50816005],\n",
       "       [0.50816   ],\n",
       "       [0.5081599 ],\n",
       "       [0.5081601 ],\n",
       "       [0.5081601 ],\n",
       "       [0.5081601 ],\n",
       "       [0.50816005],\n",
       "       [0.50816023],\n",
       "       [0.50815994],\n",
       "       [0.5081598 ],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.5081601 ],\n",
       "       [0.50815976],\n",
       "       [0.5081599 ],\n",
       "       [0.50816   ],\n",
       "       [0.50816   ],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.50815994],\n",
       "       [0.5081598 ],\n",
       "       [0.50815946],\n",
       "       [0.508159  ],\n",
       "       [0.508159  ],\n",
       "       [0.5081589 ],\n",
       "       [0.50815874],\n",
       "       [0.50815934],\n",
       "       [0.5081595 ],\n",
       "       [0.5081598 ],\n",
       "       [0.50815994],\n",
       "       [0.50815994],\n",
       "       [0.50816   ],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.5081601 ],\n",
       "       [0.5081602 ],\n",
       "       [0.5081602 ],\n",
       "       [0.5081602 ],\n",
       "       [0.50816023],\n",
       "       [0.50816035],\n",
       "       [0.5081603 ],\n",
       "       [0.5081601 ],\n",
       "       [0.50816023],\n",
       "       [0.50816023],\n",
       "       [0.5081603 ],\n",
       "       [0.5081604 ],\n",
       "       [0.5081603 ],\n",
       "       [0.50816023],\n",
       "       [0.5081601 ],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.50816005],\n",
       "       [0.50816   ],\n",
       "       [0.50816005],\n",
       "       [0.5081601 ],\n",
       "       [0.50815994],\n",
       "       [0.50815994],\n",
       "       [0.5081599 ],\n",
       "       [0.50815976],\n",
       "       [0.50815994],\n",
       "       [0.5081601 ],\n",
       "       [0.5081602 ],\n",
       "       [0.5081602 ],\n",
       "       [0.5081602 ],\n",
       "       [0.50816005],\n",
       "       [0.50815964],\n",
       "       [0.5081597 ],\n",
       "       [0.50815934],\n",
       "       [0.50815874],\n",
       "       [0.50815624],\n",
       "       [0.50815636],\n",
       "       [0.50815696],\n",
       "       [0.50816005],\n",
       "       [0.5081602 ],\n",
       "       [0.50816023],\n",
       "       [0.5081603 ],\n",
       "       [0.50816035],\n",
       "       [0.50816035],\n",
       "       [0.50816023],\n",
       "       [0.5081601 ],\n",
       "       [0.50816   ],\n",
       "       [0.50816035]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.42262864e+08 1.42262953e+08 1.42262991e+08 1.42263041e+08\n",
      " 1.42263028e+08 1.42262991e+08 1.42262991e+08 1.42262991e+08\n",
      " 1.42263003e+08 1.42263028e+08 1.42263016e+08 1.42262991e+08\n",
      " 1.42263041e+08 1.42263041e+08 1.42263041e+08 1.42263028e+08\n",
      " 1.42263066e+08 1.42263003e+08 1.42262978e+08 1.42263028e+08\n",
      " 1.42263028e+08 1.42263028e+08 1.42263028e+08 1.42263041e+08\n",
      " 1.42262965e+08 1.42262991e+08 1.42263016e+08 1.42263016e+08\n",
      " 1.42263028e+08 1.42263028e+08 1.42263003e+08 1.42262978e+08\n",
      " 1.42262902e+08 1.42262801e+08 1.42262801e+08 1.42262789e+08\n",
      " 1.42262751e+08 1.42262877e+08 1.42262915e+08 1.42262978e+08\n",
      " 1.42263003e+08 1.42263003e+08 1.42263016e+08 1.42263028e+08\n",
      " 1.42263028e+08 1.42263028e+08 1.42263041e+08 1.42263054e+08\n",
      " 1.42263054e+08 1.42263054e+08 1.42263066e+08 1.42263092e+08\n",
      " 1.42263079e+08 1.42263041e+08 1.42263066e+08 1.42263066e+08\n",
      " 1.42263079e+08 1.42263104e+08 1.42263079e+08 1.42263066e+08\n",
      " 1.42263041e+08 1.42263028e+08 1.42263028e+08 1.42263028e+08\n",
      " 1.42263028e+08 1.42263016e+08 1.42263028e+08 1.42263041e+08\n",
      " 1.42263003e+08 1.42263003e+08 1.42262991e+08 1.42262965e+08\n",
      " 1.42263003e+08 1.42263041e+08 1.42263054e+08 1.42263054e+08\n",
      " 1.42263054e+08 1.42263028e+08 1.42262940e+08 1.42262953e+08\n",
      " 1.42262877e+08 1.42262751e+08 1.42262221e+08 1.42262246e+08\n",
      " 1.42262372e+08 1.42263028e+08 1.42263054e+08 1.42263066e+08\n",
      " 1.42263079e+08 1.42263092e+08 1.42263092e+08 1.42263066e+08\n",
      " 1.42263041e+08 1.42263016e+08 1.42263092e+08]\n"
     ]
    }
   ],
   "source": [
    "# Reshape predictions to match the expected input shape of the scaler\n",
    "predictions_reshaped = np.zeros((predictions.shape[0], 2))  # Create an array for two features\n",
    "predictions_reshaped[:, 0] = predictions.flatten()  # Place the predictions in the first column\n",
    "\n",
    "# Inverse scale the predictions\n",
    "predictions_original = scaler_val.inverse_transform(predictions_reshaped)\n",
    "\n",
    "# Extract the first column for actual sales predictions\n",
    "predictions_original = predictions_original[:, 0]\n",
    "\n",
    "# Output the original predictions\n",
    "print(predictions_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2024-06-30    82542700.0\n",
       "2024-07-01    60402900.0\n",
       "2024-07-02    58046200.0\n",
       "2024-07-03    37369800.0\n",
       "2024-07-04    37369800.0\n",
       "                 ...    \n",
       "2024-10-28    36087100.0\n",
       "2024-10-29    35417200.0\n",
       "2024-10-30    47070900.0\n",
       "2024-10-31    47070900.0\n",
       "2024-11-01    47070900.0\n",
       "Name: Volume, Length: 125, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = test['Volume']\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda_3_12_7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
