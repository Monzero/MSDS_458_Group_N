{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c09555-ac3f-4f43-aedc-2b0826792621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv1D,Conv2D, Dense, Flatten, MaxPooling1D, MaxPooling2D, AveragePooling2D\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling1D, Concatenate\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4037807-ed84-4533-ba44-8f0a1d290180",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ec034b-f6fb-4ca2-b20d-9b038a03f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71e498e3-a04c-42a6-a3e9-b63e774bfd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import yfinance as yf\n",
    "#sp500 = \"LT.NS\"\n",
    "#data = yf.download(sp500, start=\"2019-11-25\", end=\"2024-11-25\")\n",
    "#data.to_csv(\"data/LnT_historical_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f121c39-2fe0-4c80-9b0f-0fae8e034f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = pd.read_csv(\"data/LnT_historical_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52519fe2-0609-4f13-b255-71ef95379b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-25 00:00:00+00:00</td>\n",
       "      <td>1259.961792</td>\n",
       "      <td>1380.849976</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1371.099976</td>\n",
       "      <td>1378.500000</td>\n",
       "      <td>2956576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-26 00:00:00+00:00</td>\n",
       "      <td>1243.674438</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>1359.550049</td>\n",
       "      <td>1379.349976</td>\n",
       "      <td>4853977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-27 00:00:00+00:00</td>\n",
       "      <td>1218.582153</td>\n",
       "      <td>1335.500000</td>\n",
       "      <td>1370.000000</td>\n",
       "      <td>1314.150024</td>\n",
       "      <td>1365.000000</td>\n",
       "      <td>7904745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-28 00:00:00+00:00</td>\n",
       "      <td>1231.721558</td>\n",
       "      <td>1349.900024</td>\n",
       "      <td>1354.000000</td>\n",
       "      <td>1327.199951</td>\n",
       "      <td>1344.000000</td>\n",
       "      <td>4503913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-29 00:00:00+00:00</td>\n",
       "      <td>1214.065308</td>\n",
       "      <td>1330.550049</td>\n",
       "      <td>1350.199951</td>\n",
       "      <td>1328.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>2515083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2024-11-14 00:00:00+00:00</td>\n",
       "      <td>3526.250000</td>\n",
       "      <td>3526.250000</td>\n",
       "      <td>3565.750000</td>\n",
       "      <td>3500.149902</td>\n",
       "      <td>3558.000000</td>\n",
       "      <td>1291765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2024-11-18 00:00:00+00:00</td>\n",
       "      <td>3542.149902</td>\n",
       "      <td>3542.149902</td>\n",
       "      <td>3568.300049</td>\n",
       "      <td>3510.850098</td>\n",
       "      <td>3521.100098</td>\n",
       "      <td>1233217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2024-11-19 00:00:00+00:00</td>\n",
       "      <td>3505.899902</td>\n",
       "      <td>3505.899902</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3495.000000</td>\n",
       "      <td>3559.899902</td>\n",
       "      <td>1826460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2024-11-21 00:00:00+00:00</td>\n",
       "      <td>3483.500000</td>\n",
       "      <td>3483.500000</td>\n",
       "      <td>3530.550049</td>\n",
       "      <td>3452.449951</td>\n",
       "      <td>3530.000000</td>\n",
       "      <td>1510581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2024-11-22 00:00:00+00:00</td>\n",
       "      <td>3603.500000</td>\n",
       "      <td>3603.500000</td>\n",
       "      <td>3613.500000</td>\n",
       "      <td>3473.100098</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>2534018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date    Adj_Close        Close         High  \\\n",
       "0     2019-11-25 00:00:00+00:00  1259.961792  1380.849976  1389.000000   \n",
       "1     2019-11-26 00:00:00+00:00  1243.674438  1363.000000  1380.000000   \n",
       "2     2019-11-27 00:00:00+00:00  1218.582153  1335.500000  1370.000000   \n",
       "3     2019-11-28 00:00:00+00:00  1231.721558  1349.900024  1354.000000   \n",
       "4     2019-11-29 00:00:00+00:00  1214.065308  1330.550049  1350.199951   \n",
       "...                         ...          ...          ...          ...   \n",
       "1233  2024-11-14 00:00:00+00:00  3526.250000  3526.250000  3565.750000   \n",
       "1234  2024-11-18 00:00:00+00:00  3542.149902  3542.149902  3568.300049   \n",
       "1235  2024-11-19 00:00:00+00:00  3505.899902  3505.899902  3607.000000   \n",
       "1236  2024-11-21 00:00:00+00:00  3483.500000  3483.500000  3530.550049   \n",
       "1237  2024-11-22 00:00:00+00:00  3603.500000  3603.500000  3613.500000   \n",
       "\n",
       "              Low         Open   Volume  \n",
       "0     1371.099976  1378.500000  2956576  \n",
       "1     1359.550049  1379.349976  4853977  \n",
       "2     1314.150024  1365.000000  7904745  \n",
       "3     1327.199951  1344.000000  4503913  \n",
       "4     1328.000000  1350.000000  2515083  \n",
       "...           ...          ...      ...  \n",
       "1233  3500.149902  3558.000000  1291765  \n",
       "1234  3510.850098  3521.100098  1233217  \n",
       "1235  3495.000000  3559.899902  1826460  \n",
       "1236  3452.449951  3530.000000  1510581  \n",
       "1237  3473.100098  3500.000000  2534018  \n",
       "\n",
       "[1238 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26add6f-0ca9-46ed-9155-f5ce1653df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all[\"Date\"] = pd.to_datetime(df_train_all[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ee43811-a9c5-4383-93ed-52dd47e8d755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1238.000000</td>\n",
       "      <td>1238.000000</td>\n",
       "      <td>1238.000000</td>\n",
       "      <td>1238.000000</td>\n",
       "      <td>1238.000000</td>\n",
       "      <td>1.238000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2008.925211</td>\n",
       "      <td>2062.823021</td>\n",
       "      <td>2085.688566</td>\n",
       "      <td>2040.985463</td>\n",
       "      <td>2063.858482</td>\n",
       "      <td>3.011686e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>916.109006</td>\n",
       "      <td>894.685372</td>\n",
       "      <td>901.813680</td>\n",
       "      <td>886.812497</td>\n",
       "      <td>894.810542</td>\n",
       "      <td>2.204713e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>654.971985</td>\n",
       "      <td>707.900024</td>\n",
       "      <td>755.750000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>697.200012</td>\n",
       "      <td>2.127960e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1305.126495</td>\n",
       "      <td>1373.475006</td>\n",
       "      <td>1392.787476</td>\n",
       "      <td>1356.712494</td>\n",
       "      <td>1377.149963</td>\n",
       "      <td>1.666719e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1791.520264</td>\n",
       "      <td>1850.674988</td>\n",
       "      <td>1871.500000</td>\n",
       "      <td>1827.625000</td>\n",
       "      <td>1849.450012</td>\n",
       "      <td>2.289248e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2637.318298</td>\n",
       "      <td>2665.549927</td>\n",
       "      <td>2688.162476</td>\n",
       "      <td>2645.337463</td>\n",
       "      <td>2668.712463</td>\n",
       "      <td>3.616259e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3866.753906</td>\n",
       "      <td>3897.149902</td>\n",
       "      <td>3919.899902</td>\n",
       "      <td>3801.100098</td>\n",
       "      <td>3855.399902</td>\n",
       "      <td>2.115335e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Adj_Close        Close         High          Low         Open  \\\n",
       "count  1238.000000  1238.000000  1238.000000  1238.000000  1238.000000   \n",
       "mean   2008.925211  2062.823021  2085.688566  2040.985463  2063.858482   \n",
       "std     916.109006   894.685372   901.813680   886.812497   894.810542   \n",
       "min     654.971985   707.900024   755.750000   661.000000   697.200012   \n",
       "25%    1305.126495  1373.475006  1392.787476  1356.712494  1377.149963   \n",
       "50%    1791.520264  1850.674988  1871.500000  1827.625000  1849.450012   \n",
       "75%    2637.318298  2665.549927  2688.162476  2645.337463  2668.712463   \n",
       "max    3866.753906  3897.149902  3919.899902  3801.100098  3855.399902   \n",
       "\n",
       "             Volume  \n",
       "count  1.238000e+03  \n",
       "mean   3.011686e+06  \n",
       "std    2.204713e+06  \n",
       "min    2.127960e+05  \n",
       "25%    1.666719e+06  \n",
       "50%    2.289248e+06  \n",
       "75%    3.616259e+06  \n",
       "max    2.115335e+07  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4167b640-c6a5-4355-9c08-f8585aa7f2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Adj_Close    0\n",
       "Close        0\n",
       "High         0\n",
       "Low          0\n",
       "Open         0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d31740-09b0-4b86-9f28-9ef872f332ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train_all[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04b573a9-d316-4ce5-adec-4f955b86a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all[\"epoch_time\"]= df_train_all[\"Date\"].apply(lambda x: x.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6685b9ad-4fee-4ea5-8805-0cd9e943f409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>epoch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-25 00:00:00+00:00</td>\n",
       "      <td>1259.961792</td>\n",
       "      <td>1380.849976</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1371.099976</td>\n",
       "      <td>1378.500000</td>\n",
       "      <td>2956576</td>\n",
       "      <td>1.574640e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-26 00:00:00+00:00</td>\n",
       "      <td>1243.674438</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>1359.550049</td>\n",
       "      <td>1379.349976</td>\n",
       "      <td>4853977</td>\n",
       "      <td>1.574726e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-27 00:00:00+00:00</td>\n",
       "      <td>1218.582153</td>\n",
       "      <td>1335.500000</td>\n",
       "      <td>1370.000000</td>\n",
       "      <td>1314.150024</td>\n",
       "      <td>1365.000000</td>\n",
       "      <td>7904745</td>\n",
       "      <td>1.574813e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-28 00:00:00+00:00</td>\n",
       "      <td>1231.721558</td>\n",
       "      <td>1349.900024</td>\n",
       "      <td>1354.000000</td>\n",
       "      <td>1327.199951</td>\n",
       "      <td>1344.000000</td>\n",
       "      <td>4503913</td>\n",
       "      <td>1.574899e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-29 00:00:00+00:00</td>\n",
       "      <td>1214.065308</td>\n",
       "      <td>1330.550049</td>\n",
       "      <td>1350.199951</td>\n",
       "      <td>1328.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>2515083</td>\n",
       "      <td>1.574986e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2024-11-14 00:00:00+00:00</td>\n",
       "      <td>3526.250000</td>\n",
       "      <td>3526.250000</td>\n",
       "      <td>3565.750000</td>\n",
       "      <td>3500.149902</td>\n",
       "      <td>3558.000000</td>\n",
       "      <td>1291765</td>\n",
       "      <td>1.731542e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2024-11-18 00:00:00+00:00</td>\n",
       "      <td>3542.149902</td>\n",
       "      <td>3542.149902</td>\n",
       "      <td>3568.300049</td>\n",
       "      <td>3510.850098</td>\n",
       "      <td>3521.100098</td>\n",
       "      <td>1233217</td>\n",
       "      <td>1.731888e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2024-11-19 00:00:00+00:00</td>\n",
       "      <td>3505.899902</td>\n",
       "      <td>3505.899902</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3495.000000</td>\n",
       "      <td>3559.899902</td>\n",
       "      <td>1826460</td>\n",
       "      <td>1.731974e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2024-11-21 00:00:00+00:00</td>\n",
       "      <td>3483.500000</td>\n",
       "      <td>3483.500000</td>\n",
       "      <td>3530.550049</td>\n",
       "      <td>3452.449951</td>\n",
       "      <td>3530.000000</td>\n",
       "      <td>1510581</td>\n",
       "      <td>1.732147e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2024-11-22 00:00:00+00:00</td>\n",
       "      <td>3603.500000</td>\n",
       "      <td>3603.500000</td>\n",
       "      <td>3613.500000</td>\n",
       "      <td>3473.100098</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>2534018</td>\n",
       "      <td>1.732234e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date    Adj_Close        Close         High  \\\n",
       "0    2019-11-25 00:00:00+00:00  1259.961792  1380.849976  1389.000000   \n",
       "1    2019-11-26 00:00:00+00:00  1243.674438  1363.000000  1380.000000   \n",
       "2    2019-11-27 00:00:00+00:00  1218.582153  1335.500000  1370.000000   \n",
       "3    2019-11-28 00:00:00+00:00  1231.721558  1349.900024  1354.000000   \n",
       "4    2019-11-29 00:00:00+00:00  1214.065308  1330.550049  1350.199951   \n",
       "...                        ...          ...          ...          ...   \n",
       "1233 2024-11-14 00:00:00+00:00  3526.250000  3526.250000  3565.750000   \n",
       "1234 2024-11-18 00:00:00+00:00  3542.149902  3542.149902  3568.300049   \n",
       "1235 2024-11-19 00:00:00+00:00  3505.899902  3505.899902  3607.000000   \n",
       "1236 2024-11-21 00:00:00+00:00  3483.500000  3483.500000  3530.550049   \n",
       "1237 2024-11-22 00:00:00+00:00  3603.500000  3603.500000  3613.500000   \n",
       "\n",
       "              Low         Open   Volume    epoch_time  \n",
       "0     1371.099976  1378.500000  2956576  1.574640e+09  \n",
       "1     1359.550049  1379.349976  4853977  1.574726e+09  \n",
       "2     1314.150024  1365.000000  7904745  1.574813e+09  \n",
       "3     1327.199951  1344.000000  4503913  1.574899e+09  \n",
       "4     1328.000000  1350.000000  2515083  1.574986e+09  \n",
       "...           ...          ...      ...           ...  \n",
       "1233  3500.149902  3558.000000  1291765  1.731542e+09  \n",
       "1234  3510.850098  3521.100098  1233217  1.731888e+09  \n",
       "1235  3495.000000  3559.899902  1826460  1.731974e+09  \n",
       "1236  3452.449951  3530.000000  1510581  1.732147e+09  \n",
       "1237  3473.100098  3500.000000  2534018  1.732234e+09  \n",
       "\n",
       "[1238 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e03feabf-6f11-4f1d-a426-2c1c7b0bfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_last_thursday(date):\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    \n",
    "    last_day = calendar.monthrange(year, month)[1]\n",
    "    last_date = datetime(year, month, last_day)\n",
    "    last_day_weekday = last_date.weekday()\n",
    "    days_since_last_thursday = (last_day_weekday - calendar.THURSDAY) % 7\n",
    "    last_thursday_date = last_date - timedelta(days=days_since_last_thursday)\n",
    "    \n",
    "    return 1 if date.date() == last_thursday_date.date() else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9d5b9-5256-4cc2-a443-04eb4e3b86fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c22b0a67-ad47-4690-8c24-96322b704587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all['opt_expiry'] = df_train_all['Date'].apply(is_last_thursday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "738b8d50-14b2-43d0-a5c5-d4acd92a0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all['10DaysMA'] =  df_train_all['Adj_Close'].rolling(window=10).mean()\n",
    "df_train_all['30DaysMA'] =  df_train_all['Adj_Close'].rolling(window=30).mean()\n",
    "df_train_all['50DaysMA'] =  df_train_all['Adj_Close'].rolling(window=50).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9102b0-57bc-4c73-b127-93237db2c6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f21ec75e-6fa8-4045-af56-741c1aa5557c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>epoch_time</th>\n",
       "      <th>opt_expiry</th>\n",
       "      <th>10DaysMA</th>\n",
       "      <th>30DaysMA</th>\n",
       "      <th>50DaysMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-25 00:00:00+00:00</td>\n",
       "      <td>1259.961792</td>\n",
       "      <td>1380.849976</td>\n",
       "      <td>1389.000000</td>\n",
       "      <td>1371.099976</td>\n",
       "      <td>1378.500000</td>\n",
       "      <td>2956576</td>\n",
       "      <td>1.574640e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-26 00:00:00+00:00</td>\n",
       "      <td>1243.674438</td>\n",
       "      <td>1363.000000</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>1359.550049</td>\n",
       "      <td>1379.349976</td>\n",
       "      <td>4853977</td>\n",
       "      <td>1.574726e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-27 00:00:00+00:00</td>\n",
       "      <td>1218.582153</td>\n",
       "      <td>1335.500000</td>\n",
       "      <td>1370.000000</td>\n",
       "      <td>1314.150024</td>\n",
       "      <td>1365.000000</td>\n",
       "      <td>7904745</td>\n",
       "      <td>1.574813e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-28 00:00:00+00:00</td>\n",
       "      <td>1231.721558</td>\n",
       "      <td>1349.900024</td>\n",
       "      <td>1354.000000</td>\n",
       "      <td>1327.199951</td>\n",
       "      <td>1344.000000</td>\n",
       "      <td>4503913</td>\n",
       "      <td>1.574899e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-29 00:00:00+00:00</td>\n",
       "      <td>1214.065308</td>\n",
       "      <td>1330.550049</td>\n",
       "      <td>1350.199951</td>\n",
       "      <td>1328.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>2515083</td>\n",
       "      <td>1.574986e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2024-11-14 00:00:00+00:00</td>\n",
       "      <td>3526.250000</td>\n",
       "      <td>3526.250000</td>\n",
       "      <td>3565.750000</td>\n",
       "      <td>3500.149902</td>\n",
       "      <td>3558.000000</td>\n",
       "      <td>1291765</td>\n",
       "      <td>1.731542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3602.230029</td>\n",
       "      <td>3526.965015</td>\n",
       "      <td>3583.747998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2024-11-18 00:00:00+00:00</td>\n",
       "      <td>3542.149902</td>\n",
       "      <td>3542.149902</td>\n",
       "      <td>3568.300049</td>\n",
       "      <td>3510.850098</td>\n",
       "      <td>3521.100098</td>\n",
       "      <td>1233217</td>\n",
       "      <td>1.731888e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3593.810010</td>\n",
       "      <td>3528.571680</td>\n",
       "      <td>3582.107998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2024-11-19 00:00:00+00:00</td>\n",
       "      <td>3505.899902</td>\n",
       "      <td>3505.899902</td>\n",
       "      <td>3607.000000</td>\n",
       "      <td>3495.000000</td>\n",
       "      <td>3559.899902</td>\n",
       "      <td>1826460</td>\n",
       "      <td>1.731974e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3586.955005</td>\n",
       "      <td>3529.823340</td>\n",
       "      <td>3580.730996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2024-11-21 00:00:00+00:00</td>\n",
       "      <td>3483.500000</td>\n",
       "      <td>3483.500000</td>\n",
       "      <td>3530.550049</td>\n",
       "      <td>3452.449951</td>\n",
       "      <td>3530.000000</td>\n",
       "      <td>1510581</td>\n",
       "      <td>1.732147e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3577.825000</td>\n",
       "      <td>3528.193343</td>\n",
       "      <td>3578.834995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2024-11-22 00:00:00+00:00</td>\n",
       "      <td>3603.500000</td>\n",
       "      <td>3603.500000</td>\n",
       "      <td>3613.500000</td>\n",
       "      <td>3473.100098</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>2534018</td>\n",
       "      <td>1.732234e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3573.630005</td>\n",
       "      <td>3532.073340</td>\n",
       "      <td>3578.981997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date    Adj_Close        Close         High  \\\n",
       "0    2019-11-25 00:00:00+00:00  1259.961792  1380.849976  1389.000000   \n",
       "1    2019-11-26 00:00:00+00:00  1243.674438  1363.000000  1380.000000   \n",
       "2    2019-11-27 00:00:00+00:00  1218.582153  1335.500000  1370.000000   \n",
       "3    2019-11-28 00:00:00+00:00  1231.721558  1349.900024  1354.000000   \n",
       "4    2019-11-29 00:00:00+00:00  1214.065308  1330.550049  1350.199951   \n",
       "...                        ...          ...          ...          ...   \n",
       "1233 2024-11-14 00:00:00+00:00  3526.250000  3526.250000  3565.750000   \n",
       "1234 2024-11-18 00:00:00+00:00  3542.149902  3542.149902  3568.300049   \n",
       "1235 2024-11-19 00:00:00+00:00  3505.899902  3505.899902  3607.000000   \n",
       "1236 2024-11-21 00:00:00+00:00  3483.500000  3483.500000  3530.550049   \n",
       "1237 2024-11-22 00:00:00+00:00  3603.500000  3603.500000  3613.500000   \n",
       "\n",
       "              Low         Open   Volume    epoch_time  opt_expiry  \\\n",
       "0     1371.099976  1378.500000  2956576  1.574640e+09           0   \n",
       "1     1359.550049  1379.349976  4853977  1.574726e+09           0   \n",
       "2     1314.150024  1365.000000  7904745  1.574813e+09           0   \n",
       "3     1327.199951  1344.000000  4503913  1.574899e+09           1   \n",
       "4     1328.000000  1350.000000  2515083  1.574986e+09           0   \n",
       "...           ...          ...      ...           ...         ...   \n",
       "1233  3500.149902  3558.000000  1291765  1.731542e+09           0   \n",
       "1234  3510.850098  3521.100098  1233217  1.731888e+09           0   \n",
       "1235  3495.000000  3559.899902  1826460  1.731974e+09           0   \n",
       "1236  3452.449951  3530.000000  1510581  1.732147e+09           0   \n",
       "1237  3473.100098  3500.000000  2534018  1.732234e+09           0   \n",
       "\n",
       "         10DaysMA     30DaysMA     50DaysMA  \n",
       "0             NaN          NaN          NaN  \n",
       "1             NaN          NaN          NaN  \n",
       "2             NaN          NaN          NaN  \n",
       "3             NaN          NaN          NaN  \n",
       "4             NaN          NaN          NaN  \n",
       "...           ...          ...          ...  \n",
       "1233  3602.230029  3526.965015  3583.747998  \n",
       "1234  3593.810010  3528.571680  3582.107998  \n",
       "1235  3586.955005  3529.823340  3580.730996  \n",
       "1236  3577.825000  3528.193343  3578.834995  \n",
       "1237  3573.630005  3532.073340  3578.981997  \n",
       "\n",
       "[1238 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c397ed2-fbbf-41b1-b7bb-51761fef5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_all[\"Next_Close\"] = df_train_all.shift(-1)[\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "127ccf88-48ac-442c-8e3a-f75aa63db29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all.dropna(subset=['50DaysMA'], inplace=True)\n",
    "#df_train_all.dropna(subset=['Next_Close'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d686223-dedc-4279-bded-448daad9f809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          0\n",
       "Adj_Close     0\n",
       "Close         0\n",
       "High          0\n",
       "Low           0\n",
       "Open          0\n",
       "Volume        0\n",
       "epoch_time    0\n",
       "opt_expiry    0\n",
       "10DaysMA      0\n",
       "30DaysMA      0\n",
       "50DaysMA      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd9bb825-da90-4a89-9a4f-350648a00c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Adj_Close', 'Close', 'High', 'Low', 'Open', 'Volume',\n",
       "       'epoch_time', 'opt_expiry', '10DaysMA', '30DaysMA', '50DaysMA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd4d849e-6a04-4ffb-902b-9a4e850148f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ffa7ba40-3a7f-4754-a7e1-e9639f058e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_scale = ['Open', 'Volume', 'High','Low', 'Adj_Close','10DaysMA','30DaysMA','50DaysMA']\n",
    "features_to_leave = ['epoch_time','opt_expiry']\n",
    "target = ['Close']\n",
    "df_train_all_scaled = df_train_all.copy()\n",
    "df_train_all_scaled\n",
    "feature_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "target_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_train_all_scaled[features_to_scale] = pd.DataFrame(\n",
    "    feature_scaler.fit_transform(df_train_all[features_to_scale]),\n",
    "    columns=features_to_scale,\n",
    "    index=df_train_all.index\n",
    ")\n",
    "\n",
    "df_train_all_scaled[\"Scaled_Close\"] = pd.DataFrame(\n",
    "    target_scaler.fit_transform(df_train_all[[\"Close\"]]),\n",
    "    columns=[\"Scaled_Close\"],\n",
    "    index=df_train_all.index\n",
    ")\n",
    "df_train_all_scaled.drop(columns=[\"Close\"],inplace=True)\n",
    "df_train_all_scaled.drop(columns=[\"opt_expiry\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "122cdc17-f143-4b46-a582-2207bf77bbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>epoch_time</th>\n",
       "      <th>Scaled_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2020-02-03 00:00:00+00:00</td>\n",
       "      <td>0.161604</td>\n",
       "      <td>0.173238</td>\n",
       "      <td>0.194580</td>\n",
       "      <td>0.187702</td>\n",
       "      <td>0.265254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2020-02-04 00:00:00+00:00</td>\n",
       "      <td>0.163053</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.199532</td>\n",
       "      <td>0.189602</td>\n",
       "      <td>0.161959</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.183068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2020-02-05 00:00:00+00:00</td>\n",
       "      <td>0.168252</td>\n",
       "      <td>0.179906</td>\n",
       "      <td>0.201904</td>\n",
       "      <td>0.190203</td>\n",
       "      <td>0.191366</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.188806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2020-02-06 00:00:00+00:00</td>\n",
       "      <td>0.170397</td>\n",
       "      <td>0.179906</td>\n",
       "      <td>0.206379</td>\n",
       "      <td>0.198119</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.191173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2020-02-07 00:00:00+00:00</td>\n",
       "      <td>0.165113</td>\n",
       "      <td>0.176556</td>\n",
       "      <td>0.202223</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>0.135670</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.185341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>2024-11-14 00:00:00+00:00</td>\n",
       "      <td>0.893983</td>\n",
       "      <td>0.888074</td>\n",
       "      <td>0.904159</td>\n",
       "      <td>0.905832</td>\n",
       "      <td>0.051525</td>\n",
       "      <td>0.995439</td>\n",
       "      <td>0.883703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>2024-11-18 00:00:00+00:00</td>\n",
       "      <td>0.898933</td>\n",
       "      <td>0.888880</td>\n",
       "      <td>0.907567</td>\n",
       "      <td>0.894149</td>\n",
       "      <td>0.048729</td>\n",
       "      <td>0.997719</td>\n",
       "      <td>0.888689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>2024-11-19 00:00:00+00:00</td>\n",
       "      <td>0.887647</td>\n",
       "      <td>0.901111</td>\n",
       "      <td>0.902519</td>\n",
       "      <td>0.906434</td>\n",
       "      <td>0.077059</td>\n",
       "      <td>0.998290</td>\n",
       "      <td>0.877322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2024-11-21 00:00:00+00:00</td>\n",
       "      <td>0.880673</td>\n",
       "      <td>0.876950</td>\n",
       "      <td>0.888968</td>\n",
       "      <td>0.896967</td>\n",
       "      <td>0.061975</td>\n",
       "      <td>0.999430</td>\n",
       "      <td>0.870299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>2024-11-22 00:00:00+00:00</td>\n",
       "      <td>0.918035</td>\n",
       "      <td>0.903165</td>\n",
       "      <td>0.895545</td>\n",
       "      <td>0.887468</td>\n",
       "      <td>0.110848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1189 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date  Adj_Close      High       Low      Open  \\\n",
       "49   2020-02-03 00:00:00+00:00   0.161604  0.173238  0.194580  0.187702   \n",
       "50   2020-02-04 00:00:00+00:00   0.163053  0.174312  0.199532  0.189602   \n",
       "51   2020-02-05 00:00:00+00:00   0.168252  0.179906  0.201904  0.190203   \n",
       "52   2020-02-06 00:00:00+00:00   0.170397  0.179906  0.206379  0.198119   \n",
       "53   2020-02-07 00:00:00+00:00   0.165113  0.176556  0.202223  0.195000   \n",
       "...                        ...        ...       ...       ...       ...   \n",
       "1233 2024-11-14 00:00:00+00:00   0.893983  0.888074  0.904159  0.905832   \n",
       "1234 2024-11-18 00:00:00+00:00   0.898933  0.888880  0.907567  0.894149   \n",
       "1235 2024-11-19 00:00:00+00:00   0.887647  0.901111  0.902519  0.906434   \n",
       "1236 2024-11-21 00:00:00+00:00   0.880673  0.876950  0.888968  0.896967   \n",
       "1237 2024-11-22 00:00:00+00:00   0.918035  0.903165  0.895545  0.887468   \n",
       "\n",
       "        Volume  epoch_time  Scaled_Close  \n",
       "49    0.265254    0.000000      0.181469  \n",
       "50    0.161959    0.000570      0.183068  \n",
       "51    0.191366    0.001140      0.188806  \n",
       "52    0.102273    0.001710      0.191173  \n",
       "53    0.135670    0.002281      0.185341  \n",
       "...        ...         ...           ...  \n",
       "1233  0.051525    0.995439      0.883703  \n",
       "1234  0.048729    0.997719      0.888689  \n",
       "1235  0.077059    0.998290      0.877322  \n",
       "1236  0.061975    0.999430      0.870299  \n",
       "1237  0.110848    1.000000      0.907925  \n",
       "\n",
       "[1189 rows x 8 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trial 2\n",
    "features_to_use = ['Open', 'Volume', 'High','Low', 'Adj_Close']\n",
    "features_to_scale = ['Open', 'Volume', 'High','Low', 'Adj_Close','epoch_time']\n",
    "features_to_leave = ['epoch_time']\n",
    "target = ['Close']\n",
    "df_train_all_scaled = df_train_all.copy()\n",
    "df_train_all_scaled\n",
    "feature_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "target_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_train_all_scaled[features_to_scale] = pd.DataFrame(\n",
    "    feature_scaler.fit_transform(df_train_all[features_to_scale]),\n",
    "    columns=features_to_scale,\n",
    "    index=df_train_all.index\n",
    ")\n",
    "\n",
    "df_train_all_scaled[\"Scaled_Close\"] = pd.DataFrame(\n",
    "    target_scaler.fit_transform(df_train_all[[\"Close\"]]),\n",
    "    columns=[\"Scaled_Close\"],\n",
    "    index=df_train_all.index\n",
    ")\n",
    "df_train_all_scaled.drop(columns=[\"Close\"],inplace=True)\n",
    "df_train_all_scaled.drop(columns=[\"opt_expiry\", '10DaysMA','30DaysMA','50DaysMA'], inplace=True)\n",
    "df_train_all_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a54bd23b-091a-470e-8fcf-a36c18b3cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_all_scaled[df_train_all_scaled[\"Date\"] <= \"2023-12-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ae887396-a503-41ab-ad66-d9c7fe5e6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train_all_scaled[df_train_all_scaled[\"Date\"].between(\"2024-01-01\",\"2024-05-31\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "f9eb90a4-b6c5-48cf-a382-6834d0fb9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_train_all_scaled[df_train_all_scaled[\"Date\"] >= \"2024-05-31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "55a29ae3-6fb6-41ab-94da-73ff4bd538cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divay Nagpal\\AppData\\Local\\Temp\\ipykernel_72392\\1681249928.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.drop(columns=[\"Date\"], inplace = True)\n",
      "C:\\Users\\Divay Nagpal\\AppData\\Local\\Temp\\ipykernel_72392\\1681249928.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_val.drop(columns=[\"Date\"], inplace = True)\n",
      "C:\\Users\\Divay Nagpal\\AppData\\Local\\Temp\\ipykernel_72392\\1681249928.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.drop(columns=[\"Date\"], inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df_train.drop(columns=[\"Date\"], inplace = True)\n",
    "df_val.drop(columns=[\"Date\"], inplace = True)\n",
    "df_test.drop(columns=[\"Date\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef93d1da-fd28-4d5d-9114-4a9bfd630f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "97de21c4-2e96-4ab4-ac4c-500fb619c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 20\n",
    "features_len = len(df_train.columns) - 1 # removing Scaled ccose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5167f6a-62d6-4740-8b35-1c3c19390b74",
   "metadata": {},
   "source": [
    "class EnhancedTime2Vec(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Time2Vec layer that includes both sine and cosine periodicity along with a linear term.\n",
    "        \n",
    "        Args:\n",
    "        - input_dim (int): Number of input features (time steps).\n",
    "        - output_dim (int): Number of output dimensions for encoding.\n",
    "        \"\"\"\n",
    "        super(EnhancedTime2Vec, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1, bias=True)  # Linear term\n",
    "        self.sin_periodic = nn.Linear(input_dim, (output_dim - 1) // 2, bias=True)  # Sine terms\n",
    "        self.cos_periodic = nn.Linear(input_dim, (output_dim - 1) // 2, bias=True)  # Cosine terms\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass to calculate Time2Vec encoding.\n",
    "\n",
    "        Args:\n",
    "        - x (Tensor): Input tensor of shape (Batch Size, Input Dim).\n",
    "\n",
    "        Returns:\n",
    "        - Tensor: Output tensor of shape (Batch Size, Output Dim).\n",
    "        \"\"\"\n",
    "        linear_part = self.linear(x)  # Linear component\n",
    "        sin_part = torch.sin(self.sin_periodic(x))  # Sine periodicity\n",
    "        cos_part = torch.cos(self.cos_periodic(x))  # Cosine periodicity\n",
    "        return torch.cat([linear_part, sin_part, cos_part], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "7843e378-a069-4c1e-9435-a648d471c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(Layer):\n",
    "    def __init__(self, kernel_size=1, **kwargs):\n",
    "        super(Time2Vec, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w0 = self.add_weight(shape=(1,), initializer='uniform', trainable=True, name='w0')\n",
    "        self.b0 = self.add_weight(shape=(1,), initializer='uniform', trainable=True, name='b0')\n",
    "        self.w = self.add_weight(shape=(self.kernel_size, 1), initializer='uniform', trainable=True, name='w')\n",
    "        self.b = self.add_weight(shape=(self.kernel_size, 1), initializer='uniform', trainable=True, name='b')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        linear_term = self.w0 * inputs + self.b0\n",
    "        periodic_term = tf.math.sin(tf.matmul(inputs, self.w) + self.b)\n",
    "        return tf.concat([linear_term, periodic_term], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f3f5dc4b-ab84-4d0e-951a-24f4a1463cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_with_time2vec(data, timesteps, features, time2vec):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "\n",
    "    for i in range(len(data) - timesteps):\n",
    "        # Extract sequence features and target\n",
    "        seq = data.iloc[i:i + timesteps, features].values\n",
    "        epoch_times = data.iloc[i:i + timesteps]['epoch_time'].values.reshape(-1, 1)  # Shape (timesteps, 1)\n",
    "\n",
    "        # Apply Time2Vec on epoch times\n",
    "        time2vec_features = time2vec(tf.convert_to_tensor(epoch_times, dtype=tf.float32)).numpy()\n",
    "        #print(\"time2vec_features : \",time2vec_features)\n",
    "        # Concatenate Time2Vec features with other sequence features\n",
    "        enhanced_seq = np.concatenate([seq, time2vec_features], axis=-1)\n",
    "\n",
    "        # Append enhanced sequence and target\n",
    "        sequences.append(enhanced_seq)\n",
    "        targets.append(data.iloc[i + timesteps]['Scaled_Close'])\n",
    "\n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6a481415-f2f5-46e0-8afa-6ad37bc11159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns\n",
    "feature_indexes = np.where(np.isin(df_train.columns, features_to_use))[0]\n",
    "feature_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0f2f252d-f900-4670-a6d2-8c331f977986",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time2vec_layer = Time2Vec(kernel_size=1)  # Example kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4c36d0dc-51f2-4458-adc8-468f0a3e65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns\n",
    "df_train_scaled=df_train.copy()\n",
    "df_val_scaled=df_val.copy()\n",
    "df_test_scaled=df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a146a5a8-0db6-4d0c-a669-b565e86d6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, targets = create_sequences_with_time2vec(df_train_scaled, timesteps, feature_indexes, time2vec_layer)\n",
    "sequences_val, targets_val = create_sequences_with_time2vec(df_val_scaled, timesteps, feature_indexes, time2vec_layer)\n",
    "sequences_test, targets_test = create_sequences_with_time2vec(df_test_scaled, timesteps, feature_indexes, time2vec_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "09a136f0-4083-4466-a8df-b66d694b371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence shape: (949, 20, 7)\n",
      "Targets shape: (949,)\n",
      "Sequence val shape: (81, 20, 7)\n",
      "Targets val shape: (81,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Sequence shape:\", sequences.shape)  # Expected: (num_sequences, timesteps, original_features + Time2Vec features)\n",
    "print(\"Targets shape:\", targets.shape) \n",
    "print(\"Sequence val shape:\", sequences_val.shape)  # Expected: (num_sequences, timesteps, original_features + Time2Vec features)\n",
    "print(\"Targets val shape:\", targets_val.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2c505920-84c9-4bcf-a9d4-ef149694e7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16160396,  0.17323769,  0.19457978,  0.18770186,  0.26525363,\n",
       "       -0.02896122,  0.01946923])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e4669577-a9ca-4383-be2e-ac55a5ccbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, maxlen, dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.dim = dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Get the shape of the inputs to determine the sequence length\n",
    "        seq_len = tf.shape(inputs)[1]  # Sequence length (50 in your case)\n",
    "        \n",
    "        # Generate positional encodings for the sequence length\n",
    "        position = tf.range(seq_len, dtype=tf.float32)[:, tf.newaxis]  # Shape (seq_len, 1)\n",
    "        div_term = tf.exp(tf.range(0, self.dim, 2, dtype=tf.float32) * -(np.log(10000.0) / self.dim))  # Shape (dim/2,)\n",
    "        \n",
    "        # Apply sine to even indices and cosine to odd indices\n",
    "        pos_enc = tf.zeros((seq_len, self.dim), dtype=tf.float32)\n",
    "        print(type(pos_enc))\n",
    "        numpy_array = tensor_util.MakeNdarray(pos_enc)\n",
    "        print(numpy_array)\n",
    "        #concrete_tensor = tf.convert_to_tensor(pos_enc)\n",
    "        #print(type(concrete_tensor))\n",
    "        #pos_enc = concrete_tensor.numpy()\n",
    "        pos_enc = pos_enc.numpy()  # convert Tensor to NumPy array before modifying\n",
    "        \n",
    "        pos_enc[:, 0::2] = np.sin(position * div_term)  # Apply sin to even indices\n",
    "        pos_enc[:, 1::2] = np.cos(position * div_term)  # Apply cos to odd indices\n",
    "        \n",
    "        # Convert back to a Tensor\n",
    "        pos_enc = tf.convert_to_tensor(pos_enc, dtype=tf.float32)\n",
    "\n",
    "        # Add positional encoding to the input tensor\n",
    "        return inputs + pos_enc[:seq_len, :]\n",
    "\n",
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, maxlen, dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.dim = dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        print(\"inp:\", inputs.shape)\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        print(\"seq_len:\",seq_len)\n",
    "        position = tf.range(seq_len, dtype=tf.float32)[:, tf.newaxis]\n",
    "        div_term = tf.exp(tf.range(0, self.dim, 2, dtype=tf.float32) * -(np.log(10000.0) / self.dim))\n",
    "\n",
    "        # Compute positional encodings\n",
    "        pos_enc_even = tf.sin(position * div_term)  # Apply sin to even indices\n",
    "        pos_enc_odd = tf.cos(position * div_term)  # Apply cos to odd indices\n",
    "\n",
    "        # Concatenate along the last dimension\n",
    "        pos_enc = tf.concat([pos_enc_even, pos_enc_odd], axis=-1)\n",
    "        input_dim = tf.shape(inputs)[-1]\n",
    "        pos_enc_dim = tf.shape(pos_enc)[-1]\n",
    "        #print(\"pos : \",pos_enc.shape)\n",
    "        # Ensure the shape matches the inputs\n",
    "        #pos_enc = tf.pad(pos_enc, [[0, 0], [0, tf.shape(inputs)[-1] - tf.shape(pos_enc)[-1]]])\n",
    "        #pos_enc = pos_enc[:, :input_dim] if pos_enc_dim > input_dim else tf.pad(pos_enc, [[0, 0], [0, input_dim - pos_enc_dim]])\n",
    "\n",
    "        #return inputs + pos_enc\n",
    "        pos_enc = tf.cond(\n",
    "        pos_enc_dim > input_dim,\n",
    "        lambda: pos_enc[:, :input_dim],  # Truncate if pos_enc is larger\n",
    "        lambda: tf.pad(pos_enc, [[0, 0], [0, input_dim - pos_enc_dim]])  # Pad if pos_enc is smaller\n",
    "        )\n",
    "\n",
    "        return inputs + pos_enc\n",
    "\n",
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, num_heads, key_dim, ff_dim, dropout=0.1, maxlen=20):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation='relu'),\n",
    "            Dense(key_dim)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.positional_encoding = PositionalEncoding(maxlen=maxlen, dim=key_dim)\n",
    "\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        print(f\"Input shape before attention: {inputs.shape}\")\n",
    "        inputs = self.positional_encoding(inputs)\n",
    "        attn_output = self.att(query=inputs, value=inputs, key=inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        print(f\"Attention output shape: {attn_output.shape}\")\n",
    "        out1 = self.layernorm1(inputs + attn_output)  # Add & Normalize\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n",
    "        return out2\n",
    "\n",
    "def create_transformer_model(input_shape, transformer_layers, num_heads, key_dim, ff_dim, dense_units, dropout_rate,  maxlen=20):\n",
    "    # Input Layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Transformer Encoder Layers\n",
    "    transformer_output = input_layer\n",
    "    for _ in range(transformer_layers):\n",
    "        transformer_layer = TransformerEncoder(\n",
    "            num_heads=num_heads, key_dim=key_dim, ff_dim=ff_dim, dropout=dropout_rate, maxlen=maxlen)\n",
    "        transformer_output = transformer_layer(transformer_output)\n",
    "\n",
    "    # Global Average Pooling\n",
    "    pooled_output = GlobalAveragePooling1D()(transformer_output)\n",
    "\n",
    "    # Dense Layers with Dropout\n",
    "    dense_1 = Dense(dense_units, activation=\"relu\")(pooled_output)\n",
    "    dropout_1 = Dropout(dropout_rate)(dense_1)\n",
    "    dense_2 = Dense(dense_units, activation=\"relu\")(dropout_1)\n",
    "    dense_2 = Dense(dense_units, activation=\"relu\")(dense_2)\n",
    "    dropout_2 = Dropout(dropout_rate)(dense_2)\n",
    "\n",
    "    # Output Layer\n",
    "    output_layer = Dense(1, activation=\"linear\")(dropout_2)\n",
    "    #output_layer = Dense(1, activation=\"linear\")(dense_2)\n",
    "\n",
    "    # Model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3b60e77c-f453-4c82-80d1-5d7ce13dfd42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape before attention: (None, 20, 7)\n",
      "inp: (None, 20, 7)\n",
      "seq_len: Tensor(\"positional_encoding_38_1/strided_slice:0\", shape=(), dtype=int32)\n",
      "Attention output shape: (None, 20, 7)\n",
      "Input shape before attention: (None, 20, 7)\n",
      "inp: (None, 20, 7)\n",
      "seq_len: Tensor(\"positional_encoding_38_1/strided_slice:0\", shape=(), dtype=int32)\n",
      "Attention output shape: (None, 20, 7)\n",
      "Input shape before attention: (None, 20, 7)\n",
      "inp: (None, 20, 7)\n",
      "seq_len: Tensor(\"positional_encoding_39_1/strided_slice:0\", shape=(), dtype=int32)\n",
      "Attention output shape: (None, 20, 7)\n",
      "Input shape before attention: (None, 20, 7)\n",
      "inp: (None, 20, 7)\n",
      "seq_len: Tensor(\"positional_encoding_39_1/strided_slice:0\", shape=(), dtype=int32)\n",
      "Attention output shape: (None, 20, 7)\n",
      "Input shape before attention: (None, 20, 7)\n",
      "inp: (None, 20, 7)\n",
      "seq_len: Tensor(\"positional_encoding_40_1/strided_slice:0\", shape=(), dtype=int32)\n",
      "Attention output shape: (None, 20, 7)\n",
      "Input shape before attention: (None, 20, 7)\n",
      "inp: (None, 20, 7)\n",
      "seq_len: Tensor(\"positional_encoding_40_1/strided_slice:0\", shape=(), dtype=int32)\n",
      "Attention output shape: (None, 20, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_38          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,830</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,830</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,830</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_45 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m7\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_38          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m7\u001b[0m)          │         \u001b[38;5;34m2,830\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m7\u001b[0m)          │         \u001b[38;5;34m2,830\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m7\u001b[0m)          │         \u001b[38;5;34m2,830\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_107 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_108 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_109 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_110 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m513\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">538,411</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m538,411\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">538,411</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m538,411\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divay Nagpal\\anaconda3\\envs\\python310clone\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 712ms/step - loss: 0.0977 - mae: 0.2443Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 561ms/step - loss: 0.1025 - mae: 0.2599Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 555ms/step - loss: 0.0966 - mae: 0.2525seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 516ms/step - loss: 0.0905 - mae: 0.2420Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 499ms/step - loss: 0.0860 - mae: 0.2344Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - loss: 0.0824 - mae: 0.2283Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - loss: 0.0791 - mae: 0.2226\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - loss: 0.0764 - mae: 0.2178Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 489ms/step - loss: 0.0740 - mae: 0.2137Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 497ms/step - loss: 0.0718 - mae: 0.2102 Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 501ms/step - loss: 0.0698 - mae: 0.2070Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 500ms/step - loss: 0.0679 - mae: 0.2037Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 507ms/step - loss: 0.0662 - mae: 0.2006Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 518ms/step - loss: 0.0646 - mae: 0.1979Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 518ms/step - loss: 0.0631 - mae: 0.1952Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 521ms/step - loss: 0.0617 - mae: 0.1925Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 520ms/step - loss: 0.0604 - mae: 0.1900Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 519ms/step - loss: 0.0591 - mae: 0.1875Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 527ms/step - loss: 0.0579 - mae: 0.1851Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 531ms/step - loss: 0.0567 - mae: 0.1827Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 530ms/step - loss: 0.0555 - mae: 0.1804Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 528ms/step - loss: 0.0545 - mae: 0.1781Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 524ms/step - loss: 0.0534 - mae: 0.1760\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 518ms/step - loss: 0.0524 - mae: 0.1739\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 516ms/step - loss: 0.0515 - mae: 0.1719Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 512ms/step - loss: 0.0506 - mae: 0.1699Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - loss: 0.0497 - mae: 0.1680Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 515ms/step - loss: 0.0489 - mae: 0.1662Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - loss: 0.0481 - mae: 0.1644Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - loss: 0.0473 - mae: 0.1627Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 528ms/step - loss: 0.0466 - mae: 0.1611 - val_loss: 0.0027 - val_mae: 0.0444\n",
      "Epoch 2/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 573ms/step - loss: 0.0041 - mae: 0.0521Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 463ms/step - loss: 0.0042 - mae: 0.0528Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 467ms/step - loss: 0.0043 - mae: 0.0528Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 483ms/step - loss: 0.0044 - mae: 0.0531Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 481ms/step - loss: 0.0043 - mae: 0.0528Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 516ms/step - loss: 0.0044 - mae: 0.0528Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 521ms/step - loss: 0.0044 - mae: 0.0528\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - loss: 0.0044 - mae: 0.0528Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 519ms/step - loss: 0.0044 - mae: 0.0529Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 515ms/step - loss: 0.0044 - mae: 0.0528Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 506ms/step - loss: 0.0044 - mae: 0.0528 Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 510ms/step - loss: 0.0044 - mae: 0.0528\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 512ms/step - loss: 0.0044 - mae: 0.0527seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 518ms/step - loss: 0.0044 - mae: 0.0526Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 518ms/step - loss: 0.0044 - mae: 0.0526\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 519ms/step - loss: 0.0044 - mae: 0.0526Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 511ms/step - loss: 0.0044 - mae: 0.0525Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 511ms/step - loss: 0.0044 - mae: 0.0525Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 512ms/step - loss: 0.0044 - mae: 0.0525Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 516ms/step - loss: 0.0044 - mae: 0.0525Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 522ms/step - loss: 0.0044 - mae: 0.0524Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 526ms/step - loss: 0.0044 - mae: 0.0523Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 521ms/step - loss: 0.0043 - mae: 0.0522Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 518ms/step - loss: 0.0043 - mae: 0.0521\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 519ms/step - loss: 0.0043 - mae: 0.0520Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 520ms/step - loss: 0.0043 - mae: 0.0519Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 516ms/step - loss: 0.0043 - mae: 0.0518Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 513ms/step - loss: 0.0043 - mae: 0.0517Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - loss: 0.0043 - mae: 0.0515Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509ms/step - loss: 0.0042 - mae: 0.0514Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 522ms/step - loss: 0.0042 - mae: 0.0514 - val_loss: 0.0035 - val_mae: 0.0481\n",
      "Epoch 3/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 613ms/step - loss: 0.0030 - mae: 0.0429Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 396ms/step - loss: 0.0029 - mae: 0.0427Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 482ms/step - loss: 0.0028 - mae: 0.0419Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 481ms/step - loss: 0.0028 - mae: 0.0416\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 496ms/step - loss: 0.0028 - mae: 0.0417Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - loss: 0.0029 - mae: 0.0420Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - loss: 0.0029 - mae: 0.0422Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 510ms/step - loss: 0.0029 - mae: 0.0423Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 516ms/step - loss: 0.0029 - mae: 0.0423\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 523ms/step - loss: 0.0029 - mae: 0.0422Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 518ms/step - loss: 0.0029 - mae: 0.0422 seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 525ms/step - loss: 0.0029 - mae: 0.0421Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 514ms/step - loss: 0.0029 - mae: 0.0421Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 515ms/step - loss: 0.0029 - mae: 0.0420Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 515ms/step - loss: 0.0029 - mae: 0.0420Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 521ms/step - loss: 0.0029 - mae: 0.0419\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 520ms/step - loss: 0.0029 - mae: 0.0419Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 513ms/step - loss: 0.0029 - mae: 0.0418Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 511ms/step - loss: 0.0029 - mae: 0.0418Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 514ms/step - loss: 0.0029 - mae: 0.0417Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 510ms/step - loss: 0.0029 - mae: 0.0416seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 509ms/step - loss: 0.0029 - mae: 0.0416Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 513ms/step - loss: 0.0028 - mae: 0.0415Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 514ms/step - loss: 0.0028 - mae: 0.0415Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 511ms/step - loss: 0.0028 - mae: 0.0415Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 510ms/step - loss: 0.0028 - mae: 0.0414\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 509ms/step - loss: 0.0028 - mae: 0.0414Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 511ms/step - loss: 0.0028 - mae: 0.0414Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - loss: 0.0028 - mae: 0.0414\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513ms/step - loss: 0.0028 - mae: 0.0414Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 537ms/step - loss: 0.0028 - mae: 0.0415 - val_loss: 0.0065 - val_mae: 0.0676\n",
      "Epoch 4/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 510ms/step - loss: 0.0024 - mae: 0.0370\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 408ms/step - loss: 0.0028 - mae: 0.0394Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 404ms/step - loss: 0.0028 - mae: 0.0393Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 423ms/step - loss: 0.0027 - mae: 0.0388Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 446ms/step - loss: 0.0026 - mae: 0.0385\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 463ms/step - loss: 0.0026 - mae: 0.0383\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - loss: 0.0026 - mae: 0.0384Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - loss: 0.0026 - mae: 0.0384seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 476ms/step - loss: 0.0026 - mae: 0.0384 Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 490ms/step - loss: 0.0026 - mae: 0.0383Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 489ms/step - loss: 0.0025 - mae: 0.0383Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 485ms/step - loss: 0.0025 - mae: 0.0383Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 492ms/step - loss: 0.0025 - mae: 0.0382Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 487ms/step - loss: 0.0025 - mae: 0.0382Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 492ms/step - loss: 0.0025 - mae: 0.0382Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 496ms/step - loss: 0.0025 - mae: 0.0382Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 499ms/step - loss: 0.0025 - mae: 0.0382\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 492ms/step - loss: 0.0025 - mae: 0.0381Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 495ms/step - loss: 0.0025 - mae: 0.0381Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 496ms/step - loss: 0.0025 - mae: 0.0381Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 496ms/step - loss: 0.0025 - mae: 0.0380Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 493ms/step - loss: 0.0025 - mae: 0.0380Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 498ms/step - loss: 0.0025 - mae: 0.0380Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 500ms/step - loss: 0.0025 - mae: 0.0379\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 501ms/step - loss: 0.0025 - mae: 0.0379Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 498ms/step - loss: 0.0024 - mae: 0.0379Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 497ms/step - loss: 0.0024 - mae: 0.0378Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - loss: 0.0024 - mae: 0.0378\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 0.0024 - mae: 0.0378Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - loss: 0.0024 - mae: 0.0378Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 513ms/step - loss: 0.0024 - mae: 0.0377 - val_loss: 0.0023 - val_mae: 0.0412\n",
      "Epoch 5/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 514ms/step - loss: 0.0036 - mae: 0.0441Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 544ms/step - loss: 0.0033 - mae: 0.0429Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 550ms/step - loss: 0.0031 - mae: 0.0420seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 516ms/step - loss: 0.0031 - mae: 0.0420Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 513ms/step - loss: 0.0031 - mae: 0.0420Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 507ms/step - loss: 0.0031 - mae: 0.0422Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - loss: 0.0031 - mae: 0.0424Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - loss: 0.0031 - mae: 0.0426Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 493ms/step - loss: 0.0031 - mae: 0.0426Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 493ms/step - loss: 0.0031 - mae: 0.0428 \n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 496ms/step - loss: 0.0031 - mae: 0.0429Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 497ms/step - loss: 0.0031 - mae: 0.0430Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 495ms/step - loss: 0.0031 - mae: 0.0431Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 493ms/step - loss: 0.0031 - mae: 0.0431\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 492ms/step - loss: 0.0032 - mae: 0.0432Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 491ms/step - loss: 0.0032 - mae: 0.0432Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 485ms/step - loss: 0.0032 - mae: 0.0432Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 486ms/step - loss: 0.0032 - mae: 0.0432Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 481ms/step - loss: 0.0032 - mae: 0.0432Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 479ms/step - loss: 0.0031 - mae: 0.0431Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 477ms/step - loss: 0.0031 - mae: 0.0431Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 479ms/step - loss: 0.0031 - mae: 0.0431Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 481ms/step - loss: 0.0031 - mae: 0.0431Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 483ms/step - loss: 0.0031 - mae: 0.0431Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 486ms/step - loss: 0.0031 - mae: 0.0430Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 486ms/step - loss: 0.0031 - mae: 0.0430Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 487ms/step - loss: 0.0031 - mae: 0.0430\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - loss: 0.0031 - mae: 0.0430Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - loss: 0.0031 - mae: 0.0429Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - loss: 0.0031 - mae: 0.0428Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 499ms/step - loss: 0.0031 - mae: 0.0428 - val_loss: 0.0060 - val_mae: 0.0634\n",
      "Epoch 6/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:58\u001b[0m 6s/step - loss: 0.0020 - mae: 0.0351Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 472ms/step - loss: 0.0021 - mae: 0.0362Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 480ms/step - loss: 0.0020 - mae: 0.0354Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 487ms/step - loss: 0.0020 - mae: 0.0355Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 469ms/step - loss: 0.0020 - mae: 0.0354Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - loss: 0.0020 - mae: 0.0355seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - loss: 0.0020 - mae: 0.0357Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - loss: 0.0020 - mae: 0.0357Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 474ms/step - loss: 0.0020 - mae: 0.0356 Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 478ms/step - loss: 0.0020 - mae: 0.0356Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 489ms/step - loss: 0.0020 - mae: 0.0356Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 484ms/step - loss: 0.0020 - mae: 0.0356Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - loss: 0.0020 - mae: 0.0356Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 489ms/step - loss: 0.0020 - mae: 0.0356Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 492ms/step - loss: 0.0020 - mae: 0.0355Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 493ms/step - loss: 0.0020 - mae: 0.0355Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 494ms/step - loss: 0.0020 - mae: 0.0354Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 493ms/step - loss: 0.0020 - mae: 0.0354Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 492ms/step - loss: 0.0020 - mae: 0.0354Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 487ms/step - loss: 0.0020 - mae: 0.0353Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 488ms/step - loss: 0.0020 - mae: 0.0353Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 488ms/step - loss: 0.0020 - mae: 0.0352Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 484ms/step - loss: 0.0020 - mae: 0.0352Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 485ms/step - loss: 0.0020 - mae: 0.0351Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 489ms/step - loss: 0.0020 - mae: 0.0351\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 487ms/step - loss: 0.0020 - mae: 0.0350Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 486ms/step - loss: 0.0020 - mae: 0.0350Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - loss: 0.0020 - mae: 0.0350Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - loss: 0.0020 - mae: 0.0350Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - loss: 0.0020 - mae: 0.0350Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 494ms/step - loss: 0.0020 - mae: 0.0350 - val_loss: 0.0023 - val_mae: 0.0424\n",
      "Epoch 7/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:59\u001b[0m 6s/step - loss: 0.0013 - mae: 0.0276Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 462ms/step - loss: 0.0012 - mae: 0.0271\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 515ms/step - loss: 0.0012 - mae: 0.0268Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 529ms/step - loss: 0.0012 - mae: 0.0268Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 532ms/step - loss: 0.0012 - mae: 0.0271Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 538ms/step - loss: 0.0012 - mae: 0.0275Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 553ms/step - loss: 0.0013 - mae: 0.0279Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 533ms/step - loss: 0.0013 - mae: 0.0282Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 540ms/step - loss: 0.0013 - mae: 0.0285Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 538ms/step - loss: 0.0014 - mae: 0.0288Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 531ms/step - loss: 0.0014 - mae: 0.0291Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 524ms/step - loss: 0.0014 - mae: 0.0295 Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 520ms/step - loss: 0.0015 - mae: 0.0299Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 513ms/step - loss: 0.0015 - mae: 0.0302Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 518ms/step - loss: 0.0015 - mae: 0.0305\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 518ms/step - loss: 0.0016 - mae: 0.0307Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 513ms/step - loss: 0.0016 - mae: 0.0310seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 511ms/step - loss: 0.0016 - mae: 0.0311Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 507ms/step - loss: 0.0016 - mae: 0.0313\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 510ms/step - loss: 0.0016 - mae: 0.0314Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 507ms/step - loss: 0.0017 - mae: 0.0315Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 511ms/step - loss: 0.0017 - mae: 0.0316\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 511ms/step - loss: 0.0017 - mae: 0.0316Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 508ms/step - loss: 0.0017 - mae: 0.0317Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 504ms/step - loss: 0.0017 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 502ms/step - loss: 0.0017 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 498ms/step - loss: 0.0017 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 502ms/step - loss: 0.0017 - mae: 0.0320Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 500ms/step - loss: 0.0017 - mae: 0.0320\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step - loss: 0.0017 - mae: 0.0321Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 511ms/step - loss: 0.0017 - mae: 0.0321 - val_loss: 0.0025 - val_mae: 0.0416\n",
      "Epoch 8/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 514ms/step - loss: 0.0022 - mae: 0.0364Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 434ms/step - loss: 0.0020 - mae: 0.0345Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 458ms/step - loss: 0.0019 - mae: 0.0334\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 463ms/step - loss: 0.0019 - mae: 0.0326seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 482ms/step - loss: 0.0019 - mae: 0.0323Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - loss: 0.0019 - mae: 0.0322Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - loss: 0.0018 - mae: 0.0321Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 518ms/step - loss: 0.0018 - mae: 0.0320Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 517ms/step - loss: 0.0018 - mae: 0.0320Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 510ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 505ms/step - loss: 0.0018 - mae: 0.0318 Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 505ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 506ms/step - loss: 0.0018 - mae: 0.0318seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 512ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 504ms/step - loss: 0.0018 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 504ms/step - loss: 0.0018 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 511ms/step - loss: 0.0018 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 511ms/step - loss: 0.0018 - mae: 0.0319Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 508ms/step - loss: 0.0018 - mae: 0.0319\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 509ms/step - loss: 0.0018 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 511ms/step - loss: 0.0018 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 508ms/step - loss: 0.0018 - mae: 0.0319Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 507ms/step - loss: 0.0018 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 504ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 502ms/step - loss: 0.0018 - mae: 0.0318\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 504ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 504ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 505ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 503ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - loss: 0.0018 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 514ms/step - loss: 0.0018 - mae: 0.0318 - val_loss: 0.0075 - val_mae: 0.0743\n",
      "Epoch 9/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:46\u001b[0m 6s/step - loss: 0.0019 - mae: 0.0324Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 413ms/step - loss: 0.0018 - mae: 0.0317Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 455ms/step - loss: 0.0019 - mae: 0.0325Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 441ms/step - loss: 0.0019 - mae: 0.0329Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 454ms/step - loss: 0.0019 - mae: 0.0329Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 463ms/step - loss: 0.0018 - mae: 0.0327Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - loss: 0.0018 - mae: 0.0325Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - loss: 0.0018 - mae: 0.0324Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 462ms/step - loss: 0.0018 - mae: 0.0323 Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 463ms/step - loss: 0.0018 - mae: 0.0322Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 462ms/step - loss: 0.0017 - mae: 0.0321Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 468ms/step - loss: 0.0017 - mae: 0.0321Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 467ms/step - loss: 0.0017 - mae: 0.0320Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 462ms/step - loss: 0.0017 - mae: 0.0320Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 460ms/step - loss: 0.0017 - mae: 0.0319Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 467ms/step - loss: 0.0017 - mae: 0.0318Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 467ms/step - loss: 0.0017 - mae: 0.0318\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 473ms/step - loss: 0.0017 - mae: 0.0317\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 477ms/step - loss: 0.0017 - mae: 0.0316Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 473ms/step - loss: 0.0016 - mae: 0.0316Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 472ms/step - loss: 0.0016 - mae: 0.0316Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 475ms/step - loss: 0.0016 - mae: 0.0316\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 475ms/step - loss: 0.0016 - mae: 0.0316Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 477ms/step - loss: 0.0016 - mae: 0.0316Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 479ms/step - loss: 0.0016 - mae: 0.0316Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 479ms/step - loss: 0.0016 - mae: 0.0317Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 482ms/step - loss: 0.0016 - mae: 0.0317\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - loss: 0.0017 - mae: 0.0317\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 0.0017 - mae: 0.0318\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - loss: 0.0017 - mae: 0.0318Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 502ms/step - loss: 0.0017 - mae: 0.0318 - val_loss: 0.0176 - val_mae: 0.1243\n",
      "Epoch 10/10\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 1/30\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 658ms/step - loss: 0.0037 - mae: 0.0485Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 2/30\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 517ms/step - loss: 0.0036 - mae: 0.0474Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m 3/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 502ms/step - loss: 0.0033 - mae: 0.0449Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 4/30\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 481ms/step - loss: 0.0031 - mae: 0.0434Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 5/30\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 492ms/step - loss: 0.0029 - mae: 0.0427Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 6/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - loss: 0.0029 - mae: 0.0420\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 7/30\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - loss: 0.0028 - mae: 0.0412\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 8/30\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 490ms/step - loss: 0.0027 - mae: 0.0406Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m 9/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 487ms/step - loss: 0.0026 - mae: 0.0402\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m10/30\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 478ms/step - loss: 0.0026 - mae: 0.0397 Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 483ms/step - loss: 0.0025 - mae: 0.0392Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m12/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - loss: 0.0025 - mae: 0.0389Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m13/30\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 494ms/step - loss: 0.0024 - mae: 0.0385Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m14/30\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 486ms/step - loss: 0.0024 - mae: 0.0382Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m15/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 479ms/step - loss: 0.0024 - mae: 0.0379Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m16/30\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 481ms/step - loss: 0.0023 - mae: 0.0377Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m17/30\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 479ms/step - loss: 0.0023 - mae: 0.0375\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m18/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 480ms/step - loss: 0.0023 - mae: 0.0373Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m19/30\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 482ms/step - loss: 0.0023 - mae: 0.0372Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m20/30\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 482ms/step - loss: 0.0023 - mae: 0.0370Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m21/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 484ms/step - loss: 0.0023 - mae: 0.0369Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m22/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 484ms/step - loss: 0.0022 - mae: 0.0368Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m23/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m3s\u001b[0m 486ms/step - loss: 0.0022 - mae: 0.0367Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m24/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 485ms/step - loss: 0.0022 - mae: 0.0366Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "\u001b[1m25/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 484ms/step - loss: 0.0022 - mae: 0.0365Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m26/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m1s\u001b[0m 481ms/step - loss: 0.0022 - mae: 0.0364Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m27/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 483ms/step - loss: 0.0022 - mae: 0.0363\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 0.0022 - mae: 0.0363Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - loss: 0.0022 - mae: 0.0362Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "Input shape before attention: (21, 20, 7)\n",
      "inp: (21, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (21, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - loss: 0.0022 - mae: 0.0361Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "Input shape before attention: (17, 20, 7)\n",
      "inp: (17, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (17, 20, 7)\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 492ms/step - loss: 0.0022 - mae: 0.0360 - val_loss: 0.0070 - val_mae: 0.0715\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 127ms/stepInput shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m2/4\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/stepInput shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "Input shape before attention: (32, 20, 7)\n",
      "inp: (32, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (32, 20, 7)\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step Input shape before attention: (4, 20, 7)\n",
      "inp: (4, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (4, 20, 7)\n",
      "Input shape before attention: (4, 20, 7)\n",
      "inp: (4, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (4, 20, 7)\n",
      "Input shape before attention: (4, 20, 7)\n",
      "inp: (4, 20, 7)\n",
      "seq_len: tf.Tensor(20, shape=(), dtype=int32)\n",
      "Attention output shape: (4, 20, 7)\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (20, 7)  # Update this based on your dataset\n",
    "transformer_layers = 3\n",
    "time2vec_dim = 2\n",
    "dense_units = 512\n",
    "dropout_rate = 0.2\n",
    "num_heads = 4\n",
    "key_dim = 7\n",
    "ff_dim = 128\n",
    "\n",
    "model = create_transformer_model(input_shape, transformer_layers, num_heads, key_dim, ff_dim, dense_units, dropout_rate, 20)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',          # The metric to monitor (could also be 'val_accuracy')\n",
    "    patience=10,                 # Number of epochs with no improvement to wait before stopping\n",
    "    verbose=0,                   # To print messages when stopping early\n",
    "    restore_best_weights=True    # Restore the best weights once training is stopped\n",
    ")\n",
    "#, callbacks=[early_stopping]\n",
    "history = model.fit(sequences,targets , validation_data=(sequences_val, targets_val), epochs=10, batch_size=None, callbacks=[early_stopping])\n",
    "\n",
    "# Prediction\n",
    "predictions = model.predict(sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7477cbef-cf7e-4850-92d1-44dced7b7538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3526.55004883],\n",
       "       [3626.5       ],\n",
       "       [3614.35009766],\n",
       "       [3573.30004883],\n",
       "       [3627.14990234],\n",
       "       [3632.        ],\n",
       "       [3666.10009766],\n",
       "       [3650.05004883],\n",
       "       [3621.10009766],\n",
       "       [3649.35009766],\n",
       "       [3651.60009766],\n",
       "       [3636.55004883],\n",
       "       [3656.19995117],\n",
       "       [3618.5       ],\n",
       "       [3651.44995117],\n",
       "       [3538.05004883],\n",
       "       [3519.44995117],\n",
       "       [3619.14990234],\n",
       "       [3679.89990234],\n",
       "       [3774.94995117],\n",
       "       [3784.64990234],\n",
       "       [3815.        ],\n",
       "       [3779.30004883],\n",
       "       [3665.69995117],\n",
       "       [3528.        ],\n",
       "       [3576.19995117],\n",
       "       [3638.25      ],\n",
       "       [3553.55004883],\n",
       "       [3592.05004883],\n",
       "       [3571.94995117],\n",
       "       [3551.80004883],\n",
       "       [3545.19995117],\n",
       "       [3568.35009766],\n",
       "       [3555.05004883],\n",
       "       [3572.69995117],\n",
       "       [3596.05004883],\n",
       "       [3606.5       ],\n",
       "       [3598.55004883],\n",
       "       [3641.89990234],\n",
       "       [3702.69995117],\n",
       "       [3689.05004883],\n",
       "       [3683.44995117],\n",
       "       [3704.64990234],\n",
       "       [3683.10009766],\n",
       "       [3690.14990234],\n",
       "       [3650.80004883],\n",
       "       [3624.14990234],\n",
       "       [3574.75      ],\n",
       "       [3578.30004883],\n",
       "       [3596.14990234],\n",
       "       [3536.94995117],\n",
       "       [3622.        ],\n",
       "       [3613.        ],\n",
       "       [3662.25      ],\n",
       "       [3695.19995117],\n",
       "       [3730.44995117],\n",
       "       [3683.69995117],\n",
       "       [3793.89990234],\n",
       "       [3787.69995117],\n",
       "       [3791.60009766],\n",
       "       [3793.85009766],\n",
       "       [3762.14990234],\n",
       "       [3705.64990234],\n",
       "       [3675.55004883],\n",
       "       [3653.5       ],\n",
       "       [3497.64990234],\n",
       "       [3493.94995117],\n",
       "       [3468.35009766],\n",
       "       [3532.39990234],\n",
       "       [3487.10009766],\n",
       "       [3460.35009766],\n",
       "       [3482.55004883],\n",
       "       [3555.05004883],\n",
       "       [3551.89990234],\n",
       "       [3532.60009766],\n",
       "       [3570.30004883],\n",
       "       [3577.80004883],\n",
       "       [3585.60009766],\n",
       "       [3511.89990234],\n",
       "       [3455.39990234],\n",
       "       [3442.64990234],\n",
       "       [3326.39990234],\n",
       "       [3340.80004883],\n",
       "       [3380.89990234],\n",
       "       [3408.35009766],\n",
       "       [3622.30004883],\n",
       "       [3626.35009766],\n",
       "       [3574.44995117],\n",
       "       [3574.80004883],\n",
       "       [3645.44995117],\n",
       "       [3646.55004883],\n",
       "       [3660.30004883],\n",
       "       [3628.85009766],\n",
       "       [3591.35009766],\n",
       "       [3547.94995117],\n",
       "       [3526.25      ],\n",
       "       [3542.14990234],\n",
       "       [3505.89990234],\n",
       "       [3483.5       ],\n",
       "       [3603.5       ]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_scaler.inverse_transform(targets_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "09d15936-eec9-474c-b113-3af2f2604c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88379717, 0.91513682, 0.91132717, 0.89845579, 0.91534059,\n",
       "       0.91686136, 0.92755356, 0.92252101, 0.91344366, 0.92230154,\n",
       "       0.92300703, 0.91828804, 0.92444933, 0.91262839, 0.92295996,\n",
       "       0.88740304, 0.88157091, 0.91283217, 0.93188053, 0.9616838 ,\n",
       "       0.96472525, 0.97424162, 0.96304778, 0.92742809, 0.88425181,\n",
       "       0.89936507, 0.91882107, 0.89226311, 0.90433492, 0.89803246,\n",
       "       0.89171439, 0.88964491, 0.89690372, 0.89273344, 0.89826763,\n",
       "       0.90558913, 0.90886575, 0.90637301, 0.91996551, 0.93902957,\n",
       "       0.93474959, 0.93299366, 0.93964098, 0.93288397, 0.93509446,\n",
       "       0.92275618, 0.91439993, 0.89891043, 0.90002356, 0.90562044,\n",
       "       0.8870581 , 0.91372582, 0.91090384, 0.92634635, 0.93667792,\n",
       "       0.94773067, 0.93307205, 0.96762562, 0.9656816 , 0.9669045 ,\n",
       "       0.96761   , 0.9576703 , 0.93995453, 0.93051662, 0.92360276,\n",
       "       0.87473543, 0.8735753 , 0.86554838, 0.88563141, 0.87142751,\n",
       "       0.86303996, 0.87000082, 0.89273344, 0.8917457 , 0.88569419,\n",
       "       0.89751513, 0.89986678, 0.90231251, 0.87920357, 0.86148781,\n",
       "       0.85749   , 0.82103942, 0.82555464, 0.83812808, 0.84673518,\n",
       "       0.91381991, 0.91508981, 0.89881635, 0.89892612, 0.92107864,\n",
       "       0.92142358, 0.92573493, 0.9158737 , 0.90411545, 0.89050718,\n",
       "       0.88370309, 0.88868856, 0.87732225, 0.87029869, 0.90792509])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d7016414-ed41-45b6-839f-703a8975a546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGzCAYAAADOnwhmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC+nUlEQVR4nOydd3hb5fXHP5K897bjDGfvRRIIgSSEBBIgQNibsFehFNofpemg0JZCmQVaSNlQQgMFQlkhCSOEkYQkZO+9bcdxvIcs6f7+eHWvJE9J1op9Ps/jx7J0dfVeSZbOPed7vsekaZqGIAiCIAhCJ8Yc7gUIgiAIgiCEGwmIBEEQBEHo9EhAJAiCIAhCp0cCIkEQBEEQOj0SEAmCIAiC0OmRgEgQBEEQhE6PBESCIAiCIHR6JCASBEEQBKHTIwGRIAiCIAidHgmIBEFoEZPJxIMPPhjuZYSdSZMmMWnSJOPvPXv2YDKZeP3118O2psY0XmOwiMRjF4RAIAGRIISI559/HpPJxNixY/3ex6FDh3jwwQdZs2ZN4BYW4SxevBiTyWT8REdH07t3b2bOnMmuXbvCvTyf+OGHH3jwwQcpKysL2xp69uzp8Xzm5OQwYcIE5s2bF7Y1CUIkEBXuBQhCZ2HOnDn07NmTH3/8kR07dtC3b1+f93Ho0CEeeughevbsyciRIwO/yAjm7rvv5sQTT6ShoYGffvqJF198kU8//ZT169eTn58f0rUUFBRQW1tLdHS0T/f74YcfeOihh7j++utJS0sLzuK8YOTIkfzqV78C1HvqX//6FxdddBEvvPACt99+e6v39ffYBSHSkQyRIISA3bt388MPP/DUU0+RnZ3NnDlzwr2k444JEyZwzTXXcMMNN/Dcc8/xxBNPUFpayhtvvNHifaqrq4OyFpPJRFxcHBaLJSj7DzZdu3blmmuu4ZprruHXv/4133//PYmJiTz99NMt3sdms2G1Wo/7YxeElpCASBBCwJw5c0hPT2f69OlccsklLQZEZWVl3HvvvfTs2ZPY2Fi6devGzJkzKSkpYfHixZx44okA3HDDDUbJQ9dy9OzZk+uvv77JPhtrS6xWKw888ACjR48mNTWVxMREJkyYwNdff+3zcRUVFREVFcVDDz3U5LatW7diMpn4xz/+AUBDQwMPPfQQ/fr1Iy4ujszMTMaPH8+iRYt8flyAyZMnAyrYBHjwwQcxmUxs2rSJq666ivT0dMaPH29s/9ZbbzF69Gji4+PJyMjgiiuuYP/+/U32++KLL9KnTx/i4+M56aST+Pbbb5ts05KOZsuWLVx22WVkZ2cTHx/PgAED+N3vfmes77777gOgV69exuu3Z8+eoKzRF/Ly8hg0aJDxXOrH98QTT/D3v/+dPn36EBsby6ZNm/w6dp2DBw9y4403kpubS2xsLEOGDOHVV19tsp7nnnuOIUOGkJCQQHp6OmPGjOHtt99u1zEKQltIyUwQQsCcOXO46KKLiImJ4corr+SFF15gxYoVRoADUFVVxYQJE9i8eTM33ngjo0aNoqSkhI8++ogDBw4waNAg/vSnP/HAAw9w6623MmHCBABOOeUUn9ZSUVHByy+/zJVXXsktt9xCZWUlr7zyCtOmTePHH3/0qRSXm5vLaaedxrvvvssf//hHj9veeecdLBYLl156KaACgkceeYSbb76Zk046iYqKClauXMlPP/3EmWee6dMxAOzcuROAzMxMj+svvfRS+vXrx1//+lc0TQPg4Ycf5g9/+AOXXXYZN998M0eOHOG5555j4sSJrF692ihfvfLKK9x2222ccsop3HPPPezatYvzzz+fjIwMunfv3up61q1bx4QJE4iOjubWW2+lZ8+e7Ny5k48//piHH36Yiy66iG3btvGf//yHp59+mqysLACys7NDtsaWaGhoYP/+/U2ey9dee426ujpuvfVWYmNjycjIwOFw+HzsoILnk08+GZPJxF133UV2djbz58/npptuoqKignvuuQeAl156ibvvvptLLrmEX/ziF9TV1bFu3TqWL1/OVVdd5dfxCYJXaIIgBJWVK1dqgLZo0SJN0zTN4XBo3bp1037xi194bPfAAw9ogPbBBx802YfD4dA0TdNWrFihAdprr73WZJuCggLtuuuua3L9aaedpp122mnG3zabTauvr/fY5tixY1pubq524403elwPaH/84x9bPb5//etfGqCtX7/e4/rBgwdrkydPNv4eMWKENn369Fb31Rxff/21BmivvvqqduTIEe3QoUPap59+qvXs2VMzmUzaihUrNE3TtD/+8Y8aoF155ZUe99+zZ49msVi0hx9+2OP69evXa1FRUcb1VqtVy8nJ0UaOHOnx/Lz44osa4PEc7t69u8nrMHHiRC05OVnbu3evx+Por52madrjjz+uAdru3buDvsaWKCgo0KZOnaodOXJEO3LkiLZ27Vrtiiuu0ADt5z//ucfxpaSkaMXFxR739/fYb7rpJq1Lly5aSUmJxzZXXHGFlpqaqtXU1GiapmkzZszQhgwZ0uZxCEKgkZKZIASZOXPmkJuby+mnnw4o/cnll1/O3Llzsdvtxnbvv/8+I0aM4MILL2yyD5PJFLD1WCwWYmJiAHA4HJSWlmKz2RgzZgw//fSTz/u76KKLiIqK4p133jGu27BhA5s2beLyyy83rktLS2Pjxo1s377dr3XfeOONZGdnk5+fz/Tp06muruaNN95gzJgxHts1FgV/8MEHOBwOLrvsMkpKSoyfvLw8+vXrZ5QKV65cSXFxMbfffrvx/ABcf/31pKamtrq2I0eOsGTJEm688UZ69OjhcZs3r10o1ujOwoULyc7OJjs7mxEjRvDf//6Xa6+9lr/97W8e21188cVGBqslvDl2TdN4//33Oe+889A0zeMYp02bRnl5ufHeS0tL48CBA6xYscLr4xGEQCAlM0EIIna7nblz53L66acb+gyAsWPH8uSTT/Lll18ydepUQJWALr744pCs64033uDJJ59ky5YtNDQ0GNf36tXL531lZWUxZcoU3n33Xf785z8DqlwWFRXFRRddZGz3pz/9iRkzZtC/f3+GDh3KWWedxbXXXsvw4cO9epwHHniACRMmYLFYyMrKYtCgQURFNf0Ia3wM27dvR9M0+vXr1+x+9W6pvXv3AjTZTm/zbw29/X/o0KFeHUtjQrFGd8aOHctf/vIXTCYTCQkJDBo0qNmuN2/eD94c+5EjRygrK+PFF1/kxRdfbHab4uJiAO6//36++OILTjrpJPr27cvUqVO56qqrOPXUU704MkHwHwmIBCGIfPXVVxw+fJi5c+cyd+7cJrfPmTPHCIjaS0uZCLvd7tER9NZbb3H99ddzwQUXcN9995GTk4PFYuGRRx4xdDm+csUVV3DDDTewZs0aRo4cybvvvsuUKVMMnQzAxIkT2blzJ//73/9YuHAhL7/8Mk8//TSzZ8/m5ptvbvMxhg0bxhlnnNHmdvHx8R5/OxwOTCYT8+fPb7YzKikpyYsjDC6hXmNWVpZfz6W/6Lqja665huuuu67ZbfTAeNCgQWzdupVPPvmEzz//nPfff5/nn3+eBx54oFnxviAECgmIBCGIzJkzh5ycHP75z382ue2DDz5g3rx5zJ49m/j4ePr06cOGDRta3V9r5Zf09PRmDf/27t3rkT1477336N27Nx988IHH/hqLon3hggsu4LbbbjPKZtu2bWPWrFlNtsvIyOCGG27ghhtuoKqqiokTJ/Lggw96FRD5S58+fdA0jV69etG/f/8WtysoKABUtkbvYAMlON69ezcjRoxo8b768+vv6xeKNQYLb449Ozub5ORk7Ha7V4FYYmIil19+OZdffjlWq5WLLrqIhx9+mFmzZhEXFxewtQuCO6IhEoQgUVtbywcffMC5557LJZdc0uTnrrvuorKyko8++ghQeo21a9c26xisObulEhMTAZoNfPr06cOyZcuwWq3GdZ988kmTtm09A6HvE2D58uUsXbrU72NNS0tj2rRpvPvuu8ydO5eYmBguuOACj22OHj3q8XdSUhJ9+/alvr7e78f1hosuugiLxcJDDz3kccygngN9XWPGjCE7O5vZs2d7PIevv/56m87S2dnZTJw4kVdffZV9+/Y1eQydll6/UKwxWHhz7BaLhYsvvpj333+/2cDpyJEjxuXG75OYmBgGDx6Mpmke5V1BCDSSIRKEIPHRRx9RWVnJ+eef3+ztJ598smHSePnll3Pffffx3nvvcemll3LjjTcyevRoSktL+eijj5g9ezYjRoygT58+pKWlMXv2bJKTk0lMTGTs2LH06tWLm2++mffee4+zzjqLyy67jJ07d/LWW2/Rp08fj8c999xz+eCDD7jwwguZPn06u3fvZvbs2QwePJiqqiq/j/fyyy/nmmuu4fnnn2fatGlNNCmDBw9m0qRJjB49moyMDFauXMl7773HXXfd5fdjekOfPn34y1/+wqxZs9izZw8XXHABycnJ7N69m3nz5nHrrbfyf//3f0RHR/OXv/yF2267jcmTJ3P55Zeze/duXnvtNa/0Oc8++yzjx49n1KhR3HrrrfTq1Ys9e/bw6aefGqNWRo8eDcDvfvc7rrjiCqKjoznvvPNCtsZg4c2xP/roo3z99deMHTuWW265hcGDB1NaWspPP/3EF198QWlpKQBTp04lLy+PU089ldzcXDZv3sw//vEPpk+fTnJyctiOUegEhKGzTRA6Beedd54WFxenVVdXt7jN9ddfr0VHRxutyEePHtXuuusurWvXrlpMTIzWrVs37brrrvNoVf7f//6nDR48WIuKimrS/vzkk09qXbt21WJjY7VTTz1VW7lyZZO2e4fDof31r3/VCgoKtNjYWO2EE07QPvnkE+26667TCgoKPNaHF233OhUVFVp8fLwGaG+99VaT2//yl79oJ510kpaWlqbFx8drAwcO1B5++GHNarW2ul+97f6///1vq9vpbfdHjhxp9vb3339fGz9+vJaYmKglJiZqAwcO1O68805t69atHts9//zzWq9evbTY2FhtzJgx2pIlS5o8h821nmuapm3YsEG78MILtbS0NC0uLk4bMGCA9oc//MFjmz//+c9a165dNbPZ3KQFP5BrbImCgoI27Q/043v88cdbvM2fYy8qKtLuvPNOrXv37lp0dLSWl5enTZkyRXvxxReNbf71r39pEydO1DIzM7XY2FitT58+2n333aeVl5e3eWyC0B5MmtYoPysIgiAIgtDJEA2RIAiCIAidHgmIBEEQBEHo9EhAJAiCIAhCp0cCIkEQBEEQOj0SEAmCIAiC0OmRgEgQBEEQhE6PGDN6gcPh4NChQyQnJwd06rggCIIgCMFD0zQqKyvJz8/HbG49ByQBkRccOnSI7t27h3sZgiAIgiD4wf79++nWrVur20hA5AW6Xfz+/ftJSUkJ82oEQRAEQfCGiooKunfv7tXYFwmIvEAvk6WkpEhAJAiCIAjHGd7IXURULQiCIAhCp0cCIkEQBEEQOj0SEAmCIAiC0OmRgEgQBEEQhE6PBESCIAiCIHR6JCASBEEQBKHTIwGRIAiCIAidHgmIBEEQBEHo9EhAJAiCIAhCp0cCIkEQBEEQOj0SEAmCIAiC0OmRgEgQBEEQhE6PBERCp6Wuwc5LS3ZxuLw23EsRBEEQwowEREKn5fUf9vDwZ5t57POt4V6KIAiCEGYkIBI6LSv3lAKw9kBZeBciCIIghB0JiIROiaZprN5XBsDukmpqrLbwLkgQBEEIKxIQCZ2S/aW1HK22AqBpsLWwMswrEgRBEMKJBERCp2T1/mMef286XBGmlQiCIAiRgAREQqdEL5eZTervzRIQCYIgdGokIBI6Jav3lwEweWAOAJsOSUAkCILQmQlrQPTCCy8wfPhwUlJSSElJYdy4ccyfP9+4vbCwkGuvvZa8vDwSExMZNWoU77//vsc+SktLufrqq0lJSSEtLY2bbrqJqqoqj23WrVvHhAkTiIuLo3v37jz22GMhOT4hMqlrsLPpUDkAV48tAGBLYSUOhxbOZQmCIAhhJKwBUbdu3Xj00UdZtWoVK1euZPLkycyYMYONGzcCMHPmTLZu3cpHH33E+vXrueiii7jssstYvXq1sY+rr76ajRs3smjRIj755BOWLFnCrbfeatxeUVHB1KlTKSgoYNWqVTz++OM8+OCDvPjiiyE/XiEy2Hiogga7RlZSDBP6ZRETZabGamdvaU24lyYIgiCECy3CSE9P115++WVN0zQtMTFRe/PNNz1uz8jI0F566SVN0zRt06ZNGqCtWLHCuH3+/PmayWTSDh48qGmapj3//PNaenq6Vl9fb2xz//33awMGDPB6TeXl5RqglZeX+31cQuTw0pKdWsH9n2g3va7eN+c9961WcP8n2qfrDoV5ZYIgCEIg8eX7O2I0RHa7nblz51JdXc24ceMAOOWUU3jnnXcoLS3F4XAwd+5c6urqmDRpEgBLly4lLS2NMWPGGPs544wzMJvNLF++3Nhm4sSJxMTEGNtMmzaNrVu3cuyYZ6eRTn19PRUVFR4/QsdB1w+d0CMNgEF5KYDoiARBEDozYQ+I1q9fT1JSErGxsdx+++3MmzePwYMHA/Duu+/S0NBAZmYmsbGx3HbbbcybN4++ffsCSmOUk5Pjsb+oqCgyMjIoLCw0tsnNzfXYRv9b36YxjzzyCKmpqcZP9+7dA3rMQnhZ4+ww0wOiwfkqIJJOM0EQhM5L2AOiAQMGsGbNGpYvX84dd9zBddddx6ZNmwD4wx/+QFlZGV988QUrV67kl7/8JZdddhnr168P6ppmzZpFeXm58bN///6gPp4QOooq6jhYVovZBMO7pQEwqIszQyQBkSAIQqclKtwLiImJMTI+o0ePZsWKFTzzzDP8+te/5h//+AcbNmxgyJAhAIwYMYJvv/2Wf/7zn8yePZu8vDyKi4s99mez2SgtLSUvLw+AvLw8ioqKPLbR/9a3aUxsbCyxsbEBPU4hMtD9h/rnJpMUq97+A7skA3C4vI5j1VbSE2NaursgBBWHQ8Osm2MJghBSwp4haozD4aC+vp6aGtXxYzZ7LtFiseBwOAAYN24cZWVlrFq1yrj9q6++wuFwMHbsWGObJUuW0NDQYGyzaNEiBgwYQHp6erAPR4gw1hj6IddrnxIXTfeMeEDKZkL4+H5HCcMeXMBfP9vslQXEjuIq/v7FNs586hsmPPYVxZV1IVilIHRcwpohmjVrFmeffTY9evSgsrKSt99+m8WLF7NgwQIGDhxI3759ue2223jiiSfIzMzkww8/NNrrAQYNGsRZZ53FLbfcwuzZs2loaOCuu+7iiiuuID8/H4CrrrqKhx56iJtuuon777+fDRs28Mwzz/D000+H89CFMLF6nxLSn9A9zeP6wV1S2F9ay6bDFZzSNysMKxM6O0t3HqXaaufFJbsorbby6EXDiLJ4nhBW1jXw72V7+WjNIbY0mr/31eZirjipRyiXLAgdirAGRMXFxcycOZPDhw+TmprK8OHDWbBgAWeeeSYAn332Gb/5zW8477zzqKqqom/fvrzxxhucc845xj7mzJnDXXfdxZQpUzCbzVx88cU8++yzxu2pqaksXLiQO++8k9GjR5OVlcUDDzzg4VUkdA5sdgfrDihDRl1QrTOoSwoLNhaJjkgIG5V1riz2e6sOUFnXwLNXnkBslAWHQ+PDNQd5ZP4WjlTWAxBlNjGhXxY2h8a320tYe6CcK04K1+oF4fgnrAHRK6+80urt/fr1a+JM3ZiMjAzefvvtVrcZPnw43377rc/rEzoWW4sqqW2wkxwbRZ/sJI/bBnfRO81k6r0QHirrbABM6JfF8l2lLNhYxE2vr+TuKf14dP5mfnLq33pmJnD7aX04a2geaQkxfL7hsAqInOVgQRD8I+yiakEIFbqgemSPtCbCVb3TbEdxJVabg5ioiJPXCR2cCmeG6JxhXbj9tD7c8uZKvttRwnc7SgBIiLHw88n9uHF8T2KjLMb99G7JrUWV1DXYiYu2NNm3IAhtI5/6QqdBD4ga64cAuqXHkxwXRYNdY0dxVZPbBSHYVDgzRClx0ZzaN4s5N48lNT4agBkj8/nqV5O4Y1Ifj2AIoEtqHNnJsdgdGhudM/oEQfAdyRAJnYbV+52C6h5NuwtNJhODuqTw4+5SNh2uMMwaBSFUVNSqDFFynPpYPqFHOl/88jTKa630zUlu8X4mk4kR3VL5YnMxa/eXM7ogIyTrFYSOhmSIhE7BZ+sPs+tINRaziZHNZIjAXUckwmoh9OgaIj0gAshOjm01GNLRy2ZrD5QFY2mC0CmQgEjo8ByprOd385S7+e2n9W7ReFEPiGSmmRAO9C6zFGeZzBdGOIN8vYtSEATfkYBI6NBomsasD9ZzrKaBQV1S+MWU/i1ua8w0K6xA09o2xhOEQOFwaFTWN80QecvwrqkA7C6pprymoY2tBUFoDgmIhA7Ne6sO8MXmIqItJp66bESr3WN9c5KwmE2U1TRwuFxcf4XQUW21ocfgKXG+Z4jSE2MoyEwAYN3BsgCuTBA6DxIQCR2Wg2W1/OljNSj43jP7G631LREXbaFLahyABERCSNH1QzEWs99t84aOSPyIBMEvJCASOiQOh8Z9/11LZb2NUT3SuG1iH6/ul+w8O3d3DRaEYKN7EPlTLtMZ0U2VzdaKjkgQ/EICIqFD8sHqg/yw8yjx0RaevGwkFi8niOtfSPoZuyCEAv395o+gWkcXVkuGSBD8QwIioUPyk3OI68xxBfTKSvT6fikSEAlhoLEHkT8MyU/BYjZRXFlPoZR8BcFnJCASOiR6p42uCfIWKZkJ4aA5DyJfSYiJol+OmtG3RrJEguAzEhAJHZKyWisAaQnNew61hJTMhHBgeBD50WHmzginsHqdGDQKgs9IQCR0SMqcGaLUBN++YPSAqKpeAiIhdFQEIEMEYtAoCO1BAiKhQ6IHRGk+ilT1klmFlMyEEFIRoAzRcKPTrAyHQ8xFBcEXJCASOiTlTpGqlMyE44GKWj1D1L6AaEBeMrFRZirrbOw5Wh2IpQlCp0ECIqHD0WB3GCUvfzNEIqoWQkllAHyIAKItZoY4R9DIoFdB8A0JiIQOh97CDL77uiTHSoZICD2B8CHScfkRiY5IEHxBAiKhw1Hm5unirSGjjpTMhHAQCKdqHek0EwT/kIBI6HAYgmofO8xASmZCeDAyRO3UEIEaUgywr7Sm3fsShM6EBERCh6Nc9yCK901QDZ4ZIk2TLh0hNARKQwTQNS0egJIqK3UN9nbvTxA6CxIQCR2O9mWI1BeSzaFR1+AI6LoEoSX0LrNAZIjSEqKJj7YAcFhGeAiC10hAJHQ49Jb7VD8EqokxUZicsiMpmwmhoMHuoNaZyUmJb3+GyGQykZ+mRtYcKqtt9/4EobMgAZHQ4TBcqv0IiMxmE0nOTrMKEVYLIcBdwK+/99pLvrNsdlACIkHwGgmIhA6Hy5TRv/JDigirhRCiv88SYyxEWQLzkazriCRDJAjeIwGR0OEoq/FfVA3Sei+EFtek+/brh3TyJSASBJ+RgEjocOg+RL4OdtWRAa9CKKmoDVyHmY4eEImoWhC8RwIiocPh72BXHfEiEkJJRQBdqnV0UbVoiATBeyQgEjocFX4OdtWRkpkQSgLpUq3jriESPy1B8A4JiIQOR1k72u7B9cUkXWZCKAiGhigvVWWI6hocHKuRTKcgeIMEREKHwuHQXKJqvzVEUjITQof+PksJYIYoNspCdnIsIMJqQfAWCYiEDkWV1YbDWSHwN0OUJBPvhRCiu1QHMkME4kUkCL4iAZHQoSh3lgfios3EOccX+EqKoSGSDJEQfIwMUQBcqt3pKm7VguATEhAJHQpXh5l/gmpwL5lJhkgIPsHQEAHkp4oXkSD4ggREQoeivS7VIF1mQmipCIKGCNzNGcWLSBC8QQIioUNRVqsE1e3xdBFRtRBK9MA7EJPu3RENkSD4hgREQoeivaaMIBkiIbQEw4cIZJ6ZIPiKBERCh0JKZsLxRmUQnKrB5VZdXFlPvc0e0H0LQkdEAiKhQ+HyIGq/qNpqd1DXIF8kQvDQNM0ozQY6Q5SRGENslPqILyqvD+i+BaEjIgGR0KHQS2b+ehCBy4cIZMCrEBgq6hr4dN3hJgF2XYODBrsyzgp0l5nJZDLKZqIjEoS2kYBI6FAEomRmMZvEnFEIKM9+sZ073/6Jt5bt9bhezw6ZTZAY459vVmvki45IELxGAiKhQ9HeOWY6yWLOKASQn/YdA2DT4QqP612C6mhMJlPAHzdfzBkFwWskIBI6FOUBMGYEEVYLgcPu0NhSWAnA3qM1HrdVGKaMgdUP6RgZonIJiAShLSQgEjoUug9Re0pmIF5EQuDYe7SaGqvduOxOsDyIdFxeRGLOKAhtIQGR0KEIhKgaXMLqCskQCe3EvUxWUmX1CLIraoPTYaYjXkSC4D0SEAkdhroGO/U2BxCIDJGUzITAsPGQp27IvWwWLA8iHXdRtaZpQXkMQegoSEAkdBj0DjP3LjF/kZKZECg2NQqI9riVzYLlQaTTJVWJqmusduP/QxCE5pGASOgwuJfL2tuxkyIZIiFA6CWz3lmJAOwpcQVErsGuwckQxUVbyEpSDQbiRSQIrSMBkdBhMFyqA1B+kLZ7IRAUV9ZxpLIekwmmDc0DYE9zJbMgZYhApt4LgrdIQCR0GAwPonbqh8C9ZCYZIsF/Nh9W7fa9shIZ1CUF8Ow0c4mqg5MhAshPFWG1IHiDBERCh6E8AJPudURULQQCXT80uEsKPTMTgBYyRPGhyBBJQCQIrSEBkdBhcI3taJ8pI4ioWggMun5ocH4KBZlKQ3Skst6YkVdpGDMGMUPkdKsWDZEgtI4EREKHQTdlbK8HEUiGSAgMmw6VAypDlBofTUaiCtb1sllFkLvMQLyIBMFbJCASOgyBMmUEt4BIpt0LflJjtbHL2VE2OF/phwqcZTPdiyjYTtUAXdNFVC0I3iABkdBhKAvApHudFCmZCe1kS2ElmgbZybHkJKuyVU9n2Wy3M1AKtlM1uDRERZV1NNgdQXscQTjekYBI6DAYouqAdJmpL6i6Bod8iQh+4S6o1tEDor1Hq3E4NKqswXWqBshMjCEmyoymQWG5ZIkEoSUkIBI6DMZg13ZOugc8nK5FRyT4g7ugWqdnlqvTrMpqQ5+mEcwMkclkEh2RIHiBBERCh6E8gD5EURYzCTEWQMpmweL7HSX87fMtHTYD11yGqMAtQ6SXy2KizMRGWYK6Fr3TbF9pTRtbCkLnJawB0QsvvMDw4cNJSUkhJSWFcePGMX/+fAD27NmDyWRq9ue///2vsY99+/Yxffp0EhISyMnJ4b777sNm8zyjX7x4MaNGjSI2Npa+ffvy+uuvh/IwhRBRFkAfInBliSRD1Dp2h8aKPaU+BTaapvF//13LC4t38uHqg0FcXXiwOzS2FDaTIXKKqosq6imqqAeCK6jWGZSn1rDuQHnQH0sQjlfCGhB169aNRx99lFWrVrFy5UomT57MjBkz2LhxI927d+fw4cMePw899BBJSUmcffbZANjtdqZPn47VauWHH37gjTfe4PXXX+eBBx4wHmP37t1Mnz6d008/nTVr1nDPPfdw8803s2DBgnAdthAEbHaHEbgEossMXGWMCskQtcr/1hzk0tlL+e0H672+z/qD5Rx26lm+2FwUrKWFjd0l1dQ1OIiPthi6IVAeWbrGbaOzJT+YYzt0RhWkA7B6/7GgP5YgHK+ENSA677zzOOecc+jXrx/9+/fn4YcfJikpiWXLlmGxWMjLy/P4mTdvHpdddhlJSUkALFy4kE2bNvHWW28xcuRIzj77bP785z/zz3/+E6tV6Ulmz55Nr169ePLJJxk0aBB33XUXl1xyCU8//XQ4D10IMBVuWZzABUQyvsMbNhxUmZD3fzrgMZaiNRZudAVBS7aVUNdgD8rawoWuHxrYJRmL2XPQsF4207M1wdQP6ZzQIw1Qo0RqrR3ruRaEQBExGiK73c7cuXOprq5m3LhxTW5ftWoVa9as4aabbjKuW7p0KcOGDSM3N9e4btq0aVRUVLBx40ZjmzPOOMNjX9OmTWPp0qUtrqW+vp6KigqPHyGy0Qe7JsdGEWUJzNtazBm9o7BCCXUdGryweKdX91m4qdC4XNtg5/sdJUFZW7hoTj+ko5fN1jsDomB2mOl0SY0nLyUOu0Nj3YGyoD+eIByPhD0gWr9+PUlJScTGxnL77bczb948Bg8e3GS7V155hUGDBnHKKacY1xUWFnoEQ4Dxd2FhYavbVFRUUFvbfMfFI488QmpqqvHTvXv3dh2jEHwCOdhVR7yIvOOwWyv3+z8daHNExO6SarYVVRFlNnHByHyg45XNmusw09EzRNuL1eDXUGSIAEYVpAGwen9ZSB5PEI43wh4QDRgwgDVr1rB8+XLuuOMOrrvuOjZt2uSxTW1tLW+//bZHdiiYzJo1i/LycuNn//79IXlcwX/KA2jKqCMZIu/QvW2yk2NpsGv865vWs0SLnNmhcX0yuWhUNwC+2FyMw6EFd6EhQtM0j5EdjenlbL3XDzcUomqAE7o7dUT7REckCM0R9oAoJiaGvn37Mnr0aB555BFGjBjBM88847HNe++9R01NDTNnzvS4Pi8vj6IizzNL/e+8vLxWt0lJSSE+Pr7ZNcXGxhqdb/qPENm4Jt2334NIxxUQSYaoJewOjeJK1S31u3MGATB3xX6KK1o2ANT1Q1MH53Jy70ySY6M4UlnPmg5SyjlSWU9JlRWzCQbmtZwh0glVhkjXEf20rwxN6xjBpyAEkrAHRI1xOBzU19d7XPfKK69w/vnnk52d7XH9uHHjWL9+PcXFxcZ1ixYtIiUlxSi7jRs3ji+//NLjfosWLWpWpyQcv+gaokAJqkFE1d5QUlWP3aFhMZs4b0Q+owvSsdocvLhkV7PbH6msZ5UzQ3HG4FxiosycNkD9X3+xqWOUzdYfVNmh3tlJxMc09Rfq2SQgCk2GaGjXVKLMJo5U1rdZ1hSEzkhYA6JZs2axZMkS9uzZw/r165k1axaLFy/m6quvNrbZsWMHS5Ys4eabb25y/6lTpzJ48GCuvfZa1q5dy4IFC/j973/PnXfeSWxsLAC33347u3bt4te//jVbtmzh+eef59133+Xee+8N2XEKwScYGiIZ8No2un4oJzkWi9nEXZP7AjBn+T6OVtU32f7LzUVoGozolkqXVJWhPXOw0vgt6mAB0fCuqc3enp4Q7dFqH4q2e4C4aAtDnJqm1fvKQvKYgnA8EdaAqLi4mJkzZzJgwACmTJnCihUrWLBgAWeeeaaxzauvvkq3bt2YOnVqk/tbLBY++eQTLBYL48aN45prrmHmzJn86U9/Mrbp1asXn376KYsWLWLEiBE8+eSTvPzyy0ybNi0kxyiEhkCbMoJkiLyhsFxlGvJSlRPypP7ZDO2aQm2DnVe/391k+4XOoGfqkDzjukkDcogym9heXMWeEs+2/e93lPCb99cZGcDjAb17bFi35gMik8lEzyxXlihUGSKAE3ooHdFPoiMShCaE5tSkBV555ZU2t/nrX//KX//61xZvLygo4LPPPmt1H5MmTWL16tU+r084fgiuqFo0RC2hZ4i6OAMik8nEXaf34/a3VvHGD3s5b0S+oaOpqrfxnbO9Xs8KgSpzju2dwfc7jvLF5iJuntAbgO+2l3Dj6yuw2h30z03mxvG9QnlofqNniIa1kCECpSNaF8K2e50TeqTx+g+SIRKE5og4DZEg+IMREAVFVC0ZopbQO8zyUlwNClMH5zK8WypV9TYufv4Hvt6iNH5Lth3BanPQMzOBfjlJHvs5Y5AKkPQM0qq9x7jlzZVYneNAthVVBv1YAkFRRR3FlfWYTc233OvoXkQQOlE1wChnhmjToQrqbWLQKAjuSEAkdAgMUbX4EIWUxhkiALPZxJs3nsTJvTOottq56Y0VvPb9bhZsVO32U4fkYTJ5ujfrGaOVe0r5YUcJN7z2I7UNdrKTlRbweAmI9HJZ35wkEmJaDnTchdWhDIi6pceTlRSD1e4wHMYFQVBIQCR0CMpqg6EhkgxRWxgZIreACNTMrjdvHMtlY7rh0OChjzfx8dpDgMogNaZbegKDuqTg0ODaV3+kos7GmIJ0Xrx2NADbi6qOi1ZxV7ksrdXtema5MkSh8iECVdIcKX5EgtAsEhAJHQLdhyiQGSJ92n2N1Y7Nh0nunYnCiqYZIp2YKDN/u3g4s84eiMmkjAizkmIMYW9jzhyUAyhvo8FdUnjl+hMZnJ+CxWyist5mPFYk4wqIWvcuc/ciCqWGCMSxWhBaQgIi4bhH0zS3DFEgNUSuL6oqab1vgqZpLWaIdEwmE7ed1ofZ14ymS2ocN0/o3WTYqc55I/KJtpjok53ImzedRGp8NLFRFkNvs62oKjgHEiA0TXMFRN3SWt02KymWWyf25sZTewXUO8sbDMfqvZIhEgR3wtplJgiBoKreht05ByGQXWYxUWZio8zU2xxU1tlISwhcsNURKK22GqLnnOTmAyKdaUPymObWat8c/XKT+ea+08lIjCEu2mVo2D83mZ1HqtleVMlp/bNb2UN4Kaqo54guqG5mZEdjfut09g41w7ulYjbBofI6CsvrWgxmBaGzIRki4bjnWLXKDsVFmz2+SAOBniWqEGF1E3RBdVZSLDFRgfkoyU+Lb/Ia9stNBiJfWK1nh/rnJjfrUB0pJMZGGVYIa/ZLlkgQdCQgEo57dG1JXkrgz3RTRFjdIoXNdJgFg/65qkU/0ktm652z2Ia24j8UKbjPNRMEQSEBkXDcc7iRW3IgkU6zljlc0bp+KFD0d2aIdhRHdqeZMbKjBYfqSEIXtkunmSC4kIBIOO5xZSri29jSd5LFi6hF9LEdwc4Q9cxMJNpioqrexqHyyOw0cxdUHw8ZotEFKiBau7+camkYEARAAiKhA3C4jU6n9qBniKTLrCnBfN7diYky08s5+ytSdUSFFXWUVFmxmE1eCarDTc/MBHpkJGC1O/h2e0m4lyMIEYEERMJxTzC1LFIya5miVjyIAo0urN4eoQGR7lDdLycp4ML+YGAymZji9H36aktRmFcjCJGBBETCcc/hIIqqpcusZQ43M8csWPTPUQHR1sLIFFZ7M9A10tDnx3215QgOR+RqswQhVEhAJBz3FIqoOuS4mzKGIkOkd5ptL47QDNFxJKjWObFnBsmxUZRU1bPW2SEnCJ0ZCYg6EXaH1uEyHQ12B8WV9UCwAiJdVC0BkTsVdTZqrGpaeiiM/Vwls6qIy2ZommaUzI4HQbVOTJSZiQOU0eWXm4vDvBpBCD8SEHUifv/hBsb85QvWdKAZRkcq69E0iDKbyEqMDfj+XRmijhVIthc9O5SWEB0SzUzPzARiLGZqG+wcLKsN+uP5wuHyOo5WW4kymxh0HAiq3TnDqSP6YrPoiARBAqJOgqZpLNpUiNXm4KVvd4V7OQFD17HkpsRhbmFGVntIdg54rZIMkQeG91MQdFvNEWUx0zs7MjvN1umC6tzk40JQ7c6k/jmYTbClsJIDx2rCvRxBCCsSEHUSiivrKamyArBgQyHFlZHp5+Irwe50SnAGRNXO8pCgCKV+SMc1wiOyhNUbdP3QcVQu00lPjGFMQQYAX22RspnQuZGAqJOgf2gD2Bwa7/y4P4yrCRzB9sJJilVn/DVWyRC543reg99hpjNAF1ZHWIZo0+EKAIZ2Pb7KZTpTjLKZBESdBU3TKKmqD/cyIg4JiDoJGw6qD+2MRDWx/e0f92FzTio/ngm2W3JCjDNDJMaMHoQ1QxRhnWZ7j1YD0Ds7Kcwr8Q89IFq286gYkHYSnl60jTF/+YJFm0Q75o4ERJ2EDYdUhuiWCb3JSIzhcHldh0iRBztTkWgERFIyc6cwRHPM3HGfaRYpnWYOh8b+Yyoo75GREObV+Eef7CQKMpVr9Xfbj4R7OUKQOVJZz4tOHenCjYVhXk1kIQFRJ2HTIZUhGtUjjcvGdAfg38v2Bu3xNE1j2a6jQc+sBDtTkegsmdU22LFHyJdwJBCODFGPjARio8zUNTjYHyEC4KLKOqw2B1FmU0ifi0BiMpmYMlCZNEr7fcfnle92U9egqgPiP+WJBESdgNJqq9GqPDg/havH9sBkgm+3l7C7pDooj/mfH/dzxYvLeGLh1qDsXyfYGqJEp6gaVFAkKELdZQZgMZvo4yxLRYqweu9RFZh1TY8nynL8fpzq7fdfby2OmOybEHjKaxp4y+1EeHtxlZRJ3Th+/4MFr9noLJf1zEwgOS6a7hkJnD5AfQC+vTw4WaL3VinR9o+7S4Oyf1DlimB3mcVGmdG7+UVHpKiut1HhtCEIZckMXI7VkdJ6v69UBUTHa7lM58ReGSTHRVFSZWWNZA06LK//sIeqehsD85LJT41D01xz+AQJiDoFG53lsiFubcHXnNwDgHdXHqDOx8yH3aFx4FgNmtb8meTBslp+2lcGqDOQ1sTbVpv/wu6S6npsDg2zCbKTAm/KCKqcoGeJJCBS6PqhpNgow8k7VETakNf9HSQgiraYmdAvC4Dlu4J3EiOEj6p6G69+vxuAn53el5E90gApm7kjAVEnQG+5H5rvCohO659Dt/R4ymsb+HjtoTb34XBoLN91lD98uIGxf/2C8X/7mte+39PstvPXHzYuW20O9hxtXu+xvaiS4Q8t4JHPNvtwNC50HUt2cmxQyxW6sLpGvIgA1/Me6uwQuITVWyOsZFaQeXwHROAa0tvRxvsIijnL9lJe20CvrESmD+vC8G5pAKztQJML2osERJ0APUPk7pNiMZu4emwBAP/5cV+r93/uy+2Me/RLLn9xGf9ettcweJz9zc5mMzwfrzvs8ffWwubP5r/YXExdg4Nlu456fzBuhMoLJ8EprJZau+JwGATVOgPzVEC0s7jK58xmMOgoJTOAhBhnA4EE/h2OugY7L32rskN3TOqDxWxihARETZCAqINTWddgCKeH5Hs66V5wQj4Aa/aXtfhlv6O4iicXbaOoop7kuCguGd2N164/kdyUWIor6/lknWd2aX9pDWv3l2E2wZSBSqe0tbCi2X3rmSt/B6ca+qEgC3tdGSIJiMDl/RRKQbVOt/R4clNisdodrHaWZcOJKyBKDPNK2k98jJiQdlTeXbmfkqp6uqbFc+EJXQEY1i0VkwkOldd1mMkF7UUCog7O5sMqO5OfGmeYMup0SY2na1o8Dq3ls4SVe5SeYFSPNFb+/gyeuHQEpw/MYea4noBq4XTXEn3mLJed3DuTU/sqTcKWFjJE6w6qx6zwMyAKdoeZjt56L15EisIgC9lbw2QycXLvTAC/M4uBorKugdJqlS3tnhE6x+5247DDnu9g4e9h44fG1fHRekAk7/PjnboGO5sOVfC/NQd5YsFWnv1yBwC3n9abaKe8ICk2in45qklh3X4RVgNEtb2JcDyjZ2GGtDBnaXRBOgfLalm555gRwLizYs8xAE7tm0VslGtw5ZUn9eDZL7ez8VAFP+4uZazzS+pTZ0A0fXgXemWqs+atzQhgy2qs7C9VmQZ/J8mHygsnUdyqPSgMw9gOd8b2yuR/aw6FPSDSs0MZiTEhF5f7jKbBvmWw8QPY9D+ocjoUW2Kh35kQk2iUzCKhFCn4zyvf7eavn21u4puWmxLLpU4POp0R3dLYVlTF2gNlnDE4N5TLjEgkQ9TB0R2qh+Y3HxCN6ZkOwKp9x5q9feXeUud2GR7XZyTGcNGoboD6BwQ1wmDdgXLMJjhrSB4DnHqPfaU1TdLw691mq9XbHH51mxleOEEOiGTAqyfh1BABnNxbvRdX7y8L65f3cdVh9vEv4LWz4McXVTAUlwaxKWCvh93fAu4lM3mfH898su4QdodGSlwUYwrSufKkHjxw7mDevW0ccdEWj21HdE8DlGxCkICow6M7VA/Jb37w5KgeKiBavfdYkzOK4oo69h6twWxSJbPG3DS+JwCLNhex72iNkR06pU8WmUmxZCbFkpUUi6Y1NdJzD4jAvyyRK0MU3EyFMeBVMkSA63nPDYOGCKBXViI5ybFYbY6wfpAHXFC99h14vB+seTsw+9PZ8hn89AaYzDDiSrjqv/B/22HYper27QsB19w+CYiOb45UqqGtr91wEu/dcQqPXDSMG8f3oiCzqc5tpDMgWru/rEUblc6EBEQdmLoGO9uLVSAytIWS2cC8ZBJjLFTW25qY3a3ce8y5TUqzJYG+Ocmc1j8bTYPXftjNp87usnOHdzG2GZCnatSNhdWNzcB8FVZrmhayTIX+RVElYlNqrXaOOnUz4coQmUwmo0QbzrJZQFvu1/wH5t0G1cWw8A9gDZCDfE0pfHKPunzKz+HC2dB/KkTFQL+p6vrti0DTpMusA6BpmhEQ5SS37c02IC+ZmCgzFXW2Fu1ROhMSEHVgthRWYndoZCXFkJvS/D9HlMXMCc4s0aq9nmWzFU5B9YnOslpz3Di+FwBvL9/HxkMVWMwmpg3JM24fkJtirMWdphki34KNspoG6p1ltpwWji1QJOqlBB9F1R3xjEvvWEyNjyYtIXy6Gb1sFk4TQT1D1L29GaK1c+HDOwANzNFQUwI/vtT+BQJ8PkuVyLL6w6Tfet7Wa6LSEJXvgyNbXSWzhnYG/rVlMP9+WPeu0i4JIaOy3mZ8LmZ5YVYbbTEz1Fk9kPZ7CYg6NIagOj8Vk8nU4najCpoPiFY6BdWN9UPuTOyXRb+cJOOf8NS+WaS7dbPpvjHuXkTHqq0ccE4I1wM1X0tmenYoKynGQ+wdDAynah8yRP9etpcxf/nCeA06CrtKVMaxd3Ziq+8pr3A4oK55S4a20DvNftp3LGw6Ij0gKmhPQLR2Lsy7HdBgzI1w3jPq+u+fgfp2unFvnQ/r5qpS2YznIbpRRi8mAXpNUJe3LwxchujbJ2H5bPjgFnjtbCjc0L79CV6jZ4eSY6OMALctREfkQgKiDszGNvRDOmOaCYiq6m3GDLQxrWSITCaTkSUCz3IZYAir3QMiPTvUMzOB/DTdHde3s9LCitAIqsElqvYlQ/T5hsMcrbaydGd4O6ECza4jKkOkD1n1m9pj8Oo0eLwPHPF9AHDvrESykmKptznCcmZrszs46Azqe/hbMlv7jisYGn0DnPMkDL8cMvpAbakSQHtD8WaVUTq8TgWZoJ7fj+9Rl8fdBd1PbP6+RtlsYWDa7q018NOb6rI5CvYthX9NVJmquiCdHGiaZKKc6AFRthflMh1dR7RORnhIQNSR0QOalvRDOiN7pGEyqTNe3aBrzb4yHJoywmtLtHzhCV3pmhZPRmIM0wbnedzWPzcZkwmOVluNf1Y9IBraNdXQJvmbIQqFOaBeMvMlQ6QLj0trrEFZU7jYdcSVIfKb6qPwxvlw4EewW2HD+z7vQvkROctmQRwg3BKHy+uwOTRioszkJvvxHtz8CXzoFgxNfwrMZrBEwaTfqG2+f7btDFp9Fbx5AXz2f/CvCfBEP3jvRvVTVQiZ/eD037Z8/75nqN/7lpKgqYxXbYPd/3Lv+v9CXRmk9YCf/wSDZ4Bmh2XPw/PjoLLIv/22RGWhOu5/TYSy/YHd93GI/hmb5UNApDtWbzhUQUMrcyc7AxIQdVAa7A62OE0ZW2q510mJi2aAc0bUT84skUs/1HK5TCcu2sKnd49n0b0TSW2kK4mPsRglBT1LpAuqh3dLJTlOZV981RCFcp6WP8NdiyrUB9Ox6g4WEDk1RL2z/MwQVR2BN86DwnWqlAOw7XO/dhVOYbWhH0qPx2z2sXS4e4kKWDQHnHCNKxjSGXqx0vzUlcHyf7W+r+//rgKfuFSITlT6ow3vw86vABNc8DxEt3JCk9kHMvuCw0bSoe8AlWyp92fosqa5slon3gLpBXDZm3DNB5DaHSoOqm63QFF7DP59IRSuV++n186GozsDt//jEH8yRAWZCaTGR2O1OVocs9RZkICog7LuQBlWu4PkuCivXHRHO8tmum7I5T/UcrnMnbSEGDJbEPHpZbMtzk4z9wxRSjsDomC33IPvw10r6xqMUSilHSgg0jTNrWTmR4aoshBenw7FGyEpD677WF1/eK26zUfGOTNEq/Yeo94WWh2R3y33h1bDf65S/j8Dz4Vzn/EMhgDMFjjtfnV56XNKpNwc5Qfgh+fU5fP/AffvgRvmq/v2mghn/w26n9T2mpxls9jdXxpX+VU227cUijZAVLwK9HT6ToHTf6cur5njKuu1B2s1vH05FG9S76XMvlC+XwVFRZvav//jlCNVzoDIC0G1jslkEh2REwmIOiD/W3OQ615dAcBJPTO8Er+6GzQ2uM2J8iZD1BYD8pSGaWthJaXVVg6WKe1Fe0pm+viIUJTMfB3uqs9YAzjWgUpmxZX1VNXbMJv80M2UH4DXzoGSrZDSFW74DHqOh/xR6nanF44v9MlOIisphnqbg3UHQited7Xc+xAYlmyHty4GayX0nAAXv6JKZM0x5ELIHqh0N8tnN7/NFw+BrQ4KxsOg81QrfcEpqkR23ccw9jbv1tXvTADM2xcRG6U+K/yaZ6Zns4ZfBgmNPjcGnw8xyXBsD+z7wfd9u2OzwrszYf9ylRm79gMVCOYOVR11r5+jAs9OiD8ZIoAR3VQVobN3mklA1IGosdr49Xtr+cXcNVTV2zixZzoPXzjMq/uOKVAfYBsOlrN6Xxk1Vjup8dH0ba94FrdOs6JKIzvUKyuRlLhokmP9yxCF0i05Kda3DFFheb1xuSNliHY69UPdMxJ86+w7uhNePQtKd0JqDxUMZfZRt/Wfpn5vW+DzekwmE2N7OctmIRav7/e15b5sv9L61ByFLiPhirebdn25Y7a4tERL/wn7V3jefmAVrH8XMMG0h6E9HX8Fp6pyW1UhI6OVDsfnTrPyg7DZmfFrLhCLSYQhF6jLq+f4t06HQwWIH94OO75Qmair/gu5QyApRwWB+aNUKe2N8+HgT/49znGM/wFRGgBrO7mwWgKiDsK2okrOe+473l15AJMJ7p7Sj//ccrLXGptu6fFkJ8fSYNd41TmKY0xBuu/6iGbQS2bbiiqNM5BhTqG3riHyNvuiE0oNkd6O7K2GSB8pAnCsxr85bZGIXi7rneVDVqRwgwqGyverssYNn0F6T9ftepfTrsVgq29uD62iC6uX7Q5tQLS3VD0XXrXc71sOL02GigPqObjmfYhrvfMTgEEzoOsYqK9QpaAVL7s6qhbMUtuMvAryR/p/IABRsdB7EgCTLWsAP0pmK19V4umC8SpAaQ69jLbpQ+8sBWxWmHs1PD0MHukBf8qAR3sojZQ5Gi5/C3qMdW2fkAEz/6cCvPoKWPSAb8fQAfA7IHKWzLYXV/mXHewgSEAUYfy4u5Qzn/qGJduO+HS/X767hp1HqslNiWXOzWP55Zn9ibJ4//KaTCaj/X7BJqXnaM1/yBd6ZiYSG2WmrsFhuFm7AiJVMqvwoWTmrtEJiajaqSGqtzmwedGF4V4yK6uxNhmJcrxiBETeZg0PrFSaoepiyB2myhppnsMl6TISEnPAWgV7fS+l6MLqVXuP+TUPz1/2OUtmbZYOV73ueg5yhsC1H0Ji0yHKzWI2w7XzYND54GiAT3+l2vTXzFHlougEmPyHdh2HgbNsdqpDZVV8Coga6tRxApx0S8vbdR+rAsKGGtj4Ydv73b4AtnyijCPrywHn/1F8Blz8EvQ7o+l94lLgopfAZIE93yorguMQTdNYsLGQy/+1lIUbvdfX+aMhAhVA6WOWtjcas9SZkIAowvhs/WG2F1cx64P1XhvO2R2a0VE299ZxnNLHyw/cRujCar3jtjWHal+wmE30y3WO8HCOBxnWzTND5EvJTM8OpcZHG2M1gomuIQLvBrwWugVEDg0qajtGlkg3ZfTKg2j3t6psUVcG3U6C6z9WZY3GmM0eXji+0i8niYzEGOoaHCHzUSmvaTB8s7qntxAQ2azwyS/VUFVHg2o/v2lh04CwLeJSVKfWmX9WXXnr5sL/7lS3nXoPpHRp9e5e4wyIBjm2kUYltb64VW+cp7rbUroqoXhLmEwqowUqqGtzvx+q3ydcA3ethF9tg98Vwf27lcaqJVK7uspzy17w5ggiiv2lNdz0xkpu+/cqlu8u5Y2le7y6n92hcbTK+7EdjRnYqPmlMyIBUYRR7vzyPFhWy7+X7vXqPkUVyhMlymxq16BJPSACiIkyG0FLINBHeOjoZpH+iKpDPW09NspCtMV7sakesOkcV15E2xepzE4zuDJEbZTM7A2qrbyhGnqdprIc8a0E1/2dAZGfOiK9bPbjntD4Eenlspzk2ObdgG318NZFsPIVwASTfw+XvgGxfurxTCY49W6Y+REkZqvrUrqq2WSBIrUb5AzBgoPTzWu8zxDZ6mHpP9TlMTe2LBLXGXGlCuz2LW29Rb6hzmXHMOp6yOoHybmt667cOfln6veG9wLvfRQk6m12/vHVds546hu+2lJsXK+7+rdFabUVh6beLhlu0wK8xdUN3Hlb7yUgijDK3bIJ//h6B+VeaFD0rq38tHgs7dD8DMlPJTZKvSVGdEsN6EgM/ewD1BeqHgi1J0MUinKZjp6J8kZH5J4hguPIi+jAKphzicrsNGr1rrfZOXBMlYnaDIh2LVYlosRsuOrdtgOB3qcrTUjpTr98ZAY6uxj3lARoIKob767Yz02vr6DY7TVts+V+6T9UuSYmGa78D0y8r32iZ51eE+C2JSozdOV/1OiNQDL4fAB+EfUBdbVeDPrUNPjo56rVPi4VRl/f9n1S8qHPZHW5tSzRzi9VGTWlG3Qb0/Z+G9NtDHQ7URl/rnzV9/uHgRteW8ETC7dRb3Mwrncm/75JWSYcKqv1quyu64cyE2N8kkvoNDdVoLMhAVGEoQdEFrOJ8toGnl+8o8376F9UXdPa58kTE2U2ug0CpR/SGeAWEA1zc85OMTJE3gdEoc4QgZtbtRfjO/Qus7ho9e913HSaffeU+t1QrWZsubH3aA0OTc1IalOfsP6/6veQi7w7o49LUe3i4FeWSJ82rwcqfmOtge/+DiteUVmyhlpe/HYXX24p5hdz1xhfSntb0w+V7YclT6jL05+AAWe3b02NScmHMx+CLiMCu1+AcXdSZsmkp7mIvttebnv7JY/DuneUXufSN7zXRo28Wv1e8x9wtPD/pJfLBs/wP5g8+Q71e+UrKuMU4ax0muL+9cJhvH3LWE7pk0W0xUSDXWtyktUcun7Im6GuzTEozzWIuyMOpvYGCYgiDD0gusk5H+y1H/YYGaCW0GcqdUtvv0nhz07vw7jemVw9tke79+XOwBYCIj1DVNtg99o23phjlhJ8U0Ydbwe8Wm0OSpwfTLr/0nHhRXRkqxKw6qx81WM+1M5iL4e6WqvVWAqAYZd6//h6+/123wMivfVdFzr7habBR3fBF3+ET38JL0+Bv3ZldsWd/CHq36zedYjnv1YnJ/tbyxAt/J0SDfcYp+aSHU/EJvNRnirDDd39CpTuannbDe/D1w+ry9OfhD6ne/84A86BuDSoPAS7vm56e0OdGkwLKiDyl0Hnq9Ji9RG/xsOEEk3TjKaAqUNyMZlMWMwmY9bjAS+CfX87zHT65SZhNqkTOD246mxIQBRh6AHRjJH5nNw7A6vNwZMLWx9+qdeYuwYgIJo0IIf/3Hoy3VoSi/qJ3sUArhZPgKQ4l+agysss0ZFKq7HPUOHtgFd9FlyMxWy4OZdWHwei6u+fVb97T1KeNCVbYc93xs3GyI62BNVb56sMU3pP30od/ZwB0Z7vfZ7yrgcmhyvq/HesXvaCs507Sj0HCVmg2enLfm6Kms+vo97h6S+28ePuUjdTxkb/Izu/gk3/UxmTc54ITJksxGzPOoNv7UOJclhh/v3ND03dvwLmObMv4+6CMTf49iDRca5geeVrTW/f+ZUyr0zOV2Uvf7FEu7relr0Q0QNg3Uel6LIFcIn293uhI2pvQBQXbaGn02i0s5bNJCCKMPSAKDU+mllnDwJg3uqDbDrUsvJfzyAFOogJJCaTiScvG8Hvpw8y2vsBoi1mY8q2t2WzCrfnKFR4O+BVb7nPSYkl0ylsjPgMUfkBVfoAOP33ymkYnKJghW7K2KYHkV4uG3apbwFBVl/I6K06snY2kzVohczEGBJjLGiaK1vaLC19Ie75Hhb+Xl2e+hflZXPfDsrvWMdvG24C4PqoBYxiC7+Yu5rtzmyZR4bIZoXPfq0un3QL5A316RgihYTYKP5oux67KUp1/W351HODfcth7pVq9MiAc+DMP/n3QKOvB0wqK7mtUXfhpg/V78Ezmo418ZVR1ykDx6L1HgF+pOEZELm0m3rWf38IMkQgOiIJiCKIuga7kTZNjY9mRPc0zhuRj6bBI/M3t3g/I0PUTg1RsDmtfzY3T+jdpOSil8289SIqD0dAZAx4bT0D4a5vSncGRBGvIVr6vApEek6A7ifCiSoIYPPHRoeOVx5ENaXKQRh8K5fp9POvbGYymYyy2d6Wvjg2fwKPdFPzr9zHOlQchv9er0wFh10KY2/Xd8pRcyZv26fwgXY6ZjSejnuZY+XlRknUw6V62T/h6HYlJJ80y6f1RxJx0RZ2afksyXa2x8+/X5VBdy9RQ3lfnapKUHnDlN+P2c/Gi7yhrk6wj+92ifht9a5ymd463x4SMmDklepyay34mqaC4hcnKafrEOOe2dQ7WsH1HvOm08xfDyJ3OnunmQREEYS7oFofF3Hf1AFYzCa+3V7CoWa0RA6H5pYhiuyAqCV87TQLS0DkzBC11Xavd8DlpsSRkeDMEFVb1QfuundVB1a4aE7AWlPqMtUbf4/6nTdMeQc5bLD6TedQV5eGqEU2fajukzcMsgf4vj5dR7TpI7UuH9CzNc2eSVcdUd1Q1irVyv3iJPjPlUo4/e5Ml2niec94ZLX0zN7LCTdBcj7dtUPcF/0eAPHRFtcXT/lB+OZxdfnMP0N8mk9rjyR0V/bP069WY1YqDsBzY1QwtHuJKimecC1cM89/GwGdyb+HjD5QeRgWOIe/7vxKuUwn56v3YCDQg9ytn8Gub5rfZu1/1KDcQ6uV9USI0U+EY6PMHieMRobomDcZIvXZ054M0UBDWN05vYgkIIog9C/6lLgo45+iR2aCUabYVtQ0ai+pqsdqc2A2hbYNPZD46kUUjoBI1xBV1duU4PjfF8Had1SpxI0it6GzRoaoxgrfPgEf3AJzLvNrsnu72f4FPN4HXjhVdfDoE8d/fElpfvKGQZ8pru31LNGqNzhaWUtFnQ2TSc2ga5F1ernsMv/W2Os0NaCzvgJ+eNanuxqdZs0Jq+f/GmpLVdAz/Arlg7P1MyWcPvAjxKbC5f9W87bc0LVf0UkZKlgCbrR8xijTNgZ1ScakB7mvna2ew+4nw4gr/DjwyEEPiMpt0XD239SVlYfAEgsn3gx3r4EZ/4Ck7PY/WEwCXPA8YII1b6nS2ab/qdsGn9/+cplO9gBnZ5sG/71ODZh1p2QHfPp/rr9b8OEKJvVuAZE7ugwiFKJqcDW/bC+q6jAO+74gAVEEYQREjb7o++aoM7EdxU0t1Q84s0NdUuOJ9sN7IhLwJUNktTmodTp4hzIg0jN2XYu+hk/uVT4p826FZ4bDt08aGY3CCvWhlJcaZ5ijnVr2MXz1F7Uje71rKnioWPkavH2ZKgUUbVBfCrPHw/r3XJPUT73HU/Mz+AI1IqF8P6VrVNdY17R44qJbKJGU7XdOMTfB0Iv9W6fZDKc7MwXL/wVVxa1v70aPlkpmWz6FjR8oofMFz8NF/4I7f3QGbSb1c9GLrmGzbuj+URkJ0co8csSVmNB4K+tNXjzxsHoOP7gFyvZCUl6TDNPxSLzTb6umwQ4Dz4Fpf4UJ/we/WKu6yXx12m6LHid7ls62fKYuD74gsI8z/UnIP0H9D/znKqh3fpba6uG9G1RAq5uHHgxDQNTgDIga/X91z1AZosKKujZH0+gBkT8u1To9MhKIj7ZQb3Ow52jgfb0inePzG7SDopswNv6i7+cMiHRhqzvHi36oNVwBUdsZIj1oNJlc9wsFCTEW+poOcP7OP6orek9SX4KVh+HLP8FTg+Gz+2go3QeogCg9IYazzD9yr3W26z6gfG587KTyC4cDFv0RPrlHaWRGXAmn/QZiU6B4I7x/k8qcpPds+gUUHWcM40xa/4Zafmv6oQ2qlETP8Wp0gr8MOBu6jlat698+5fXdujdXMqstU+MzQDk960NQs/qpWVh3/wS3fwcDzmp2n7rDuJ7p46xHICmPhMpdZH16k3oOY1NhygNqXzkDfTnSiETPENXpTtXj7oQpfwjciJDmcC+d1Zer/6vuY9u+ny9Ex8Plc9TcvOKN8OEd6v/jiwehcJ0K/q/4j9q2cL1fg4bbg64hapwhyk6KJTbKjEPzHBrdmLoGuzFOJjvJ/0qB2Wyivz5mqRPqiCQgiiBaKgX1cQZEzQ3dC6QHUbhIjvXenFF/jpJjozC3w5XbV9JNNbwU/SSxjlolPr76PbhnPVz4L8gbDrZa+PFFnjtyIw9HvUIPUwk5Jct5JvofWNCwj7oervkAMvupD/1VbwR3wQ118P6N8P3f1d+TfgsXvACnz4J71sHEXysnZVAZAOfIhbIaq8uN29lO3eXI9/QwFbXeYbbeGRANu6R96zY5R12A6nIrP9B0G33iuxsFznbhfaU1LlO5hb+DqkL1nJ/2m6b7yejdajeYriHStWDEp8N5fwdMEBWnsmq/WAMTftWk3Ha8oo8iqfFllll7iUmAGf9EZewIbLnMndSucMUcsMTA5o/g3Wth2fPqtgteUNmqhEzlbl24PvCP3wotlcxMJpNbp1nLAZEu9I+xmEmJb9+JoiGsPtz5dEShO8UW2kTvsmqxZHakCk3TPER3hkv18RwQ6RkiL8ZiGEFjQujKZTjsnLn5t+SbiyiJyiXr0teVxwkozcjwy2H3ErQljxG95zuujvoSbd43YI7GZLLxmf0kTjztEbLNFjV/6uO71Qfx2Ntc+wk0H96uhm6ao+H851ydNqC+2Cf/Dsb9TJnvdR0NKP3N9Oe+JTU+mg9+dgo5Gb2hzxRMO7/kfzF/YFfVrdDQW51t62iaEqEWbVCPNej89q+99+lQcCrs/V65ITv1O4DqYvvkXtX9ltpVzeBK7U6PpHyusZRQbEujbFsy6Q1FsPotwKQ0L97OwHJDL5mlu8+FGnA2/Gyp+uJsbljtcU5CtN484Kefk78UjFOB8MpXlVYpWHQ/CaY/pUw4dSPSsbe7soRdx6guxwMr/RsZ4ieugKhpSbp7RgI7j1Qbn/XN4a4fatU41QsGuDlWdzbCmiF64YUXGD58OCkpKaSkpDBu3Djmz5/vsc3SpUuZPHkyiYmJpKSkMHHiRGprXZFyaWkpV199NSkpKaSlpXHTTTdRVeWZSVm3bh0TJkwgLi6O7t2789hjj4Xk+HylxQxRdhImE5TVNHC0UQu33mEW0pJZTSmseDlg4mBfRNXh8CDiyz+RX/I9tVoMT2X8semIApMJep9G6SUfcGn9AyyxD8PksGGy1bKcodzTcCfH6pxfMMMvh6RcqDgYPPfcwg0qGDKZ4Zr3PIMhd+LTjWBI0zR+9+F6KutsHDhWy23/XkVdgx3OepQ95u6km6oYve0peG40/PSm6sZZ9AD8fTi87Wyx7z9NtTm3F/cs0eq3VNDWUKt8ft66GMr2KS1W6S7V+bRmDpbvHucv0a/xYszTpP/nHKULATjpVnXm7we6qDo9IcbzhpxBHTIYAtfMvtpQB0QAE/8PfrnJvw5FXxh1LZx0m7qcN8zTS0kPgkKsI6p36iJjo5t+JbvMGdsOiLICYFY7SPciaqaJJ1hYbQ52l1Qbma5wEdYMUbdu3Xj00Ufp168fmqbxxhtvMGPGDFavXs2QIUNYunQpZ511FrNmzeK5554jKiqKtWvXYnZLp1599dUcPnyYRYsW0dDQwA033MCtt97K22+/DUBFRQVTp07ljDPOYPbs2axfv54bb7yRtLQ0br311nAderO0FBDFRVvonp7AvtIadhRXecyqOWCUzEJoyvjdU6pF9auH1dn3wOnt2p3Lh8iHDFEoAqJDq2Hx32CbCtJ/3XAr+7WeLW5eWFHHCm0gv4z9IyuvS4WDq3jou55Y6xwuL6LoOHVG+uVD8P0zKkAKtBD3u6fV78EzXLqlNvhwzUG+3V5CTJSZuCgzq/eVMeuD9fzt4uGcWfcoM0xL+FvGJ1gqDqoWdndikpRJ37SHA3cMBaeorredX6oOoIqDcGSLuu2kW9VzWHlYtbyX74eKg6zYsIWommIGJFaTYD2qvlinPOD3EoySWWIIg+8wEx+jPltDniEKNWc9qkTjXUdDlFsQ4TxBCHWnWUslM8CrklkgPIh09JLZvtIaqutthgdbMNl7tJozn15CekI0qx+YGvTHa4mwBkTnnXeex98PP/wwL7zwAsuWLWPIkCHce++93H333fzmN676/4ABrrOHzZs38/nnn7NixQrGjFGR/XPPPcc555zDE088QX5+PnPmzMFqtfLqq68SExPDkCFDWLNmDU899dRxExCBKpvtK61he3EVJ/fOBNRZ/cEAju3wmj3fq9+1pTD3Khh9g/oy9FNH4UuXWUgCooM/wTd/U541ACYz+4b/go+Xn0i/Vsp6Rst9apxKzXc/iYTVP0DJMc+J92NuVJ1pxZtUCajfmYFbe+ku1VUFMP5e7+5SbeXPnyjjz19M6cfI7mnMfPVH5q0+SJTZRIPDxGcxk3n87odUSWPJE0r03H+a6ijrN9WzjBYoJv9eBUQ7v1R/J+aoTjH9+WrUGfZe3TreWbmfeyf25xdT+rY70DRKZo0zRB2Y+HBmiEKJ2dz8yYIeEB3bDdVHITEzJMtpq2QG3mWIAjHOKDNJjVkqqapnW1ElJ/RIb/tO7USXS+jVgnARMaJqu93O3Llzqa6uZty4cRQXF7N8+XJycnI45ZRTyM3N5bTTTuO771z260uXLiUtLc0IhgDOOOMMzGYzy5cvN7aZOHEiMTGuD7Vp06axdetWjh1r3pG0vr6eiooKj59Q0Fo5SNcR7XRrvS+tthot6PlpIfIgstaorgxQBm2YYNVr8K+Jng7APuBLySyoAZHDDv+7E146XQVDJrPqzLpzBcfG3AO0fuasu1TnpbheCw8vIp34NOfoAlSWKJB8/yxoDuh7htcT0f/y6SZKq60MyE3m1om9ObVvFg+ePwSA/65SouZeWYmYouNV19F9O+E3++GyN1UWKhjBEEDXUTDUKdIeMF1pd1oJHnu4T70PQNat1MgQdZ6ASNcQWe0ObF4OW+5QxKcpET7AoZ9C9rAtdZmBq2TWmlt1IAMicPkRharTTJ9jmRSCbFRrhD0gWr9+PUlJScTGxnL77bczb948Bg8ezK5datLygw8+yC233MLnn3/OqFGjmDJlCtu3bwegsLCQnBzPWn5UVBQZGRkUFhYa2+Tm5npso/+tb9OYRx55hNTUVOOne/cAe2+0QKsZouymXkS6fignObbZM4ugcGi1ciNOzldi3Zn/U5eP7oA3Zrgs+H0gxY8MUWPhebvRNDWmYPVbrkDorpVw4WzI6ktibNuzzIrcXKp1PNyq3Tn5Z8r1d8+3PnvutEhlIayZoy6P/6VXd/luewkf/HQQkwkeuXiY4WV17ckFzBxXYGzXx73l3myGqBAFCRf+C+5cobqDGmu3GtFs672f2OwO472W3okCIr3LDJxeRJ0RXUcUwrJZSz5E4CqZHamsV7q+Zgh0QBTqER76Z39SCK1UmiPsAdGAAQNYs2YNy5cv54477uC6665j06ZNOJxOurfddhs33HADJ5xwAk8//TQDBgzg1VdfDeqaZs2aRXl5ufGzf//+oD6eTqsBkdMbYnux6w16IBwt9/tV5o3uJxliYu74HtIKVDu5HwMUIyJD9N1TsOIlwAQXv6ICIbeSjC42rW6lZFZY4ZpjpuOaZ9bo2FK7KtdkUE7KT/SDlybDN4+prq2dXyvB8J7v4eAqsHvRBr30n6pluPvJSoPTBrVWO7+dp9qLZ55cwKhGqfEHzh3M+L4qCBneLbXtxw8GlijI7u9VxqfAMGf0zlBOa2X6eXltg9HZnxZKAX+YiY0yo7tZdPiyWUvoZbMQCqtb0xClJUQbmZOWOs0CqSGCMGSI6l12KuEk7G33MTEx9O3bF4DRo0ezYsUKnnnmGUM3NHjwYI/tBw0axL59TvO7vDyKiz3PrG02G6WlpeTl5RnbFBUVeWyj/61v05jY2FhiYwPzxvKFtjREAEUV9VTUNZASF+2mHwqhoHr/j+q3u3FaQobSk/z4oprVNehcn3apa4iqwqUhWj1HmSuCMt8belGTTXRhYYNdw2pzENPMB9fh5jJETkFusxPvpz8B6QVqjMSh1SrwObiq+TWeeLNy222J2mNK3wMw4ZdeBRCzv9nJvtIauqTGcd9ZTU0FoyxmXrl+DD/uLuWkXgHoHgsyult1UYU6k27RVdvJrf9exfaiSj69e0IT4aj+eqXGRxN1nDrA+4PJZCIhJoqqepsERAdXqcxxCNzHWyuZ6V5EWwor2X+slr45yU22CXzJzDXTrLHVSzCQDFELOBwO6uvr6dmzJ/n5+WzdutXj9m3btlFQoFL548aNo6ysjFWrXF8iX331FQ6Hg7FjxxrbLFmyhIYG1xn6okWLGDBgAOnpwReL+UJrX/YpcdGGJbuuIwr5UFdN88wQuaMLFP0YXqoHRNVWe5vzcwIeEG1f5OqaOvUXcPIdzW6W4F5KaKFs5iGqdqILcpudeB8dD6f9Gm5dDL/aCuc9CwPPVa3AOUMgeyBkqpMFVr4KR7Y23YfOjy+p4aW5Q5XI2Qs+WnsIgPvPGthi7T42ysKEftmhK8m2g7SEaOMMszXPFoBNhypYtKmIPUdr2NyMAZ2e0etM+iEdw5yxswZEuUPV7LbaY6pJIQToYzmaO9GC1meaaZoWkLEd7vTLTcJsgmM1Dca+g0lVvWiImDVrFkuWLGHPnj2sX7+eWbNmsXjxYq6++mpMJhP33Xcfzz77LO+99x47duzgD3/4A1u2bOGmm9TgyUGDBnHWWWdxyy238OOPP/L9999z1113ccUVV5Cfnw/AVVddRUxMDDfddBMbN27knXfe4ZlnnuGXv/ROYxEq6m126px15Jb0Mf2MspkKiAxTxlB5EB3dqTrLLLHKndmdnuOV9ubo9ubdhVvBvbOgrSxRQH2Idn6lpp1rdlW+mvJgi5tGW8zGh1VVC2UzfdK9e8ksI7HlgMju0NhTUq1KN8l5MPo6pZW5/Tv42Q9w53L4+SoVJGnOMQPNYa2GZS+oy+Pv9eqMdu/RanaXVBNlNjFlUMfw1DGZTIawem9zQ17deP8n13v0kPN1c6fU6DDrPOUyHT34rw2lW3UkERXjakgIkY6otS4zcM0029+MsLqy3mbcPytAJbO4aAs9ne7vodARVUmGCIqLi5k5cyYDBgxgypQprFixggULFnDmmaqT5J577mHWrFnce++9jBgxgi+//JJFixbRp49L2zFnzhwGDhzIlClTOOeccxg/fjwvvviicXtqaioLFy5k9+7djB49ml/96lc88MADEdtybzK1XEfVhdU7jYAoxBmiA85yWddRTUW1camuVPOub3zabUyU2UgVV7ShI/I6Q1S8Gf57vZpG7mjULeNwKK3Ovy9S7eN9Jis/pTbGBehnL82dOddYbYaPUm5zXWbNBET/XrqHSU8s5q3l+1o/lil/VMNJt34Ge3/wvE3T4PPftDyTrAUWbz0CwJie6WFvdQ0ketlsXyvC6ga7g/+tOWj8fbis6ZfMsU7YYaYTHy636kgixAaNrZXMwL3TrOn7Ws/gJMdGeYji28uAEOqI9JPMTq0heuWVV9rc5je/+Y2HD1FjMjIyDBPGlhg+fDjffvutz+sLJXrmIyUuusUZXY2n3od8jllL5TKd3pPgwApVNjvhap92nRwXTX1VfZudZl4HRJ//Rq1j4zzVin7Gg9B3ikqDf3Ar7Fikths1E85+3KsRGgkxFkqrmxdW69mhxBiLR4BhdJk1oyH6dnsJAP9Zvo9rTy5ocrtBdn+1zlWvKXfomxa5skArXlbO0Saz0hhZvPuX/mabCogmDegY2SEdbwKiJduOUFLlej0ON5Mh0l+vzuRBpNPpS2YQcoNGV5dZSyWzls0ZA60f0hmQl8z8DYVsC4FjdWVHKJlZrVa2bt2KzdZJU6sBxJsv+j5uM83KaxuMN1HXtBCJqpsTVLvT6zT1e/c3TYZvtkWKFxPvG+wO40O61YCoZLtTy2RSk92L1sOci+GN8+Bfp6lgKCpODZQ8/zmv51wlGp1mTb8oCpvRDwFkJKkv1BqrvUnLrG6Nv+lwBXtK2uiMmvQbiE5QAefmj9R1e75TgR+oLFLfM7w6jroGOz/sVMHYaf2zvbrP8YLhRdRKyUwvl+nvoeamiOs2CZ0xQ2SUzDpzQKRniArXq0HJQabtklnL5oyBHNvhTm9nRWJXW59NAUAvmYU7W+1XQFRTU8NNN91EQkICQ4YMMbq+fv7zn/Poo48GdIGdBW8Con45Lkv1nUdUligzMSagadIWqS1TZSiAbi1kiLqfBFHxUFXkGrPgJd64VevPkdq+lX8cvduq/zT4xVoYd5eacL3nWyjfB+m9VJblhGt8WmNrXkTNCapBpYCjnBk/9yxRVb3Nw2ht/oY25sIl56nBsABfPKT0XO/OVJ5QQy9RgnAv+XF3KXUNDnJTYo322o5CWxmishorX2xSnak3ntoLcGX33DHmmHXCgCg+uuXScKchrQASssDRoIKiINNWyUzPEJXVNDQ5aQxWhqh3ltIQ7TpS1caW7Uc/puNSQzRr1izWrl3L4sWLiYtzfQGcccYZvPPOOwFbXGfCm4AoKymG1PhoNA2+3abO8ENWLju4EtAgozcktZBViIp1+d/42G1meBHVt5wh0p+j5LgoLFoLH9bWGpc54Yk3K0uAaQ8rcfKYG2HUdaqrq8vw5u/fComGhqhpQNRcyz0ooW9zOqLtjdLQn60/3PYCTvk5JGZD6U548XSoOarE7ec/51NrsF4uO61/dtDbaUONe0DUnM/Qx+sOY7U7GJiXbIjJmxNVu0pmHUdf5S0JRsms42b+dx6p4qbXV/D11hYMUU0mNx1RC1YYAaQ1HyJQn49pzvdiY8fqQHsQ6fTOVgHRsZqGpsayASZSNER+BUQffvgh//jHPxg/frzHB+qQIUPYuXNnwBbXmSivaTsgMplMho5o8Tb1jxyyGWZtlct0/Gy/12vHbWWIYmjgMcvz8LcC2PJp0402vA915eoMr88U1/VpPeDcp+H8Z5U9vx/oXxTNlcyKmhnboeNyq3YFe3pdfnCXFMwmWH+wvG2H5dhkOO1+dbm+XJ3BXvE2xPhWMl3s/BLoaPohgPy0eCxmE/U2B8XNtAu/7xxFcsnobkY3YElVvdH2rFPaCeeY6XT0ktnRqnpueG0FX24p5rXv97S8YVdnQLR/WdDX1JpTtY4x9b7R50SwMkQJMVHG/8iukuBmiY7rLrMjR440GZkBUF1d3eHOOENFea16Q7Q1kqKfMyBau78MCOGUe11Q3e3E1rfTA6I934G9bedpHW9KZtXlJfw75hHOti9Wnjsf3tG0xX/Fy+r3mBvb7BrzFT1D1KyouhmXap10pzmj+zwzvZX1lD6ZjO2lBkjO3+BFlmj09cqjyBKrZoml+TZWZn9pDTuPVGMxmzi1b+ujMI5Hoi1mY65f47LZziNVrNlfhsVsYsbIrmQkxhATZUbTXCVPnU7dZWa03Xe8gKjeZue2f68y3huteuz0PFX93jgPlr/Y8nYBWhe0nCECV+t9kwxRkAIicI3s2XkkuDqi41pUPWbMGD791HV2rgdBL7/8MuPGjQvMyjoZ3nZP6Rki3b8wJB5EDrur26KtDFHuUEjIVAGLD6lmvWTWYtt92T5GLryMseYt1JgSIGuAygR9cJtaH6jHO7xGBQsnXOv1Y3uLIapu5sy5sIWSGbi+VN3TznqGqH9eMucM7wLAp+vb0BGB6oa7aQHcs971ge0DerlsVI+04AzIjQCMslkjYbWeHTqtfzbZybGYTCYjgG3caWZkiDphQJTQQbvMNE3jN++vZ+XeY1icur6SqlYCoh7jlP4QYP59gR/E7EZbJTNwnfw2FlYHMyDSy2Y7g6gj0jTNZcx4PGaI/vrXv/Lb3/6WO+64A5vNxjPPPMPUqVN57bXXePjhhwO9xk6BtwGR3mmmExINUfEmFeDEJEPOoNa3NZuh10R12YeyWasZosNr4eUzSK7cxWEtg6e6PQNX/geiE2Hvd/D939V2K5w2DkMugMRMrx/bWxKcouqaVjJEjUXV0Lxb9dZC9QEzIDeZaUNyMZlU1q8th2VAlc6Sc9verhl0/6GOWC7T6ZGhPsT3umWI7A6NeauV99DFo7oZ1+slTvdOswa7w3gfZnTCkpnuQ9TRSmbPfbWDeasPYjGbePwSpSEsrbbiaMkd32SCqX+Bifepvxc9oPzLfOyg9Ya2uswAurfQeh8sDRG4C6uDlyGqsdqNpzQ59jjsMhs/fjxr1qzBZrMxbNgwFi5cSE5ODkuXLmX06NGBXmOnwOsMUbZnQBQSDZFRLhsDZi862vzQEbUYEJUfgNemQ1URJQl9uLD+IarSBqrBq+c8rrb5+q+w4wulHwIlpg4CSUaGyHONNrvDOEtrLiAyMkTOMszRqnrjzLRfbhI5yXGc2FPNCvu8rW6zdmC1OTpsu707PRpNvXc4NN5cuofD5XWkxEV5OHPnOzOs7hki/XUym9ouYXdE4p3v84407f6jtYd4atE2AP5ywVDOG6EmGdgdWvNzBnVMJpj8e/UD8PXDau5hgIMio2TWgg8RQLeMpuaMdofG0arAju1wx2i9D2KGSM8OWcwm4lo5/lDgd36qT58+vPTSS4FcS6fG25EUXdPiiY+2GPX9kJTMvBVU6+gB0YEVUF8FsUmtbg7KkBKa8SH66d9grYS84byW9ySFy464nqORVylPoY3z4O3LVQt63rC2dU5+kmBoiDy/KI5U1ePQIMpsIiux6YdS4wzRtiL14dIjI4EE55fP9GFd+HF3KZ+tP8zNE3oHZf0r95RSY7WTlRTL4C4pQXmMSEAPiPYerebrLcX87fMthmbrsjHdPYa+GiUzN7dqXfyelhBjlFY6Ey5RdcfoMlu+6yj/9+5aAG6Z0IsrT+oBqA7CYzUNlFRZyWwruzLxPmUpsvB38N1TkNUfRl4ZsDUaourWNETpLg2RPnC1tNqKwzl/Nhh6N71ktq+0BpvdEZRBx/pnfnJcVNg1yH4d3WeffcaCBQuaXL9gwQLmz5/f7kV1RrzNEJnNJvrkJBrbhsTIqi2H6sak91Q/DlvTURMt0GyGyOGANU4X8lPupqhBfWgZZ+0mk+ocS+mmHgtgzE1Bm06d2EI7sp5dyEmObdZlvHGGyNAP5bo8gM4amgfAT/vKmjUKDATu7fYtuaF3BAqc5ow/7SvjhtdXsKWwkuS4KH591gDuO2uAx7Z6QOTeet+Z55hBx9IQbS+q5JY3V2K1O5g2JJffnO0q+etzv1rVEblzyl0waZa6/OWf1AzBAGG1t10y0zVEVfU2vt9xlG+3H+GTdWpAc2ZiTFCClfzUeOKizTTYtWbnqAUCY9J9mAXV4GdA9Jvf/Aa7vek/i6ZprY7ZEFrGlynuetksJPqhY3vh2B7AzZfDG/Qs0dbPvNo8ubkM0Z4lykgxNhUGndv8cxSfDhe/pEZXxGfAsEu9X6OP6BmixsNd9dKMntJujMuHSK1fd6gekOfKnOWmxDGmIB0IXtlM1w+dNqDjlsvA5eoLak7ebRN78+2vT+dnk/o2+cLpkqr+hwqbKZl1xg4z6DizzIoq6rj+tRVU1NkY1SONZ644wSPj53NABHDqPcrCo/IQ/PCPgK3VmwxRXLTFEE5f88pyrn3lRx76eBPQfDNHIDCbTcaQ12CVzSJl0j34GRBt376dwYMHN7l+4MCB7Nixo92L6oz4EhD1c2YWuoei5X71W+p3rwlqgKu3DLnQef9/Q9HGNjdvNkO02mmwOOxiiI5v+TkqOAVu/QZu/sKr8py/JMU2/0WhT1YvaCEgcvkQOTNEhU0zRABnD1PdZl6ZNPrIobJathZVYjbBhA7Ybu9Oanw0/ze1P9ef0pPF/zeJWecMIq0FcXSXtKai6s7sQQQYZdzjWVRdVW/jhtdWcLCslt5Zibx83YkepVJwjbpotfW+MdFxai4iqGaOivb/r2qa5lXbPcDVY3uQmRhDt/R4BuYlM6YgnUkDsvm/aQNavV976GPoiIIjrHaN7Qh/QOTXClJTU9m1axc9e/b0uH7Hjh0kJiYGYl2dCqvNYWiCvAmILh3djZ3FVVwzrpWBoC1ht3k9ABS7zRUQjbrOt8fpPQkGnQebP4ZPfgk3zG/VF6hJQFRb5prZNVKN2GhVZ+WH87SvJBizzDwzREZAlNlShsjlQ6RpmluGqFFANDSPP3+yiZV7j1FUURfQs76P16rU+uiC9E7RSn7X5H5ebadniEqqrNTb7MRGWSjr7Bmi49yHqMHu4I63VrHpcAVZSTG8fsNJzb6WWc45g+6Dfr1iyEWw7AWlkfz6L2omYjuwOTTDRqW1khnAPWf0554z+rfr8XxF1xEFy5wxUjyIwM8M0YwZM7jnnns8XKl37NjBr371K84///yALa6zoGc+TCbvouSclDieunwko3qke/8gVcXw74vg0e7wzeNg8+JDYMcXKjUcn6GCG18561HVGr9/Gax5q9VN9ZJZVb0Nu0NTHWO2OsgeBF1HAb5l0YJBS8Nd95WqM6cemc2fDOgfxlabg51HqqmssxFlNtE7yzOblZ8Wzwk90tA0WLAxcGUzTdN4z+nBc5Fby7mgdEL6WXlRucoUdOY5ZnD8a4j+8+M+vt1eQny0hVevP9EY+NsYv0pmoD6op/1VXV49Bw6va89yjZZ7aL3LLFy4vIiCmyFKCvNgV/AzIHrsscdITExk4MCB9OrVi169ejFo0CAyMzN54oknAr3GDo/+RZ8UGxUcseue72H2BNj5JTTUqLOa2eNh79LW7/fTG+r3iCvVnDJfSe0Gp/9WXV70AFQfbXFT90Cwqt7mmkd2wjWGSDrsAVELw131DFHPFj5446Mtxpfusl3qOeiVlUhMM+nxc4b6XjbbX1rDmU99wyvf7W729nUHytleXEVslJnpThNIQWEymYzW+0POspmhIeqkJTOXD9Hx2WW2cs8xAO6Y1Ifh3dJa3C7b34AIVIPJkIsATXWetaMNv94tExcTBGF0e9FP3IJWMjveM0Spqan88MMPfPrpp/zsZz/jV7/6FV9++SVfffUVaWlpAV5ixydoX/QOB3z3NLxxHlQVKnfns/6mZmCVbIXXzoKP7obaY03vW3EYtjk7CUf7WC5zZ+ztkDtMPcaiB1rcLC7aYnwY1B7coFynzVEw/HJApcH1M9bwBUSuKeD64NAaq82YmVWQ0XyGyGQyGVkiPSDq38KUeb3b7MfdpV5rG/67cj/bi6t47PMtFDcaQQEY2aGzhuYZ9gaCi8bmjJ3ZpRrcMkQN9mYH5EY6W50avSH5rVtLZCWr19cnDZE7ZzyoXPF3L3F9VvqBniGKsZgjsvtTzxCVVNW3PEmgHRiDXSNAQ+R3OGoymZg6dSr33Xcfd911FxMnTgzkujoV3noQ+YStHuZeBV88CJpdBRa3fg0n3w53rYBRM9V2P70Br0xtGhSteUvdr/vJkN0OwZ4lCs59yrXPPd+3uKn+DxG9ztlq3/8sSFIdUXrQCOEzy9O/KOwOzfgQ02cipcZHk9pKm7Yu0F22qxRQDtXN0T0jgRHdUnH4UDZb7Gynr7c5mP3NLo/b6hrsfOTUD1062re5Z50Fl7BaBZOdedI9uDREmuZZzjkeUGVppwt8CycdOn6XzHTSC9TnKaiTPYd/z5U3YzvCSXJctGH6GIwskeFDFAEZIq9X8Oyzz3LrrbcSFxfHs88+2+q2d999d7sX1pkISoZo7X9g23x1BnPOY0oUrfvzJGTA+c+pUtj7N0PJNnh3JlzzgZqV5XAoQ0RoX3ZIp/tJaijpqtfh01/C7d+px2lEclwU5dU1pGxzOk6PvNq4TX+OkmOjwmaWp4uqQQmr46ItbQqqdfQMkf7h27jDzJ2zh3Vh7YFy5m84zDUnty6cL6mqZ92BcuPvOcv3cvtpvclxZj2+3FxMeW0D+alxjOsT+HEmHQGXOaMKiCRD5Hqf11jtTbqzIpldJVXYHBrJsVFtmtbqAdHRKjW+w6/szIRfwcrXVcZ966d+aS29cakON72zEymurGfXkSpGdk8L6L4rI2TSPfgQED399NNcffXVxMXF8fTTT7e4nclkkoDIR4ISEG2cp35Pul8FI81RcApc9S68Ok2lfT/7Pzj377B7MZTtVf4/gy8IzHqm/FF1nB3ZAhs/hOFN/YKS46KZbF5NdN1RSMyBfmcat+nPUThHKVjMJsMlvMZqJxPXANEeLbTc6zT+cm3t7PXsoXk8On8Ly3aVcrSqvlUX3SXO7NDgLinERZv5aV8Z/1qyiz+cq2wx/rtqP6DE1J3Rddkb9E4zvWSm2yN0Vg2RxWwiJsqM1eagxmo7rrrt9HJZ/7zkNl2PM51dZjaHRnltg38BcFwqnHQzfPukkicMPNdnY1iXB1HkBp69s5NYtqs0KBmi41JDtHv3bjIzM43LLf3s2rWrjT0JjQl4QFR9FHZ/qy7rfkAtkTcULn5FGRuueh2WPQ+rnGLq4ZdCTIC8jhIylJ4IYPkLzW6SHBfFFZav1R8jLvfIIoVbUK3TWFi956j6gGgzQ+RWfomNMrcaQBVkJjIkPwW7Q2PRpqJW9/u102zx9IHZRjvuW8v2UlxZR1FFnREwXTxaustaIt+tZFbXYKfaqVXrrBkicB/fcXx1mukjWtoql4EKQFKcWQm/y2agPtei4pTucc93Pt890ktm4DbkNQit95HkQ+TzK9DQ0ECfPn3YvHlzMNbTKQm4hmjLx0r/kzccMryYizXgLJj6sLq84Hew5RN12VfvobYYfQNYYtQHx4GVTW4eyk4mW9bgwAyjrve4LSg6Kz9INOaZqX9iXUNU0ELLvY77l2u/3KQ2szXn6CaNrbhW2x0a3253Ta+f0C+LE3qkUW9z8OI3u5i3+iAODcYUpNMrS/zBWiIvxTXgtaxGvc8sZpPxZdkZSThO3ar1DNFALwIicDNnbE9AlJSjumFBZYl8RC+ZNdd1GikE05zRlSEKv2bP51cgOjqaurqmnSyC/wS8HLTxQ/V7yAXe3+fkO1TAgqbmguWfEHizw6RsGHqJurysaZbogvI3AdiWezZk9fW4LVIyRAmNvIjacqnWcS87tKYf0jnb2W32w44SwyiwMWv2l1FW00BKXBQndE/DZDK5skTL9zJn+V4ALpHsUKvoGaLSaqvRep+eEBP2QZPh5Hg1Z9QDopaaFhrjElb7aM7YmHF3qSz7zi/h8Fqf7mqUzCJYq6V3mu0uqcbhCGznYSRpiPwKSe+8807+9re/YbMdnz4VkUZAv+yrjyo9EPim/zGZ4JzHoffp6m+9vBVo9K6MTR9CxSHX9ftXMLhqGTbNzDddbmhyt/KayAiI3Ae8NtgdHHROSW8zQ+SmR/Hm7LV3dhID85KxtVI2W7y1GIAJ/bONwY4T+2UxsnsadQ0O9pfWEhdt5hzxHmqV1Phow3tn8+EKADISw3+2Gk7ij8OSWUVdg/H/ODCv9ZZ7HcOLyN/We52MXk5fIuD7Z3y6q2uwa+RmiLqlJxBjMVNvc33mBYrjUkPkzooVK/jggw/o0aMH06ZN46KLLvL4EXwjoAHR1k+d5bJhkNnHt/taouHq91QXmNP/J+B0GQE9TlFZqBWvuK5f/AgA79snsp+8JncznqMwt0InGgNe7Rwqq8Xu0IiNMhttqS3ha4YIXGWz+S2UzfRhrZP6u4a1qiyRa2zFWUPEe6gtTCaT0Wm28ZAKiDrrHDOdhGiX51a4sDs07n1nDbM+WMeO4ra1K9udI3HyUuK8/pxwje9oZ0AEMP4e9XvjPCh109JWH1WltLXvNHs3b+eYhROL2WToJHeVBK5spmna8e9DlJaWxsUXX8y0adPIz88nNTXV40fwjYAGRHq5zN/uMEuUCqaCWS7Qs0SrXoOGOti3DHZ+icMUxXP2CzwHvDqJlJJZYqwrQ7THrcOsrZZd9y9YbwSfAOcMU4Hht9uPePgwgTKTW39Qtds3nl5/Wv9sTuqVgckEV7fRti8odC+iTYf0DFHnDoji3TKh4WJLYQXzVh/kPz/u58ynv+Fnc1ax4WB5K9t7L6jWabcXkTt5w6DvmaA54IfnoLJQaTL/PlT5wc27FY7ubHI3bybdRwLGCA8vglNvqW2wq1FNREZA5NMKHA4Hjz/+ONu2bcNqtTJ58mQefPBB4uNb93sQWidgguGaUtj9jbrcVndZOBkwHVK7Q/l+2PAerHsXgN3dZnBgew79WwmIwtl2D54aon1edpgBdE2PJzbKTFZSrOGM3BZ9c5Lpl5PE9uIqvthU5NEppnePDclPISfZc38mk4lXrz+RwvI6+uZ4zksTmkcXVm8pdGaIOnlAlBABGiLdQTrGYsZqd/DZ+kI+W1/Iaf2z+fvlI5u8Rr4KqsElqm63hkhn/L2wY5HycVs9B+zOQMsSqy6v/rdyuHbD1WUWuRoiUGV8KApop5neYWY2uUbGhBOfQtKHH36Y3/72tyQlJdG1a1eeffZZ7rzzzmCtrdMQsOzHlk9VKSrXj3JZKLFEwYk3q8tfPKiCOHM0e4f8DHA5l7oTKRmiJGN8h83NlLHtDq7U+Gg++8UE3r/jFJ/EunrZ7OHPNhtf1gBfO/VDpw/IaXGdEgx5jy6srnOerXdWDyKd+AgY8KoHRGN7Z7Dw3olceEJXLGYT32w7wjNfbm+yfdgzRKC83bqdCI4GFQB1Pxmufh8ufkndvuZtsHt+vkVsyezwWvjPVfDVw3BwFb0z1UlDIDvN3CfdR0ITg0+vwJtvvsnzzz/PggUL+PDDD/n444+ZM2cODj8tywU1o6s6UDO6Nn2ofg+Z0b79hIJRMyEqHqqPGH9HZajyTiSXzPQz56p6G3uNlnvvvJr6ZCeRl+pddkjnpgm9GNY1ldJqK1e9tJzNhyuw2R18u70EgEmNymWCf+jmjDqSIQp/QKRnbbKTY+mfm8zTl4/kn1eNAuDT9YeNUgsoLcpWvwIip4aovaJqHZMJLpitmlKu/xRu/Bz6nQH9z4bEbKgqgu0LPe7i6jKLoIDo2B5462KlSV3yGLw0mRlfncFfo14ipejHgD2My4MoMnSOPr0C+/bt45xzzjH+PuOMMzCZTBw6dKiVewmtUdHcjK6aUt+nJ9eUwq7F6vLgCC6X6SRkwIgr1GVLDEz4lVFDbi4gijQfopp6u9cu1e0hJS6at24ay/BuKii6+uXlvLNyP+W1qt0+0Db6nZUujQLVzt5lppeGwznxXs8QZbs5tU8emENqfDRHKutZvvuocX1RRT3ltQ1YzCafMqPubfcBG2Sb1RfO/hv0HO/SYkbFqFFJAD+96bF5WEpmmgZVxc1/z9QegzmXqZPVnCEweAbEJBFTW8xVUV/zz4YHqCneHZBlRFKHGfgYENlsNuLiPD84oqOjaWgI/ATczkKTGV3LX4THeqnUqi9s/cxZLhvaxMMnYhl/j1rvlAcgtatxltDcROWIyxBZbewt1TVEwTU9TE2I5t9uQdHv5m0APNvthfahi6p1OnuXma7nCKeGSC9jZbkFRDFRZsOj6+O1h43r9XJyr6xEnwKLbKeGyGp3UNHMiVhA0Qdqb1/oYTkSlpLZt0/CE/3g3xfCkW2u621WeOdaNZstOR+ueQ8uexN+vQuu+YBdpu5YTBoHlr0XkGVEkgcR+BgQaZrG9ddf79FiX1dXx+233y5t937iIRaurzLaz322gN/0P/U7ULPHQkF6T7jjezjl5wCGM3BVvc3D/CugZcV2omeI9pRUU9fgwGyizSGSgSA1XgVFI7q5ujjd2+2F9tG4ZCZdZpFQMnNmiBpZWpw3Ih+A+RsO0+D08PGnXAYQF20xshMB0xG1RFY/ZTmiOWDNHOPqkI/u0DQ1pglg19fwwjhY+Aeoq4CP74Y930JMMlz9X0hRzzVRsdB3Cpu7XACAZdv8gCzluM4QXXfddeTk5Hi02F9zzTVNWu8F7/HIfKx8FWpLnTfs934nmgb7l6vL/acFeIWhQ88QaZprVhg0KiuG+Uwi0VlK2F6kOi3y0+JDZrmfGh/NmzeNZWyvDLqkxnHGoNyQPG5nICUuysj+gWSIImGWmV4yy2o03Pjk3plkJcVSVtPAdzuUls7oMPPS48udgOuIWkPPEv30b3Bqb0PuVH14jfp+iU6A/mepysIPz8JTg2Htf8BkgcteV3MuG5E5+gIACqpWo9Uca/dS9AaaSMkQ+bSK1157LVjr6LToAVFWnNO7QqfioPc7qT0GdU5/jqx+rW8bwcRFm4kym7A5NCrrbEaApD9HSbFRYS8RJTh9iHR3WW8F1YEiNT6aubeejKbRpveR4D26OeNOZwdNZxdVx0fALLOWMkQWs4npw/J4Y+lePl57iNMH5PjVYaaTlRTLnqM1gWu9b43BM2D+/VC2V3XX9jndt5KZ3QZ2a/uGbm92zqrsOwUufwu2LVBrOubUBZ37FPQ9o9m7njDiBLZ91J3+pv3sWz6PHqff2GSbpxZuZemuo7x6/YltiqUNUfXxmCESAo+e/TinYRFUF0OsM8NWftB7YbXuiprSFaKPX08ok8nUrLA6UvRD0DS1G2z9UHOYTCYJhoJAvrP0GWMxGyNaOisuUXV4AqIGu4NjznE9egbHHb1stnBjEdX1NnYcURlbb0d2uBPw1vvWiEmA4Zeqy05xtU8ls/euh0e6wtyrYdc3vjffgGt498Dz1O/+0+Bny+CcJ+Cil2D09S3eNTbKws6MiQDUbfi4ye0Hy2r5x9c7WLHnGN85O2FbI5JcqkECorBTXttADA2cVea0dT/9t4BJeVhUt/2GAlwBkTeT7SMc/YzC3YsoUkwZAY+yCrQ91FU4ftANM9MToyPCEyWcGG33DeHpMjvqzNZYzKZmy5ejeqSTnxpHVb2N13/Yg9XmICHGQrd0308Is5IDOL7DG/Sy2ZZPoPqo911mZftg88dKg7TlE3jzfHj+ZFjxMlhrvHvskh1wZAuYo6D/VNf10XFw0i0w/LI2dxE7VAVS3Y4uBZvnc/b28r3o8k99LmBrVEbQpHuQgCjslNc2cJHlW9JsxZDcRUXnyc5ZXt7qiIyAqFdQ1hhK9DOFspqmAVFqfPjPInQNkU6oS2ZC8OjizBB1dv0QhF9UrQcnmYkxzWZDzWYT5zqzRP/6Ro3D6J+b7FfmNKQZIlDzHLuMUKWvde9gtXnpQ7ThffU7f5Qyto1OVMHNp7+COZeAw4vXSs8O9ZwA8el+LX/k2NM5rGWQQC0l612eSvU2O++scH1nbXaWMVuj6njuMhMCT2VNLT+zODvETrlbReopXdXf5Qe820kHyhANcIoil2w/YlwXKR5E4Ooy0+mREfqSmRAcujpb7xuLeDsj4RZVtySodufc4crFXW+X92Vkhzv6YxypDIGGSGfkNer3xnnea4jWO1vdR18P05+EX22Gsx6FmCTY+73KFLWFHhANOte/dQMZSXGsSzgFgKOrPjSu/3xDISVVVmUfg3cZIqNkJhoiAWDAkQX0MB+hLibdVbtNdc6s8lZY3YECovNGqrO+T9a5WmojSUOkD3fV6SEZog7DWUO7cMnobvzs9AgeexMiwu1UfaQFQbU7w7qmemRo/RFUQxgyROAKSA78SIJVSSNaLZkVbYKiDWCOhsHnq+viUuHkO+DMP6m/v3gIju1teR8Vh+HACnV5wDktb+cF9v5nAZBz6CujW+7NpeqxZ45TEwcOHKtVnnLVR2HeHbB2bpP9SIZIcOGwM7VU+VHs6neDq3NAD4i8zRDpE5Q7QEA0oW8WmYkxlFZbDVFeJAVE8dEWw3w2KykmYvwzhPaTGh/NE5eO4JQ+WeFeStiJa6cx4/7SGmx2/0c6NWfK2BiTycR5w/ONv/0NiLJDrSEC5e/T7UQAxtT8ANC6fccGZ3ao39Smpa7RN0DBqdBQDZ/c07LQeuun6nfXMS5/IT8ZOO4cKrV40h2lVO1ZwcZD5azae4wos4k7TutjOL9vOVQBH90Fa9+Gebe5slxO3GeZUVPqvW42SEhAFE72LaWr7QBlWiKlg691Xe9LQFR7zOVd1AECoiiL2egg+XCNypBFUkBkMpkMHVE4OswEIRToXWZWm8NjZpg3LN15lAmPfc1DH2/y+/GNklly63ou/bMC/OswA88MUcDGd3jDQJUlGmdVAVGLJTNNg/X/VZeHXdL0drMZznsWLLGw8yvlJdQcm9tfLtPpnZfJymg1V+7wsvd4a5nKDk0bmkdOShyDuqjXwrbqDTVFQefDOzxMh/Xmmdyy1TB7PHxwq5FxCgcSEIWTnuO5PuZJZjXcTFJKhut6XwKiUqd3RFIexHSML+gZIz1baiMpIAJXOUE6zISOins3ZY2P88zWHSgDYMWeUr8f3xjs2oaea0BeMr+fPogHzxvst7u4HhDVNbgc8UPCINWtNdKxgVSqWi6ZHVihOsxikpSRYnNk9YXTZ6nLn8+CyiLP22vLlAM1uNrt20lFgepSS9i9gA9Xq1EkM09W5bJBXZLpYSpi9ObH1MZnPASDzldC8rlXQfEWAKrrrPzM8iH951+hJCLH9ij7mTAhAVGYWVnfnfmOsZ5f9r6IqjuQfkhnZPc0CjITqG2ws3BTYUS13YNLWC36IaGjEhtlNkrDvgqriypUdmfv0RqPETy+oLtGt6Yh0rl5Qm+uP9X/DtvE2CjDiDIkbtU6mX0gZwhR2Jli/qnlLjM9OzTw3NYNGcf9XHWv1ZXBZ//nWTrbvlA5UmcPDNisyx4nXUCDZqFrw15ybAfpn5vESb3Uif3g3ASejn6eWEctFIxX45kuehG6j1UmwnMuQTu0hufsf+bX0e9i0uww/HK47RtXl3UYkIAojNjsDkNl7xEQpXZXv6uK1LC91tAzRB0oIDKZTMwYqYLCD1cfory2mecojOjCamm5FzoqJpOJBD/dqosq6gClPyqqrPPr8Q1RdYg6/kLuRaTjLF+dZVnRfMnMboON89TlYZe2vi9LFJz/DzV6Y/NH8MwI+Py3qkSlz7oc2P5ymc7wfgWsMg0B4A7LR9wxIsrw7zr58JuMNm+nUovHPuN5MFuUafCVcyGzL5Tvx/TiaYw3b6BGi6Vu+nNw4b8g1j8dWKCQgCiMuE9X9nDqTMxS9WA0qDzU9I7udCAPIncucJbNvttRwsFjynQsUgKiK0/qwZiCdCb1zwn3UgQhaMQ7dUT+BkQAu0uq/XpsQ1TtRYYoEISl0wyMstlE8zritGaCx93fQPURSMiE3qe1vb8uw1UrviVWjQdZ9k94fXpA2u0bYzGbONhFjfi4ImoxFy45B54fB/PvJ2PF0wD8oeEG9tozXXdKyICr34NENZh6i6M75zf8hZjR10IEmKFKQBRG6hrs9MpKpFt6PNHuM7pMJkjVy2ZttN53wJIZQO/sJIZ3S8Xu0IzAMVICoqvHFvDeHad0+nlXQsfG8CLy0a26sJ0BkdXmMIxZQ+UJZXgRhWKemRu2rMHsdeQQZ2ogcd/iphvoXVlDLgSLl59/Y2+FX++Cy/4NI650daVl9YcuIwOxbINeZ97OX+wzOZA6SmWmijfB8tmYHDa+i5nAh45T2Xy4kUFjRi+4aSFHJj/BDOufKYouiJhRRNIzHEby0+L5+v8mNX9jajcV7LSlI+qgARHABSO7su5AufF3pAREgtAZ8MeLSNM0iitcWZY9fgRER6vV/aPMJtJC9D9vZIhCqSECrA6NBY4TudX8KXE7P4NRF7tubKhVozqg7XJZY2KTlF/R4PNV2e3wWkjrHvAszKjeuZzwp2fVH7XHYMcXqqvMZuVL889gdTmbD1cw3WmiaZDRm8LemdTzHRkR4kEEkiGKXFJ0c8ZWAqL6Spciv4OVzADOHdEF9xOHSBFVC0JnwPAi8iEgOlbTgNXNf8ifDFGJ0zE6M6n5sR3BIDspPBqi+gYHn9uVH5FlxwKXZtRmhQW/BWslpPaAbif5/yCWKOg2GpKCU+I3mUxKO5SQoWahXfo6XPk2Pbur77CWHKv1lvtI8nKTgChS8ab1XhdUJ2Qp19IORk5yHKf2VSZ5iTEWz7KiIAhBxVUy8z4gctcPgX8B0ZEqtQ9vOswCha5VCnlAZHOwWutLsZaGqb4Sdi9RLfavnQUrX1UbTfyV8ho6ztBHqWxpYaaZYcooGSKhTbwKiDqOQ3VLXODsNhO9jiCEFn9KZrp+SC9v7yut8dnYUc8QhXKmnEtUHVoNkdXmQMPMV6gsEUseg9kT4OAqiEuDK99xjXQ6zhjoNGc8WFZLuduwbh1jbIdkiIQ28UZU3YH1QzrnjujCdeMKuG/agHAvRRA6Ff50mRU7A6IR3dOIiTLTYNc4eKzWp8c94sXYjkATri4zfbDrN5aT1RX7lysfofxRcNsSGNCCEeNxQGp8NF3T4gHYXNi0bKZbzqTERY4UQgKiSEX3Imo1Q9TxA6LYKAsPzRhq+BIJghAaEgwNkfddZoXlKqDIT40znNx3H/WtbHbEB1PGQJGla4hCLKqutym91fqoYZDo1PicdBvcuADSC0K6lmCgj/BoTkdUVS8ZIsFbdLfq+nKoa16UZmiIMmU6tyAIgSXej5KZbsSYmxJHryw1Smj3kSqfHtebwa6BRtcQVVvtPjtztwc9QxQVHQM3zIebFsE5j0FUx5AIDOri1BE1br0HKiNs0j1I233kEpukash1ZWrGS1wzgws7qCmjIAjhxx8NkV4yy02Jo84pxt5ztManxw1Hhig5NoqYKDNWm4OSqnq6h2hOYX2DyhDFRJkDNlIjkjAyRM2WzKTLTPCF1spm1mqoPKwud+CSmSAI4cHoMvNDVJ2XGmtkiHb52GnmyhCFLktiMpmMMSFHQqgj0ktmLQ52Pc7RA6KthZXY7J5T7HVRdXIEZYgkIIpkUlsZ8npsj/odn+5yIhUEQQgQug9RjU9t9yqYyEmOo6czIPLVnNHbSfeBJjdFPV5RuX/z1/xBL5k1O8esA1CQkUBCjIV6m4M9jbRkldJlJvhEa633nUBQLQhC+Ehwdpl5myFqsDuM7E5eqktDdOBYDVabo7W7GtTb7JTXqlJKKEtmoCYHgGoTDxVGhqilSffHOWaziQFOP6LGIzzEh0jwDV1YXdFM670ERIIgBBFfZ5mVVNWjaRBtMZGREENOciwJMRYcmvIj8oajzuxQtMUU8lE9eov4obIQZogaOnbJDGBgXvOdZuJDJPhGaxqiox3flFEQhPDha5dZobPUlJMch9msxjn0zPStbObeYWYK8fTzfCMgCmWGqGOXzAAGOzvNNjUOiOp1DZH4EAHwwgsvMHz4cFJSUkhJSWHcuHHMnz/fuH3SpEnGnBT95/bbb/fYx759+5g+fToJCQnk5ORw3333YbN5ntEsXryYUaNGERsbS9++fXn99ddDcXjtxyiZ7W96m2SIBEEIIr6Kqg39UIqr1NUr29l672VApHeYhbLlXscIiMrDUDLrwAHRyO5K47pid6lH6dQVEEmGCIBu3brx6KOPsmrVKlauXMnkyZOZMWMGGzduNLa55ZZbOHz4sPHz2GOPGbfZ7XamT5+O1Wrlhx9+4I033uD111/ngQceMLbZvXs306dP5/TTT2fNmjXcc8893HzzzSxYsCCkx+oXuqi64hA4GtXgdQ8iCYgEQQgCvrbd63PM8lLijOt6OTNE3pozhqPDTCc/Ta07tBmijl8yG5KfQlZSLNVWOz/uLjWul5JZI8477zzOOecc+vXrR//+/Xn44YdJSkpi2bJlxjYJCQnk5eUZPykpLj+ehQsXsmnTJt566y1GjhzJ2WefzZ///Gf++c9/YrWqWvTs2bPp1asXTz75JIMGDeKuu+7ikksu4emnnw758fpMchcwmcFuheojrusbaqHCWUaTgEgQhCAQH+3b6I4iNw8iHZc5o28ZolALqsGlISqpshoeSsGm3vk4HVVUDUpYPXlgNgBfbSkGVKnQ6mzDF1F1M9jtdubOnUt1dTXjxo0zrp8zZw5ZWVkMHTqUWbNmUVPjEuctXbqUYcOGkZuba1w3bdo0KioqjCzT0qVLOeOMMzwea9q0aSxdurTFtdTX11NRUeHxExYs0SooAlcABHBsr/odmwIJmaFflyAIHR5Xycw7UXVhMwGR0XrvdYYo9INddVLjo41jPhyi1vt6e8cvmQFMHqi+o7/cUoSmaUbLPUBiTOQERGFfyfr16xk3bhx1dXUkJSUxb948Bg8eDMBVV11FQUEB+fn5rFu3jvvvv5+tW7fywQcfAFBYWOgRDAHG34WFha1uU1FRQW1tLfHx8U3W9Mgjj/DQQw8F/Fj9IqWr6jIrPwBdR6vr3B2qQyw8FAShc2CIqhvsaJrWpsi52KkhynXTEPV2BkSHy+uotdqNfbaEbooYjgyRyWQiPy2eHcVVHCqrNbJbwaQzdJkBjO+XRYzFzN6jNewqqcbifC8lxliwmCPnOyzsYemAAQNYs2YNy5cv54477uC6665j06ZNANx6661MmzaNYcOGcfXVV/Pmm28yb948du7cGdQ1zZo1i/LycuNn//5mRM2horEXkd0Gy2ery9kDw7MmQRA6PIlObYemwT3vrOHAsdZb55vLEKUnxhjt895kicIpqobQexF1BlE1KJ3Q2N4ZAHy9pdg12DWCymUQAQFRTEwMffv2ZfTo0TzyyCOMGDGCZ555ptltx44dC8COHTsAyMvLo6ioyGMb/e+8vLxWt0lJSWk2OwQQGxtrdL7pP2HDcKt2ehF99SfY/Q1EJ8L4e8O3LkEQOjRJsVFcf0pPTCb435pDTH7yG/72+RYq6xqa3b45DRHgk2N1OAa7utM1xMJqo+2+A2uIdCYPzAHgy83FEelSDREQEDXG4XBQX9/8LJk1a9YA0KWL0tWMGzeO9evXU1xcbGyzaNEiUlJSjLLbuHHj+PLLLz32s2jRIg+dUkRjeBHth43z4HtnsDjjH5AzKHzrEgShw/Pg+UP4+K7xnNw7A6vNwQuLdzLp8cWs3V/msV2N1WZ8ybmXzMBVNvNmpllJGEXVAPmpofUi6gxdZjp6QLRiTymHndYGSRHkQQRhDohmzZrFkiVL2LNnD+vXr2fWrFksXryYq6++mp07d/LnP/+ZVatWsWfPHj766CNmzpzJxIkTGT58OABTp05l8ODBXHvttaxdu5YFCxbw+9//njvvvJPYWPUPdfvtt7Nr1y5+/etfs2XLFp5//nneffdd7r33OMmu6CWzgz/Bh3eqy6f8HIZeFL41CYLQaRjaNZX/3HIyL80cQ++sRI5WW3nuqx0e2+geRIkxliZGe96aM9Y12KlwBlWhnmOmE/KSmfu0+w5OQWYifbITsTk0PluvNL4pUjJzUVxczMyZMxkwYABTpkxhxYoVLFiwgDPPPJOYmBi++OILpk6dysCBA/nVr37FxRdfzMcff2zc32Kx8Mknn2CxWBg3bhzXXHMNM2fO5E9/+pOxTa9evfj0009ZtGgRI0aM4Mknn+Tll19m2rRp4Thk3zHGdxyAhmroOQGmPBjWJQmC0LkwmUycOTiXv18xEoDlu456TC/XXaobl8vAe3PGo9WqwyzGYiYlPjxflPkhHt/RGZyq3ZkySDU4fbNNVXUirWQW1tW88sorLd7WvXt3vvnmmzb3UVBQwGeffdbqNpMmTWL16tU+ry8i0EtmACnd4NLXwRJZbyJBEDoHQ/JTSY6LorLOxsZDFYzongZAcWUrAVGmd633LkF1TMjHduh0dcsQedNZ1146U8kMVNnsxSW7aLBrQOQFRJ0jLD2eSciAtB4QFQeXvQmJWeFekSAInRSL2cTJvZX32fc7S4zrXRmipqWunlkJgPIYqmhBkA0u/VBWmPRDALmpsZhMYLU5jIxVMOksXWY6owvSPcpk0mUm+IbJBDd/BT9fBd1Gh3s1giB0ck7towKipTuPGtfpGqLc1KYZouS4aKNrrDXHar3DLFz6IVCZGv3xQyGs7gxO1e5EW8xM7J9t/J0sGSLBZ5KyXeJqQRCEMHJKX5WlXrGn1NDAGC33yU0DIoBBzonnaxp1p7kTbg8inVBOvbd2spIZwJRBOcZlyRAJgiAIxy39cpLISoqhrsHBmn1lgNtg12YyRABjeylTvmW7jjZ7O7hliMJYMgN3HVHwhdWdrWQGcFr/HHRz6qRYabsXBEEQjlNMJhPj+qgs0ffOspnLpbr5YEbXHS3fXYqmac1u45pjFvpJ9+6Ecup9ZzJm1MlIjOEkZ4CsP9eRQud5FQRBEISA4NIRlaBpmtscs+a/4IZ3SyMu2kxptZXtxVVNbtc0jdX7jgFQEIIZYq0RypJZZ5ll1pinLx/Js1eewGlueqJIQAIiQRAEwSdOcWaIVu8r42BZLVanJ1FOCxqimCgzowvSAeVh1JgthZUcKq8jLtrMOGc2KVyENCDqJNPuG9MlNZ7zR+SHzV6hJTrXqyAIgiC0m+4Z8XRNi8fm0Ph03WEAMhNjWnVcHttLBTrLdpc2ue2rLcqob3zfLOKiw5stCZWGSNM0N1G1fBVHAvIqCIIgCD5hMpk4ta8KcOatVoOnc1ool+nowurlu4420RF9sVkN4NadjMOJniEqqaqnztkWHwx0QTVAbJiDQEEhAZEgCILgM3rZbEthJQB5LQiqdUZ0TyM2ykxJlZWdbn5EJVX1Rjv+6QNyWrh36EhPiCbeGaDohpPBwCMgkgxRRCCvgiAIguAz4/p4an1aElTrxEVbOKFHGgDLd7t0RF9vKUbTYGjXlBbb9kOJyWQKSaeZ3mFmMkGUObK0NJ0VCYgEQRAEn8lNiaNPtqsjrK2SGbja75ftcumIdP3QlIHhL5fphGLqvavDzBxx4uLOigREgiAIgl+c2tc1WzHPi4BIF1brOiKrzcGSbUcATwfjcNM1BFPvO9tg1+MBCYgEQRAEvzjFrWzWkimjOyf0SCPGYqa4sp7dJdUs332Uaqud7ORYhuanBnOpPhGK1nvDlFH0QxGDvBKCIAiCX4ztlYle7WlLQwRKRzTS0BGV8uVmvVyWgzmCdDRGQFQezIDImSHqRC7VkU5kTVYTBEEQjhvSE2O4/bQ+7CmpZlCXFK/uc3KvDH7cXcqyXUf5yelOPXlg5JTLwDVSIjQaIimZRQoSEAmCIAh+c/9ZA33afmzvTPhqBws3FlHbYCcmysz4fllt3zGEdHUrmWmaFhTRs5TMIg95JQRBEISQMapHOtEWE7VO08NT+mSSEBNZ5+Z6+39dg4NjNQ1BeYzOOOk+0pFXQhAEQQgZ8TEWRnRLM/6eEmHlMlBlrOxkJRIPlrBauswiDwmIBEEQhJBystsA18kRMK6jOYLtRWQVUXXEIa+EIAiCEFImDcgG1DgPXa8TaXQNslu1aIgij8gq3AqCIAgdnjE9M5h768n0zExse+MwkZ8aXC8i6TKLPCQgEgRBEEKOe9ksEskPslu1iKojD3klBEEQBKERekC0pbACTdMCvn+jZCYaoohBXglBEARBaMTYXhkkxljYeaSaBRsLA75/PUMUY5GSWaQgAZEgCIIgNCI9MYYbx/cC4MmF27A7ApslMjREkiGKGOSVEARBEIRmuHlCb1LiotheXMVHaw8GdN/SZRZ5yCshCIIgCM2QGh/Nbaf1AeDvX2ynwe4I2L7FmDHykIBIEARBEFrghlN7kpUUw96jNby36kDA9itdZpGHvBKCIAiC0AIJMVH8bFJfAJ79cjt1zhls7aW+QbrMIg15JQRBEAShFa4a24MuqXEcLq/j7eX7ArJPKZlFHhIQCYIgCEIrxEVbuHtKPwCeX7yDGqut3fsUUXXkIa+EIAiCILTBJaO70SMjgZIqK19tKW73/qyiIYo45JUQBEEQhDaItpgZkp8CQGm1td37M0pm0VIyixQkIBIEQRAEL0iOU+M/K+sCUTKTDFGkIa+EIAiCIHhBUmw0EKiASDREkYa8EoIgCILgBXqGqKq+od37MkZ3SJdZxCABkSAIgiB4QVBKZuJDFDHIKyEIgiAIXhDYgEiVzGIs8jUcKcgrIQiCIAhekBynNERV7QyINE2TDFEEIq+EIAiCIHhBUqzKEFXUtU9D1GDX0DR1WTREkYMERIIgCILgBS5RdfsyRHq5DKTLLJKQV0IQBEEQvCBQGiK9XAYSEEUS8koIgiAIghcYGqJ6G5pe8/IDPSCKiTJjMpkCsjah/UhAJAiCIAheoGeI7A6N2gZ7G1u3TH2DmDJGIvJqCIIgCIIXxEdbsJhVRqc9ZTOrXUwZIxEJiARBEATBC0wmk9Fp1p6AyOVSLV/BkYS8GoIgCILgJa6AyP/We/Egikzk1RAEQRAELwlE671rsKuUzCIJCYgEQRAEwUsC0XovJbPIRF4NQRAEQfASvfU+ICUzCYgiCnk1BEEQBMFLApIh0ktm0VIyiyQkIBIEQRAELwlIl5luzCiT7iMKeTUEQRAEwUvc3ar9xTBmlC6ziEJeDUEQBEHwElfJTDREHQ15NQRBEATBSwKjIRKn6khEAiJBEARB8BJdQ9SektneozUAZCXFBGRNQmCQgEgQBEEQvETXEFW0I0P0456jAIzpmRGQNQmBIawB0QsvvMDw4cNJSUkhJSWFcePGMX/+/CbbaZrG2Wefjclk4sMPP/S4bd++fUyfPp2EhARycnK47777sNk836iLFy9m1KhRxMbG0rdvX15//fUgHpUgCILQUTGcqv3UEB0qq2V/aS1mE4wuSA/k0oR2EtaAqFu3bjz66KOsWrWKlStXMnnyZGbMmMHGjRs9tvv73/+OyWRqcn+73c706dOxWq388MMPvPHGG7z++us88MADxja7d+9m+vTpnH766axZs4Z77rmHm2++mQULFgT9+ARBEISORXvb7lfsKQVgaNdUY19CZBDWV+O8887z+Pvhhx/mhRdeYNmyZQwZMgSANWvW8OSTT7Jy5Uq6dOnisf3ChQvZtGkTX3zxBbm5uYwcOZI///nP3H///Tz44IPExMQwe/ZsevXqxZNPPgnAoEGD+O6773j66aeZNm1aaA5UEARB6BCktLPtfvluFRCdJOWyiCNiNER2u525c+dSXV3NuHHjAKipqeGqq67in//8J3l5eU3us3TpUoYNG0Zubq5x3bRp06ioqDCyTEuXLuWMM87wuN+0adNYunRpi2upr6+noqLC40cQBEEQkpwlsxqrHZvd4fP9V+gBUS8JiCKNsAdE69evJykpidjYWG6//XbmzZvH4MGDAbj33ns55ZRTmDFjRrP3LSws9AiGAOPvwsLCVrepqKigtra22f0+8sgjpKamGj/du3dv1zEKgiAIHQP3MpevWaKjVfVsL64C4ETJEEUcYS9gDhgwgDVr1lBeXs57773HddddxzfffMOOHTv46quvWL16dcjXNGvWLH75y18af1dUVEhQJAiCIBATZSY2yky9zUFlnY20BO9b51fsOQZA/9wk0hOl5T7SCHtAFBMTQ9++fQEYPXo0K1as4JlnniE+Pp6dO3eSlpbmsf3FF1/MhAkTWLx4MXl5efz4448etxcVFQEYJba8vDzjOvdtUv6/vTuPi6rq/wD+GWZnmUHZkV0QMAUplPihoomKmi8TnwofDFzSVMyFUrQeNBfUNBRzLUWstFxSehItH8TENERFUApSMxVTEDPZlHXm/P4gbo4swrAMw3zfr9e8Xs695879zheH+XLOuffIZJBKpfXGJBaLIRaLW+PtEUII6WSMJEJUlFY0e2L1ORou69A0PmT2NKVSiYqKCixcuBCXL19GZmYm9wCA9evXIz4+HgDg6+uLrKwsFBQUcMcnJSVBJpNxw26+vr5ITk5WOUdSUhI3T4kQQghpDplEvZsz1l5h1s/RpNVjIi2n0R6iRYsWYcSIEbCzs0NJSQm+/PJLnDx5EseOHYOlpWW9E6nt7Ozg6OgIABg2bBh69uyJN954A2vWrEF+fj7+85//IDw8nOvhmT59OjZt2oQFCxZg8uTJOHHiBPbv348jR46063slhBDSORiqsZ5ZSXkVfrlbBICuMOuoNFoQFRQUIDQ0FHl5eZDL5fDw8MCxY8cwdOjQJh3P5/ORmJiIGTNmwNfXFwYGBggLC8OyZcu4No6Ojjhy5AjmzZuHDRs2wMbGBjt27KBL7gkhhKhFnfXM0m89hJIBdl31YSmXtFVopAU0WhDFxcU1qz1jrM42e3t7HD16tNHjBg0apJHJ2YQQQjof7uaMzRgyo/lDHV+Hm0NECCGEdGS165k1Z8iMCqKOjwoiQgghpBm4Fe+bOGRWXqXA5T9q5g/5UEHUYVFBRAghhDSDrJlziDJvF6JSoYS5kRh2XfXbMjTSAlQQEUIIIc3Q3CGzJ4fL6luonHQMVBARQgghzWDYzPsQ1RZENFzWsVFBRAghhDRD7WX3xU0YMqtWKJF+q2bJDrohY8em8aU7OhOFQoGqqqZfdUBIZyEUCsHn8zUdBiHtojmTqm8+eISyKgX0RXy4mBu2dWikBaggagWMMeTn56OwsFDToRCiMcbGxrC0tKQ5EqTT4+YQVTz7D+Br92pWt3cxN4SeHn02OjIqiFpBbTFkbm4OfX19+kIgOoUxhsePH3NrClpZWWk4IkLaFreWWRN6iK4V1BREzuZGbRoTaTkqiFpIoVBwxZCJCY0PE90klUoB1CzHY25uTsNnpFMzfOKye8ZYo38E1xZEPSxouKyjo0nVLVQ7Z0hfn+4tQXRb7WeA5tGRzq52yKxayVBepWy07bV7JQAAFyqIOjwqiFoJDZMRXUefAaIr9IV81P53b2weUbVCid/vPwIAuNCQWYdHBREhhBDSDHp6vH8WeG1kHlHuX49RqVBCKuSjm7G0vcIjaqKCiHRYPB4P33zzjVrH3rx5EzweD5mZma0aU3vQ5tgJ0RVGTbj0/uq92gnVdIWZNqCCiCA1NRV8Ph+jRo1q9rEODg6IjY1t/aB0mK2tLfLy8tCrVy9Nh0IIacA/y3c0XBD9VvD3/CG6/5BWoIKIIC4uDm+//TZOnTqFu3fvajocnVZZWQk+nw9LS0sIBHQRKCEdlRF3pVnDc4i4S+5pQrVWoIJIx5WWlmLfvn2YMWMGRo0ahV27dtVpc/jwYfTt2xcSiQSmpqYYO3YsAGDQoEG4desW5s2bBx6Px02q/eCDD9CnTx+V14iNjYWDgwP3/Pz58xg6dChMTU0hl8vh7++PixcvNit2pVKJNWvWwNnZGWKxGHZ2doiOjm6wfUpKCvr16wexWAwrKyssXLgQ1dX//HX39ddfo3fv3pBKpTAxMUFAQAAePXrE7d+xYwfc3d0hkUjg5uaGLVu2NBrfoEGDMGvWLMyaNQtyuRympqaIiooCY4xr4+DggOXLlyM0NBQymQzTpk2rd8jsl19+wcsvvwyZTAYjIyMMGDAA169fVzs2QkjLcJfeN7Ke2VXupow0oVobUEHUBhhjeFxZrZHHk1+2TbF//364ubnB1dUVEyZMwM6dO1Ve48iRIxg7dixGjhyJjIwMJCcno1+/fgCAQ4cOwcbGBsuWLUNeXh7y8vKafN6SkhKEhYXh9OnTOHv2LFxcXDBy5EiUlJQ0+TUWLVqE1atXIyoqCtnZ2fjyyy9hYWFRb9s7d+5g5MiR6Nu3Ly5duoStW7ciLi4OK1asAADk5eVh/PjxmDx5MnJycnDy5EkEBQVxudizZw8WL16M6Oho5OTkYOXKlYiKisJnn33WaIyfffYZBAIBzp07hw0bNmDdunXYsWOHSpuPPvoInp6eyMjIQFRUVL2xDxw4EGKxGCdOnEB6ejomT57MFXPqxkYIUd+zhswUSobr9+keRNqE+uTbQFmVAj0XH9PIubOXDYe+qOk/1ri4OEyYMAEAEBgYiKKiIqSkpGDQoEEAgOjoaAQHB2Pp0qXcMZ6engCArl27gs/nw8jICJaWls2K86WXXlJ5/umnn8LY2BgpKSl4+eWXn3l8SUkJNmzYgE2bNiEsLAwA0L17d/Tv37/e9lu2bIGtrS02bdoEHo8HNzc33L17F5GRkVi8eDHy8vJQXV2NoKAg2NvbAwB69+7NHb9kyRLExMQgKCgIAODo6Ijs7Gx88skn3PnrY2tri/Xr14PH48HV1RVZWVlYv349pk6dqpKLd955h3t+8+ZNldfYvHkz5HI59u7dC6Gw5pdwjx49WhwbIUR9z1rP7PZfj1FZrYRYoAebLnSfOm1APUQ67MqVKzh37hzGjx8PABAIBHj99dcRFxfHtcnMzMSQIUNa/dz37t3D1KlT4eLiArlcDplMhtLSUuTm5jbp+JycHFRUVDQ5tpycHPj6+qrcK8fPzw+lpaX4448/4OnpiSFDhqB379549dVXsX37djx8WLNC9aNHj3D9+nVMmTIFhoaG3GPFihUqw1b1efHFF1XO6evri2vXrkGhUHDbvL29G32NzMxMDBgwgCuGntSS2Agh6pM9Yw5R7fyh7maG4NMVZlqBeojagFTIR/ay4Ro7d1PFxcWhuroa1tbW3DbGGMRiMTZt2gS5XM4tydAcenp6dYbunr57cVhYGB48eIANGzbA3t4eYrEYvr6+qKysbNI51ImrMXw+H0lJSfjpp5/wv//9Dxs3bsT777+PtLQ07g7M27dvh4+PT53jWsrAwKDR/Y2919LS0jaNjRBSP66HqIE5RFfpDtVah3qI2gCPx4O+SKCRR1PvFlxdXY3PP/8cMTExyMzM5B6XLl2CtbU1vvrqKwCAh4cHkpOTG3wdkUik0tsBAGZmZsjPz1cpip6+p86ZM2cwe/ZsjBw5Es899xzEYjH+/PPPJmYYcHFxgVQqbTS2J7m7uyM1NVUlpjNnzsDIyAg2NjYAan5ufn5+WLp0KTIyMiASiZCQkAALCwtYW1vj999/h7Ozs8rD0dGx0fOmpaWpPK+dL9WcYsXDwwM//vhjvUtitCQ2Qoj6jCSN35jxN24NM5pQrS2oh0hHJSYm4uHDh5gyZQrkcrnKvnHjxiEuLg7Tp0/HkiVLMGTIEHTv3h3BwcGorq7G0aNHERkZCaDmKqlTp04hODgYYrEYpqamGDRoEO7fv481a9bgX//6F77//nt89913kMlk3DlcXFzwxRdfwNvbG8XFxZg/f36zen0kEgkiIyOxYMECiEQi+Pn54f79+/jll18wZcqUOu1nzpyJ2NhYvP3225g1axauXLmCJUuWICIiAnp6ekhLS0NycjKGDRsGc3NzpKWl4f79+3B3dwcALF26FLNnz4ZcLkdgYCAqKipw4cIFPHz4EBEREQ3GmZubi4iICLz11lu4ePEiNm7ciJiYmCa/TwCYNWsWNm7ciODgYCxatAhyuRxnz55Fv3794OrqqnZshBD11U6qLm5wyKymh8iZ7kGkPRh5pqKiIgaAFRUV1dlXVlbGsrOzWVlZmQYiU9/LL7/MRo4cWe++tLQ0BoBdunSJMcbYwYMHWZ8+fZhIJGKmpqYsKCiIa5uamso8PDyYWCxmT/532rp1K7O1tWUGBgYsNDSURUdHM3t7e27/xYsXmbe3N5NIJMzFxYUdOHCA2dvbs/Xr13NtALCEhIQG34NCoWArVqxg9vb2TCgUMjs7O7Zy5UrGGGM3btxgAFhGRgbX/uTJk6xv375MJBIxS0tLFhkZyaqqqhhjjGVnZ7Phw4czMzMzJhaLWY8ePdjGjRtVzrdnzx4uD126dGEDBw5khw4dajA+f39/NnPmTDZ9+nQmk8lYly5d2HvvvceUSiXX5un33FDsly5dYsOGDWP6+vrMyMiIDRgwgF2/fl3t2NqCtn4WCFHH9z/nMfvIRPbK5tN19ikUSub6n6PMPjKRXS8o0UB0pFZj399P4zHWzOu0dVBxcTHkcjmKiopUejkAoLy8HDdu3ICjoyMkEomGIiQd0aBBg9CnTx+duZM3fRaILvnp+p/49/Y0OJsb4niEv8q+3AePMXDtDxAJ9JC9dDgEfJqdoimNfX8/jX5KhBBCSDMZiWuGzOq77L52uMzJ1ICKIS1CPylCCCGkmRpbuqP2knsXmlCtVWhSNSFt5OTJk5oOgRDSRmqX7nhUqYBCyVTuNcRdck8TqrUK9RARQgghzVTbQwTUvRfRP5fcU0GkTaggIoQQQppJLOBDJKj5Cn1y2EypZFxB5EyLumoVKogIIYQQNRjVc7fqO4VleFypgJDPg70JrWGmTaggIoQQQtRQ392qa3uHHE0NIKQrzLQK/bQIIYQQNdROrH7y0vvaS+7pCjPtQwURIYQQoobaexE9uXxH2u9/AQB60PwhrUMFEWkXEydOxCuvvMI9HzRoEObOndvucZw8eRI8Hg+FhYVqHb9r1y4YGxu3akztRZtjJ6QjenrI7LeCUiT/WgAAGOVhpbG4iHqoINJhEydOBI/HA4/Hg0gkgrOzM5YtW4bq6vpXb25Nhw4dwvLly5vUtqVFDKnx+uuv4+rVq5oOg5BOgxsy+3tS9fZTvwMAhva0oEVdtRDdmFHHBQYGIj4+HhUVFTh69CjCw8MhFAqxaNGiOm0rKyshEola5bxdu3ZtldchTVNVVQWpVAqpVKrpUAjpNGR/r3hfUl6FguJyJGTcAQC8NdBJk2ERNVEPkY4Ti8WwtLSEvb09ZsyYgYCAAHz77bcA/hnmio6OhrW1NVxdXQEAt2/fxmuvvQZjY2N07doVY8aMwc2bN7nXVCgUiIiIgLGxMUxMTLBgwQI8vYbw00NmFRUViIyMhK2tLcRiMZydnREXF4ebN29i8ODBAIAuXbqAx+Nh4sSJAAClUolVq1bB0dERUqkUnp6e+Prrr1XOc/ToUfTo0QNSqRSDBw9WibMhhYWFeOutt2BhYQGJRIJevXohMTGxwfZbt25F9+7dIRKJ4Orqii+++ILbxxjDBx98ADs7O4jFYlhbW2P27Nkq7/vdd99Ft27dYGBgAB8fn2fe4ZrH42Hr1q0YMWIEpFIpnJycVN73zZs3wePxsG/fPvj7+0MikWDPnj31DpkdPnwYffv2hUQigampKcaOHdui2AjRJYbifyZVx/90E5UKJV6w7wJvB/qDTxtRD1FbYAyoeqyZcwv1AR7v2e0aIJVK8eDBA+55cnIyZDIZkpKSANT0NAwfPhy+vr748ccfIRAIsGLFCgQGBuLy5csQiUSIiYnBrl27sHPnTri7uyMmJgYJCQl46aWXGjxvaGgoUlNT8fHHH8PT0xM3btzAn3/+CVtbWxw8eBDjxo3DlStXIJPJuF6OVatWYffu3di2bRtcXFxw6tQpTJgwAWZmZvD398ft27cRFBSE8PBwTJs2DRcuXMA777zT6PtXKpUYMWIESkpKsHv3bnTv3h3Z2dng8/n1tk9ISMCcOXMQGxuLgIAAJCYmYtKkSbCxscHgwYNx8OBBrF+/Hnv37sVzzz2H/Px8XLp0iTt+1qxZyM7Oxt69e2FtbY2EhAQEBgYiKysLLi4uDcYZFRWF1atXY8OGDfjiiy8QHByMrKwsuLu7c20WLlyImJgYeHl5QSKR4NixYyqvceTIEYwdOxbvv/8+Pv/8c1RWVuLo0aMtjo0QXVE7hyivqBypv9f83qTeIe1FBVFbqHoMrLTWzLnfuwuIDJp9GGMMycnJOHbsGN5++21uu4GBAXbs2MENle3evRtKpRI7duwA7+/CKz4+HsbGxjh58iSGDRuG2NhYLFq0CEFBQQCAbdu21fkyftLVq1exf/9+JCUlISAgAADg5PTPL5Xa4TVzc3Ouh6OiogIrV67E8ePH4evryx1z+vRpfPLJJ/D39+d6bmJiYgAArq6uyMrKwocffthgLMePH8e5c+eQk5ODHj161InlaR999BEmTpyImTNnAgAiIiJw9uxZfPTRRxg8eDByc3NhaWmJgIAACIVC2NnZoV+/fgCA3NxcxMfHIzc3F9bWNf9f3n33XXz//feIj4/HypUrGzzvq6++ijfffBMAsHz5ciQlJWHjxo3YsmUL12bu3Lncz6A+0dHRCA4OxtKlS7ltnp6eLY6NEF1RO4foeM49KBngZGaAAHcLDUdF1EUFkY5LTEyEoaEhqqqqoFQq8e9//xsffPABt793794q84YuXbqE3377DUZGqpeUlpeX4/r16ygqKkJeXh58fHy4fQKBAN7e3nWGzWplZmaCz+fD39+/yXH/9ttvePz4MYYOHaqyvbKyEl5eXgCAnJwclTgAcMVTQzIzM2FjY8MVQ8+Sk5ODadOmqWzz8/PDhg0bANQULrGxsXByckJgYCBGjhyJ0aNHQyAQICsrCwqFos65KioqYGJi0uh5n34fvr6+yMzMVNnm7e3d6GtkZmZi6tSp9e5rSWyE6Aqjv+cQKf/+1TZtgBP09NTvoSeaRQVRWxDq1/TUaOrczTB48GBs3boVIpEI1tbWEAhU/0sYGKj2NpWWluKFF17Anj176ryWmZlZ8+MF1JroW1paczfYI0eOoFu3bir7xGKxWnGoG0tjbG1tceXKFRw/fhxJSUmYOXMm1q5di5SUFJSWloLP5yM9Pb3OkJyhYcuvUHn6Z/e0xt5rW8dGSGfw5AKvZkZivOLVrZHWpKOjgqgt8HhqDVtpgoGBAZydnZvc/vnnn8e+fftgbm4OmUxWbxsrKyukpaVh4MCBAIDq6mqkp6fj+eefr7d97969oVQqkZKSwg2ZPam2h0qhUHDbevbsCbFYjNzc3AZ7ltzd3bkJ4rXOnj3b6Pvz8PDAH3/8gatXrzapl8jd3R1nzpxBWFgYt+3MmTPo2bMn91wqlWL06NEYPXo0wsPD4ebmhqysLHh5eUGhUKCgoAADBgx45rmefh+hoaEqz2t7xprKw8MDycnJmDRpUp19LYmNEF1Ru5YZAEzyc4BEWP9cQ6IdqCAizRISEoK1a9dizJgxWLZsGWxsbHDr1i0cOnQICxYsgI2NDebMmYPVq1fDxcUFbm5uWLduXaP3EHJwcEBYWBgmT57MTaq+desWCgoK8Nprr8He3h48Hg+JiYkYOXIkpFIpjIyM8O6772LevHlQKpXo378/ioqKcObMGchkMoSFhWH69OmIiYnB/Pnz8eabbyI9PR27du1q9P35+/tj4MCBGDduHNatWwdnZ2f8+uuv4PF4CAwMrNN+/vz5eO211+Dl5YWAgAAcPnwYhw4dwvHjxwHU3AxRoVDAx8cH+vr62L17N6RSKezt7WFiYoKQkBCEhoZyk5/v37+P5ORkeHh4YNSoUQ3GeeDAAXh7e6N///7Ys2cPzp07h7i4uCb9DGstWbIEQ4YMQffu3REcHIzq6mocPXoUkZGR6NGjh9qxEaIrLGQSADVXm4X42Gs4GtJijDxTUVERA8CKiorq7CsrK2PZ2dmsrKxMA5G1TFhYGBszZkyz9+fl5bHQ0FBmamrKxGIxc3JyYlOnTuXyU1VVxebMmcNkMhkzNjZmERERLDQ0VOW1/P392Zw5c7jnZWVlbN68eczKyoqJRCLm7OzMdu7cye1ftmwZs7S0ZDwej4WFhTHGGFMqlSw2Npa5uroyoVDIzMzM2PDhw1lKSgp33OHDh5mzszMTi8VswIABbOfOnQwAe/jwYYPv+8GDB2zSpEnMxMSESSQS1qtXL5aYmMgYYyw+Pp7J5XKV9lu2bGFOTk5MKBSyHj16sM8//5zbl5CQwHx8fJhMJmMGBgbsxRdfZMePH+f2V1ZWssWLFzMHBwcmFAqZlZUVGzt2LLt8+XKD8QFgmzdvZkOHDmVisZg5ODiwffv2cftv3LjBALCMjAyV4+qL/eDBg6xPnz5MJBIxU1NTFhQUpHZs2vxZIERd32Xlsczch5oOgzSgse/vp/EYa2CmK+EUFxdDLpejqKiozjBReXk5bty4AUdHR0gkEg1FSHQJj8dDQkKCylIoHQF9FgghHU1j399PoxszEkIIIUTnUUFECCGEEJ1Hk6oJ0TI0yk0IIa2PeogIIYQQovOoICKEEEKIzqOCqJUolUpNh0CIRtFngBCizWgOUQuJRCLo6enh7t27MDMzg0gk4hY9JUQXMMZQWVmJ+/fvQ09PT2XtO0II0RZUELWQnp4eHB0dkZeXh7t3NbR+GSEdgL6+Puzs7KCnRx3PhBDtQwVRKxCJRLCzs0N1dbXKeluE6Ao+nw+BQEC9o4QQrUUFUSvh8XgQCoUQCoWaDoUQQgghzUR924QQQgjReVQQEUIIIUTnUUFECCGEEJ1Hc4iaoHaphOLiYg1HQgghhJCmqv3ebsqSR1QQNUFJSQkAwNbWVsOREEIIIaS5SkpKIJfLG23DY7RS5DMplUrcvXsXRkZGrX5ZcXFxMWxtbXH79m3IZLJWfW2iinLdfijX7Ydy3X4o1+2ntXLNGENJSQmsra2feY806iFqAj09PdjY2LTpOWQyGX3A2gnluv1QrtsP5br9UK7bT2vk+lk9Q7VoUjUhhBBCdB4VRIQQQgjReVQQaZhYLMaSJUsgFos1HUqnR7luP5Tr9kO5bj+U6/ajiVzTpGpCCCGE6DzqISKEEEKIzqOCiBBCCCE6jwoiQgghhOg8KogIIYQQovOoICKEEEKIzqOCSIM2b94MBwcHSCQS+Pj44Ny5c5oOSeutWrUKffv2hZGREczNzfHKK6/gypUrKm3Ky8sRHh4OExMTGBoaYty4cbh3756GIu48Vq9eDR6Ph7lz53LbKNet586dO5gwYQJMTEwglUrRu3dvXLhwgdvPGMPixYthZWUFqVSKgIAAXLt2TYMRay+FQoGoqCg4OjpCKpWie/fuWL58ucoCoZRv9Zw6dQqjR4+GtbU1eDwevvnmG5X9TcnrX3/9hZCQEMhkMhgbG2PKlCkoLS1tcWxUEGnIvn37EBERgSVLluDixYvw9PTE8OHDUVBQoOnQtFpKSgrCw8Nx9uxZJCUloaqqCsOGDcOjR4+4NvPmzcPhw4dx4MABpKSk4O7duwgKCtJg1Nrv/Pnz+OSTT+Dh4aGynXLdOh4+fAg/Pz8IhUJ89913yM7ORkxMDLp06cK1WbNmDT7++GNs27YNaWlpMDAwwPDhw1FeXq7ByLXThx9+iK1bt2LTpk3IycnBhx9+iDVr1mDjxo1cG8q3eh49egRPT09s3ry53v1NyWtISAh++eUXJCUlITExEadOncK0adNaHhwjGtGvXz8WHh7OPVcoFMza2pqtWrVKg1F1PgUFBQwAS0lJYYwxVlhYyIRCITtw4ADXJicnhwFgqampmgpTq5WUlDAXFxeWlJTE/P392Zw5cxhjlOvWFBkZyfr379/gfqVSySwtLdnatWu5bYWFhUwsFrOvvvqqPULsVEaNGsUmT56ssi0oKIiFhIQwxijfrQUAS0hI4J43Ja/Z2dkMADt//jzX5rvvvmM8Ho/duXOnRfFQD5EGVFZWIj09HQEBAdw2PT09BAQEIDU1VYORdT5FRUUAgK5duwIA0tPTUVVVpZJ7Nzc32NnZUe7VFB4ejlGjRqnkFKBct6Zvv/0W3t7eePXVV2Fubg4vLy9s376d23/jxg3k5+er5Foul8PHx4dyrYb/+7//Q3JyMq5evQoAuHTpEk6fPo0RI0YAoHy3labkNTU1FcbGxvD29ubaBAQEQE9PD2lpaS06P612rwF//vknFAoFLCwsVLZbWFjg119/1VBUnY9SqcTcuXPh5+eHXr16AQDy8/MhEolgbGys0tbCwgL5+fkaiFK77d27FxcvXsT58+fr7KNct57ff/8dW7duRUREBN577z2cP38es2fPhkgkQlhYGJfP+n6nUK6bb+HChSguLoabmxv4fD4UCgWio6MREhICAJTvNtKUvObn58Pc3Fxlv0AgQNeuXVuceyqISKcVHh6On3/+GadPn9Z0KJ3S7du3MWfOHCQlJUEikWg6nE5NqVTC29sbK1euBAB4eXnh559/xrZt2xAWFqbh6Dqf/fv3Y8+ePfjyyy/x3HPPITMzE3PnzoW1tTXluxOjITMNMDU1BZ/Pr3O1zb1792BpaamhqDqXWbNmITExET/88ANsbGy47ZaWlqisrERhYaFKe8p986Wnp6OgoADPP/88BAIBBAIBUlJS8PHHH0MgEMDCwoJy3UqsrKzQs2dPlW3u7u7Izc0FAC6f9DuldcyfPx8LFy5EcHAwevfujTfeeAPz5s3DqlWrAFC+20pT8mppaVnn4qPq6mr89ddfLc49FUQaIBKJ8MILLyA5OZnbplQqkZycDF9fXw1Gpv0YY5g1axYSEhJw4sQJODo6qux/4YUXIBQKVXJ/5coV5ObmUu6baciQIcjKykJmZib38Pb2RkhICPdvynXr8PPzq3P7iKtXr8Le3h4A4OjoCEtLS5VcFxcXIy0tjXKthsePH0NPT/Xrkc/nQ6lUAqB8t5Wm5NXX1xeFhYVIT0/n2pw4cQJKpRI+Pj4tC6BFU7KJ2vbu3cvEYjHbtWsXy87OZtOmTWPGxsYsPz9f06FptRkzZjC5XM5OnjzJ8vLyuMfjx4+5NtOnT2d2dnbsxIkT7MKFC8zX15f5+vpqMOrO48mrzBijXLeWc+fOMYFAwKKjo9m1a9fYnj17mL6+Ptu9ezfXZvXq1czY2Jj997//ZZcvX2Zjxoxhjo6OrKysTIORa6ewsDDWrVs3lpiYyG7cuMEOHTrETE1N2YIFC7g2lG/1lJSUsIyMDJaRkcEAsHXr1rGMjAx269YtxljT8hoYGMi8vLxYWloaO336NHNxcWHjx49vcWxUEGnQxo0bmZ2dHROJRKxfv37s7Nmzmg5J6wGo9xEfH8+1KSsrYzNnzmRdunRh+vr6bOzYsSwvL09zQXciTxdElOvWc/jwYdarVy8mFouZm5sb+/TTT1X2K5VKFhUVxSwsLJhYLGZDhgxhV65c0VC02q24uJjNmTOH2dnZMYlEwpycnNj777/PKioquDaUb/X88MMP9f6ODgsLY4w1La8PHjxg48ePZ4aGhkwmk7FJkyaxkpKSFsfGY+yJW28SQgghhOggmkNECCGEEJ1HBREhhBBCdB4VRIQQQgjReVQQEUIIIUTnUUFECCGEEJ1HBREhhBBCdB4VRIQQQgjReVQQEUIIIUTnUUFECCGEEJ1HBREhhBBCdB4VRIQQQgjRef8PcdfnooEIV5gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(target_scaler.inverse_transform(targets_test.reshape(-1,1)), label='Actual close price')\n",
    "plt.plot(target_scaler.inverse_transform(predictions.reshape(-1,1)), label='Predicted close price')\n",
    "\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7867b-ec9b-48ec-8b02-eaf72ee66b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbedf4bc-7aeb-499f-8a22-342ed4e6eab5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4de4d-2d87-4e8c-9299-e7112d4aaae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a5ead7ad-9720-4293-aeff-26dcbee581eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape before attention: (958, 10, 12)\n",
      "Attention output shape: (958, 10, 12)\n",
      "Input shape before attention: (958, 10, 12)\n",
      "Attention output shape: (958, 10, 12)\n",
      "Input shape before attention: (958, 10, 12)\n",
      "Attention output shape: (958, 10, 12)\n",
      "Input shape before attention: (958, 10, 12)\n",
      "Attention output shape: (958, 10, 12)\n",
      "Input shape before attention: (958, 10, 12)\n",
      "Attention output shape: (958, 10, 12)\n",
      "Input shape before attention: (958, 10, 12)\n",
      "Attention output shape: (958, 10, 12)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[319], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_transformer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime2vec_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Compile the Model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[315], line 33\u001b[0m, in \u001b[0;36mcreate_transformer_model\u001b[1;34m(input_data, time2vec_dim, transformer_layers, dense_units, dropout_rate)\u001b[0m\n\u001b[0;32m     30\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)(dropout_2)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Model\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39m\u001b[43minput_layer\u001b[49m, outputs\u001b[38;5;241m=\u001b[39moutput_layer)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_layer' is not defined"
     ]
    }
   ],
   "source": [
    "model = create_transformer_model(sequences,input_shape, time2vec_dim, transformer_layers, dense_units, dropout_rate)\n",
    "# Compile the Model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673fdba-1a1b-4f65-919b-6066f81c3c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81788aba-e3c5-45b8-9771-0c2b554fb54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fefa4-88ce-4485-ac82-e486b987c4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6a6f6-07e9-4ae1-b44d-8336b70cf801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e1575-5a94-4bab-b470-ecdfd91f5589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00f3e1-c74a-4ea9-ab76-f90f270695de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e70bb-2f26-48a9-918f-1cfbd1aaba7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4e51e3c6-24c2-4ae1-818c-5ff9d436f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = ['Adj_Close', 'Close', 'High', 'Low', 'Open', 'Volume', \n",
    "                 'opt_expiry', '10DaysMA', '30DaysMA', '50DaysMA']\n",
    "time_column = 'epoch_time'\n",
    "target_column = 'Next_Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "87bf57d6-f102-4961-a8e2-403f5a803794",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_times = df_train_scaled[time_column].values.reshape(-1, 1)  # Reshape epoch_time to (num_samples, 1)\n",
    "features = df_train_scaled[input_columns].values  # Other input features\n",
    "targets = df_train_scaled[target_column].values.reshape(-1, 1)  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7a7a40d7-98fa-478e-8a3c-3592b5cbb8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_input = Input(shape=(1,), name=\"epoch_time\")\n",
    "other_inputs = Input(shape=(len(input_columns),), name=\"other_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2c2ca798-bc2b-49a4-b917-eafeebfa11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time2vec = Time2Vec(kernel_size=1)(time_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "e6ee5d56-4413-4108-8763-745425c8f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_inputs = Concatenate()([time2vec, other_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "afac9b12-6349-45b3-8c87-23b19e4060d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer-like Dense Layers\n",
    "dense1 = Dense(64, activation='relu')(concat_inputs)\n",
    "dense2 = Dense(32, activation='relu')(dense1)\n",
    "# Output layer\n",
    "output = Dense(1, name='Next_Close')(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6d3ab2e5-38db-4841-a7d3-71e81488f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[time_input, other_inputs], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c4310f2e-dd2c-4629-bd45-4555cb684929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ epoch_time          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time2_vec_19        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │ epoch_time[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Time2Vec</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ other_features      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time2_vec_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ other_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ concatenate_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Next_Close (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ epoch_time          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time2_vec_19        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m4\u001b[0m │ epoch_time[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mTime2Vec\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ other_features      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ time2_vec_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ other_features[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m832\u001b[0m │ concatenate_17[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ Next_Close (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,949</span> (11.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,949\u001b[0m (11.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,949</span> (11.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,949\u001b[0m (11.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6ad94069-06c8-4a0d-b6e8-2e3f8fa5a02b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x={'epoch_time': array([[1.5807744e+09],\n       [1.5808608e+09],\n       [1.5809472e+09],\n       [1.5810336e+09],\n       [1.5812928e+09],\n       [1.5813792e+09],\n       [1.5814656e+09],\n       [1.5815520e+09],\n       [1.5816384e+09],\n       [1.5818976e+09],\n       [1.5819840e+09],\n       [1.5820704e+09],\n       [1.5821568e+09],\n       [1.5825024e+09],\n       [1.5825888e+09],\n       [1.5826752e+09],\n       [1.5827616e+09],\n       [1.5828480e+09],\n       [1.5831072e+09],\n       [1.5831936e+09],\n       [1.5832800e+09],\n       [1.5833664e+09],\n       [1.5834528e+09],\n       [1.5837120e+09],\n       [1.5838848e+09],\n       [1.5839712e+09],\n       [1.5840576e+09],\n       [1.5843168e+09],\n       [1.5844032e+09],\n       [1.5844896e+09],\n       [1.5845760e+09],\n       [1.5846624e+09],\n       [1.5849216e+09],\n       [1.5850080e+09],\n       [1.5850944e+09],\n       [1.5851808e+09],\n       [1.5852672e+09],\n       [1.5855264e+09],\n       [1.5856128e+09],\n       [1.5856992e+09],\n       [1.5858720e+09],\n       [1.5862176e+09],\n       [1.5863040e+09],\n       [1.5863904e+09],\n       [1.5867360e+09],\n       [1.5869088e+09],\n       [1.5869952e+09],\n       [1.5870816e+09],\n       [1.5873408e+09],\n       [1.5874272e+09],\n       [1.5875136e+09],\n       [1.5876000e+09],\n       [1.5876864e+09],\n       [1.5879456e+09],\n       [1.5880320e+09],\n       [1.5881184e+09],\n       [1.5882048e+09],\n       [1.5885504e+09],\n       [1.5886368e+09],\n       [1.5887232e+09],\n       [1.5888096e+09],\n       [1.5888960e+09],\n       [1.5891552e+09],\n       [1.5892416e+09],\n       [1.5893280e+09],\n       [1.5894144e+09],\n       [1.5895008e+09],\n       [1.5897600e+09],\n       [1.5898464e+09],\n       [1.5899328e+09],\n       [1.5900192e+09],\n       [1.5901056e+09],\n       [1.5904512e+09],\n       [1.5905376e+09],\n       [1.5906240e+09],\n       [1.5907104e+09],\n       [1.5909696e+09],\n       [1.5910560e+09],\n       [1.5911424e+09],\n       [1.5912288e+09],\n       [1.5913152e+09],\n       [1.5915744e+09],\n       [1.5916608e+09],\n       [1.5917472e+09],\n       [1.5918336e+09],\n       [1.5919200e+09],\n       [1.5921792e+09],\n       [1.5922656e+09],\n       [1.5923520e+09],\n       [1.5924384e+09],\n       [1.5925248e+09],\n       [1.5927840e+09],\n       [1.5928704e+09],\n       [1.5929568e+09],\n       [1.5930432e+09],\n       [1.5931296e+09],\n       [1.5933888e+09],\n       [1.5934752e+09],\n       [1.5935616e+09],\n       [1.5936480e+09],\n       [1.5937344e+09],\n       [1.5939936e+09],\n       [1.5940800e+09],\n       [1.5941664e+09],\n       [1.5942528e+09],\n       [1.5943392e+09],\n       [1.5945984e+09],\n       [1.5946848e+09],\n       [1.5947712e+09],\n       [1.5948576e+09],\n       [1.5949440e+09],\n       [1.5952032e+09],\n       [1.5952896e+09],\n       [1.5953760e+09],\n       [1.5954624e+09],\n       [1.5955488e+09],\n       [1.5958080e+09],\n       [1.5958944e+09],\n       [1.5959808e+09],\n       [1.5960672e+09],\n       [1.5961536e+09],\n       [1.5964128e+09],\n       [1.5964992e+09],\n       [1.5965856e+09],\n       [1.5966720e+09],\n       [1.5967584e+09],\n       [1.5970176e+09],\n       [1.5971040e+09],\n       [1.5971904e+09],\n       [1.5972768e+09],\n       [1.5973632e+09],\n       [1.5976224e+09],\n       [1.5977088e+09],\n       [1.5977952e+09],\n       [1.5978816e+09],\n       [1.5979680e+09],\n       [1.5982272e+09],\n       [1.5983136e+09],\n       [1.5984000e+09],\n       [1.5984864e+09],\n       [1.5985728e+09],\n       [1.5988320e+09],\n       [1.5989184e+09],\n       [1.5990048e+09],\n       [1.5990912e+09],\n       [1.5991776e+09],\n       [1.5994368e+09],\n       [1.5995232e+09],\n       [1.5996096e+09],\n       [1.5996960e+09],\n       [1.5997824e+09],\n       [1.6000416e+09],\n       [1.6001280e+09],\n       [1.6002144e+09],\n       [1.6003008e+09],\n       [1.6003872e+09],\n       [1.6006464e+09],\n       [1.6007328e+09],\n       [1.6008192e+09],\n       [1.6009056e+09],\n       [1.6009920e+09],\n       [1.6012512e+09],\n       [1.6013376e+09],\n       [1.6014240e+09],\n       [1.6015104e+09],\n       [1.6018560e+09],\n       [1.6019424e+09],\n       [1.6020288e+09],\n       [1.6021152e+09],\n       [1.6022016e+09],\n       [1.6024608e+09],\n       [1.6025472e+09],\n       [1.6026336e+09],\n       [1.6027200e+09],\n       [1.6028064e+09],\n       [1.6030656e+09],\n       [1.6031520e+09],\n       [1.6032384e+09],\n       [1.6033248e+09],\n       [1.6034112e+09],\n       [1.6036704e+09],\n       [1.6037568e+09],\n       [1.6038432e+09],\n       [1.6039296e+09],\n       [1.6040160e+09],\n       [1.6042752e+09],\n       [1.6043616e+09],\n       [1.6044480e+09],\n       [1.6045344e+09],\n       [1.6046208e+09],\n       [1.6048800e+09],\n       [1.6049664e+09],\n       [1.6050528e+09],\n       [1.6051392e+09],\n       [1.6052256e+09],\n       [1.6053120e+09],\n       [1.6055712e+09],\n       [1.6056576e+09],\n       [1.6057440e+09],\n       [1.6058304e+09],\n       [1.6060896e+09],\n       [1.6061760e+09],\n       [1.6062624e+09],\n       [1.6063488e+09],\n       [1.6064352e+09],\n       [1.6067808e+09],\n       [1.6068672e+09],\n       [1.6069536e+09],\n       [1.6070400e+09],\n       [1.6072992e+09],\n       [1.6073856e+09],\n       [1.6074720e+09],\n       [1.6075584e+09],\n       [1.6076448e+09],\n       [1.6079040e+09],\n       [1.6079904e+09],\n       [1.6080768e+09],\n       [1.6081632e+09],\n       [1.6082496e+09],\n       [1.6085088e+09],\n       [1.6085952e+09],\n       [1.6086816e+09],\n       [1.6087680e+09],\n       [1.6091136e+09],\n       [1.6092000e+09],\n       [1.6092864e+09],\n       [1.6093728e+09],\n       [1.6094592e+09],\n       [1.6097184e+09],\n       [1.6098048e+09],\n       [1.6098912e+09],\n       [1.6099776e+09],\n       [1.6100640e+09],\n       [1.6103232e+09],\n       [1.6104096e+09],\n       [1.6104960e+09],\n       [1.6105824e+09],\n       [1.6106688e+09],\n       [1.6109280e+09],\n       [1.6110144e+09],\n       [1.6111008e+09],\n       [1.6111872e+09],\n       [1.6112736e+09],\n       [1.6115328e+09],\n       [1.6117056e+09],\n       [1.6117920e+09],\n       [1.6118784e+09],\n       [1.6121376e+09],\n       [1.6122240e+09],\n       [1.6123104e+09],\n       [1.6123968e+09],\n       [1.6124832e+09],\n       [1.6127424e+09],\n       [1.6128288e+09],\n       [1.6129152e+09],\n       [1.6130016e+09],\n       [1.6130880e+09],\n       [1.6133472e+09],\n       [1.6134336e+09],\n       [1.6135200e+09],\n       [1.6136064e+09],\n       [1.6136928e+09],\n       [1.6139520e+09],\n       [1.6140384e+09],\n       [1.6141248e+09],\n       [1.6142112e+09],\n       [1.6142976e+09],\n       [1.6145568e+09],\n       [1.6146432e+09],\n       [1.6147296e+09],\n       [1.6148160e+09],\n       [1.6149024e+09],\n       [1.6151616e+09],\n       [1.6152480e+09],\n       [1.6153344e+09],\n       [1.6155072e+09],\n       [1.6157664e+09],\n       [1.6158528e+09],\n       [1.6159392e+09],\n       [1.6160256e+09],\n       [1.6161120e+09],\n       [1.6163712e+09],\n       [1.6164576e+09],\n       [1.6165440e+09],\n       [1.6166304e+09],\n       [1.6167168e+09],\n       [1.6170624e+09],\n       [1.6171488e+09],\n       [1.6172352e+09],\n       [1.6175808e+09],\n       [1.6176672e+09],\n       [1.6177536e+09],\n       [1.6178400e+09],\n       [1.6179264e+09],\n       [1.6181856e+09],\n       [1.6182720e+09],\n       [1.6184448e+09],\n       [1.6185312e+09],\n       [1.6187904e+09],\n       [1.6188768e+09],\n       [1.6190496e+09],\n       [1.6191360e+09],\n       [1.6193952e+09],\n       [1.6194816e+09],\n       [1.6195680e+09],\n       [1.6196544e+09],\n       [1.6197408e+09],\n       [1.6200000e+09],\n       [1.6200864e+09],\n       [1.6201728e+09],\n       [1.6202592e+09],\n       [1.6203456e+09],\n       [1.6206048e+09],\n       [1.6206912e+09],\n       [1.6207776e+09],\n       [1.6209504e+09],\n       [1.6212096e+09],\n       [1.6212960e+09],\n       [1.6213824e+09],\n       [1.6214688e+09],\n       [1.6215552e+09],\n       [1.6218144e+09],\n       [1.6219008e+09],\n       [1.6219872e+09],\n       [1.6220736e+09],\n       [1.6221600e+09],\n       [1.6224192e+09],\n       [1.6225056e+09],\n       [1.6225920e+09],\n       [1.6226784e+09],\n       [1.6227648e+09],\n       [1.6230240e+09],\n       [1.6231104e+09],\n       [1.6231968e+09],\n       [1.6232832e+09],\n       [1.6233696e+09],\n       [1.6236288e+09],\n       [1.6237152e+09],\n       [1.6238016e+09],\n       [1.6238880e+09],\n       [1.6239744e+09],\n       [1.6242336e+09],\n       [1.6243200e+09],\n       [1.6244064e+09],\n       [1.6244928e+09],\n       [1.6245792e+09],\n       [1.6248384e+09],\n       [1.6249248e+09],\n       [1.6250112e+09],\n       [1.6250976e+09],\n       [1.6251840e+09],\n       [1.6254432e+09],\n       [1.6255296e+09],\n       [1.6256160e+09],\n       [1.6257024e+09],\n       [1.6257888e+09],\n       [1.6260480e+09],\n       [1.6261344e+09],\n       [1.6262208e+09],\n       [1.6263072e+09],\n       [1.6263936e+09],\n       [1.6266528e+09],\n       [1.6267392e+09],\n       [1.6269120e+09],\n       [1.6269984e+09],\n       [1.6272576e+09],\n       [1.6273440e+09],\n       [1.6274304e+09],\n       [1.6275168e+09],\n       [1.6276032e+09],\n       [1.6278624e+09],\n       [1.6279488e+09],\n       [1.6280352e+09],\n       [1.6281216e+09],\n       [1.6282080e+09],\n       [1.6284672e+09],\n       [1.6285536e+09],\n       [1.6286400e+09],\n       [1.6287264e+09],\n       [1.6288128e+09],\n       [1.6290720e+09],\n       [1.6291584e+09],\n       [1.6292448e+09],\n       [1.6294176e+09],\n       [1.6296768e+09],\n       [1.6297632e+09],\n       [1.6298496e+09],\n       [1.6299360e+09],\n       [1.6300224e+09],\n       [1.6302816e+09],\n       [1.6303680e+09],\n       [1.6304544e+09],\n       [1.6305408e+09],\n       [1.6306272e+09],\n       [1.6308864e+09],\n       [1.6309728e+09],\n       [1.6310592e+09],\n       [1.6311456e+09],\n       [1.6314912e+09],\n       [1.6315776e+09],\n       [1.6316640e+09],\n       [1.6317504e+09],\n       [1.6318368e+09],\n       [1.6320960e+09],\n       [1.6321824e+09],\n       [1.6322688e+09],\n       [1.6323552e+09],\n       [1.6324416e+09],\n       [1.6327008e+09],\n       [1.6327872e+09],\n       [1.6328736e+09],\n       [1.6329600e+09],\n       [1.6330464e+09],\n       [1.6333056e+09],\n       [1.6333920e+09],\n       [1.6334784e+09],\n       [1.6335648e+09],\n       [1.6336512e+09],\n       [1.6339104e+09],\n       [1.6339968e+09],\n       [1.6340832e+09],\n       [1.6341696e+09],\n       [1.6345152e+09],\n       [1.6346016e+09],\n       [1.6346880e+09],\n       [1.6347744e+09],\n       [1.6348608e+09],\n       [1.6351200e+09],\n       [1.6352064e+09],\n       [1.6352928e+09],\n       [1.6353792e+09],\n       [1.6354656e+09],\n       [1.6357248e+09],\n       [1.6358112e+09],\n       [1.6358976e+09],\n       [1.6359840e+09],\n       [1.6363296e+09],\n       [1.6364160e+09],\n       [1.6365024e+09],\n       [1.6365888e+09],\n       [1.6366752e+09],\n       [1.6369344e+09],\n       [1.6370208e+09],\n       [1.6371072e+09],\n       [1.6371936e+09],\n       [1.6375392e+09],\n       [1.6376256e+09],\n       [1.6377120e+09],\n       [1.6377984e+09],\n       [1.6378848e+09],\n       [1.6381440e+09],\n       [1.6382304e+09],\n       [1.6383168e+09],\n       [1.6384032e+09],\n       [1.6384896e+09],\n       [1.6387488e+09],\n       [1.6388352e+09],\n       [1.6389216e+09],\n       [1.6390080e+09],\n       [1.6390944e+09],\n       [1.6393536e+09],\n       [1.6394400e+09],\n       [1.6395264e+09],\n       [1.6396128e+09],\n       [1.6396992e+09],\n       [1.6399584e+09],\n       [1.6400448e+09],\n       [1.6401312e+09],\n       [1.6402176e+09],\n       [1.6403040e+09],\n       [1.6405632e+09],\n       [1.6406496e+09],\n       [1.6407360e+09],\n       [1.6408224e+09],\n       [1.6409088e+09],\n       [1.6411680e+09],\n       [1.6412544e+09],\n       [1.6413408e+09],\n       [1.6414272e+09],\n       [1.6415136e+09],\n       [1.6417728e+09],\n       [1.6418592e+09],\n       [1.6419456e+09],\n       [1.6420320e+09],\n       [1.6421184e+09],\n       [1.6423776e+09],\n       [1.6424640e+09],\n       [1.6425504e+09],\n       [1.6426368e+09],\n       [1.6427232e+09],\n       [1.6429824e+09],\n       [1.6430688e+09],\n       [1.6432416e+09],\n       [1.6433280e+09],\n       [1.6435872e+09],\n       [1.6436736e+09],\n       [1.6437600e+09],\n       [1.6438464e+09],\n       [1.6439328e+09],\n       [1.6441920e+09],\n       [1.6442784e+09],\n       [1.6443648e+09],\n       [1.6444512e+09],\n       [1.6445376e+09],\n       [1.6447968e+09],\n       [1.6448832e+09],\n       [1.6449696e+09],\n       [1.6450560e+09],\n       [1.6451424e+09],\n       [1.6454016e+09],\n       [1.6454880e+09],\n       [1.6455744e+09],\n       [1.6456608e+09],\n       [1.6457472e+09],\n       [1.6460064e+09],\n       [1.6461792e+09],\n       [1.6462656e+09],\n       [1.6463520e+09],\n       [1.6466112e+09],\n       [1.6466976e+09],\n       [1.6467840e+09],\n       [1.6468704e+09],\n       [1.6469568e+09],\n       [1.6472160e+09],\n       [1.6473024e+09],\n       [1.6473888e+09],\n       [1.6474752e+09],\n       [1.6478208e+09],\n       [1.6479072e+09],\n       [1.6479936e+09],\n       [1.6480800e+09],\n       [1.6481664e+09],\n       [1.6484256e+09],\n       [1.6485120e+09],\n       [1.6485984e+09],\n       [1.6486848e+09],\n       [1.6487712e+09],\n       [1.6490304e+09],\n       [1.6491168e+09],\n       [1.6492032e+09],\n       [1.6492896e+09],\n       [1.6493760e+09],\n       [1.6496352e+09],\n       [1.6497216e+09],\n       [1.6498080e+09],\n       [1.6502400e+09],\n       [1.6503264e+09],\n       [1.6504128e+09],\n       [1.6504992e+09],\n       [1.6505856e+09],\n       [1.6508448e+09],\n       [1.6509312e+09],\n       [1.6510176e+09],\n       [1.6511040e+09],\n       [1.6511904e+09],\n       [1.6514496e+09],\n       [1.6516224e+09],\n       [1.6517088e+09],\n       [1.6517952e+09],\n       [1.6520544e+09],\n       [1.6521408e+09],\n       [1.6522272e+09],\n       [1.6523136e+09],\n       [1.6524000e+09],\n       [1.6526592e+09],\n       [1.6527456e+09],\n       [1.6528320e+09],\n       [1.6529184e+09],\n       [1.6530048e+09],\n       [1.6532640e+09],\n       [1.6533504e+09],\n       [1.6534368e+09],\n       [1.6535232e+09],\n       [1.6536096e+09],\n       [1.6538688e+09],\n       [1.6539552e+09],\n       [1.6540416e+09],\n       [1.6541280e+09],\n       [1.6542144e+09],\n       [1.6544736e+09],\n       [1.6545600e+09],\n       [1.6546464e+09],\n       [1.6547328e+09],\n       [1.6548192e+09],\n       [1.6550784e+09],\n       [1.6551648e+09],\n       [1.6552512e+09],\n       [1.6553376e+09],\n       [1.6554240e+09],\n       [1.6556832e+09],\n       [1.6557696e+09],\n       [1.6558560e+09],\n       [1.6559424e+09],\n       [1.6560288e+09],\n       [1.6562880e+09],\n       [1.6563744e+09],\n       [1.6564608e+09],\n       [1.6565472e+09],\n       [1.6566336e+09],\n       [1.6568928e+09],\n       [1.6569792e+09],\n       [1.6570656e+09],\n       [1.6571520e+09],\n       [1.6572384e+09],\n       [1.6574976e+09],\n       [1.6575840e+09],\n       [1.6576704e+09],\n       [1.6577568e+09],\n       [1.6578432e+09],\n       [1.6581024e+09],\n       [1.6581888e+09],\n       [1.6582752e+09],\n       [1.6583616e+09],\n       [1.6584480e+09],\n       [1.6587072e+09],\n       [1.6587936e+09],\n       [1.6588800e+09],\n       [1.6589664e+09],\n       [1.6590528e+09],\n       [1.6593120e+09],\n       [1.6593984e+09],\n       [1.6594848e+09],\n       [1.6595712e+09],\n       [1.6596576e+09],\n       [1.6599168e+09],\n       [1.6600896e+09],\n       [1.6601760e+09],\n       [1.6602624e+09],\n       [1.6606080e+09],\n       [1.6606944e+09],\n       [1.6607808e+09],\n       [1.6608672e+09],\n       [1.6611264e+09],\n       [1.6612128e+09],\n       [1.6612992e+09],\n       [1.6613856e+09],\n       [1.6614720e+09],\n       [1.6617312e+09],\n       [1.6618176e+09],\n       [1.6619904e+09],\n       [1.6620768e+09],\n       [1.6623360e+09],\n       [1.6624224e+09],\n       [1.6625088e+09],\n       [1.6625952e+09],\n       [1.6626816e+09],\n       [1.6629408e+09],\n       [1.6630272e+09],\n       [1.6631136e+09],\n       [1.6632000e+09],\n       [1.6632864e+09],\n       [1.6635456e+09],\n       [1.6636320e+09],\n       [1.6637184e+09],\n       [1.6638048e+09],\n       [1.6638912e+09],\n       [1.6641504e+09],\n       [1.6642368e+09],\n       [1.6643232e+09],\n       [1.6644096e+09],\n       [1.6644960e+09],\n       [1.6647552e+09],\n       [1.6648416e+09],\n       [1.6650144e+09],\n       [1.6651008e+09],\n       [1.6653600e+09],\n       [1.6654464e+09],\n       [1.6655328e+09],\n       [1.6656192e+09],\n       [1.6657056e+09],\n       [1.6659648e+09],\n       [1.6660512e+09],\n       [1.6661376e+09],\n       [1.6662240e+09],\n       [1.6663104e+09],\n       [1.6665696e+09],\n       [1.6666560e+09],\n       [1.6668288e+09],\n       [1.6669152e+09],\n       [1.6671744e+09],\n       [1.6672608e+09],\n       [1.6673472e+09],\n       [1.6674336e+09],\n       [1.6675200e+09],\n       [1.6677792e+09],\n       [1.6679520e+09],\n       [1.6680384e+09],\n       [1.6681248e+09],\n       [1.6683840e+09],\n       [1.6684704e+09],\n       [1.6685568e+09],\n       [1.6686432e+09],\n       [1.6687296e+09],\n       [1.6689888e+09],\n       [1.6690752e+09],\n       [1.6691616e+09],\n       [1.6692480e+09],\n       [1.6693344e+09],\n       [1.6695936e+09],\n       [1.6696800e+09],\n       [1.6697664e+09],\n       [1.6698528e+09],\n       [1.6699392e+09],\n       [1.6701984e+09],\n       [1.6702848e+09],\n       [1.6703712e+09],\n       [1.6704576e+09],\n       [1.6705440e+09],\n       [1.6708032e+09],\n       [1.6708896e+09],\n       [1.6709760e+09],\n       [1.6710624e+09],\n       [1.6711488e+09],\n       [1.6714080e+09],\n       [1.6714944e+09],\n       [1.6715808e+09],\n       [1.6716672e+09],\n       [1.6717536e+09],\n       [1.6720128e+09],\n       [1.6720992e+09],\n       [1.6721856e+09],\n       [1.6722720e+09],\n       [1.6723584e+09],\n       [1.6726176e+09],\n       [1.6727040e+09],\n       [1.6727904e+09],\n       [1.6728768e+09],\n       [1.6729632e+09],\n       [1.6732224e+09],\n       [1.6733088e+09],\n       [1.6733952e+09],\n       [1.6734816e+09],\n       [1.6735680e+09],\n       [1.6738272e+09],\n       [1.6739136e+09],\n       [1.6740000e+09],\n       [1.6740864e+09],\n       [1.6741728e+09],\n       [1.6744320e+09],\n       [1.6745184e+09],\n       [1.6746048e+09],\n       [1.6747776e+09],\n       [1.6750368e+09],\n       [1.6751232e+09],\n       [1.6752096e+09],\n       [1.6752960e+09],\n       [1.6753824e+09],\n       [1.6756416e+09],\n       [1.6757280e+09],\n       [1.6758144e+09],\n       [1.6759008e+09],\n       [1.6759872e+09],\n       [1.6762464e+09],\n       [1.6763328e+09],\n       [1.6764192e+09],\n       [1.6765056e+09],\n       [1.6765920e+09],\n       [1.6768512e+09],\n       [1.6769376e+09],\n       [1.6770240e+09],\n       [1.6771104e+09],\n       [1.6771968e+09],\n       [1.6774560e+09],\n       [1.6775424e+09],\n       [1.6776288e+09],\n       [1.6777152e+09],\n       [1.6778016e+09],\n       [1.6780608e+09],\n       [1.6782336e+09],\n       [1.6783200e+09],\n       [1.6784064e+09],\n       [1.6786656e+09],\n       [1.6787520e+09],\n       [1.6788384e+09],\n       [1.6789248e+09],\n       [1.6790112e+09],\n       [1.6792704e+09],\n       [1.6793568e+09],\n       [1.6794432e+09],\n       [1.6795296e+09],\n       [1.6796160e+09],\n       [1.6798752e+09],\n       [1.6799616e+09],\n       [1.6800480e+09],\n       [1.6802208e+09],\n       [1.6804800e+09],\n       [1.6806528e+09],\n       [1.6807392e+09],\n       [1.6810848e+09],\n       [1.6811712e+09],\n       [1.6812576e+09],\n       [1.6813440e+09],\n       [1.6816896e+09],\n       [1.6817760e+09],\n       [1.6818624e+09],\n       [1.6819488e+09],\n       [1.6820352e+09],\n       [1.6822944e+09],\n       [1.6823808e+09],\n       [1.6824672e+09],\n       [1.6825536e+09],\n       [1.6826400e+09],\n       [1.6829856e+09],\n       [1.6830720e+09],\n       [1.6831584e+09],\n       [1.6832448e+09],\n       [1.6835040e+09],\n       [1.6835904e+09],\n       [1.6836768e+09],\n       [1.6837632e+09],\n       [1.6838496e+09],\n       [1.6841088e+09],\n       [1.6841952e+09],\n       [1.6842816e+09],\n       [1.6843680e+09],\n       [1.6844544e+09],\n       [1.6847136e+09],\n       [1.6848000e+09],\n       [1.6848864e+09],\n       [1.6849728e+09],\n       [1.6850592e+09],\n       [1.6853184e+09],\n       [1.6854048e+09],\n       [1.6854912e+09],\n       [1.6855776e+09],\n       [1.6856640e+09],\n       [1.6859232e+09],\n       [1.6860096e+09],\n       [1.6860960e+09],\n       [1.6861824e+09],\n       [1.6862688e+09],\n       [1.6865280e+09],\n       [1.6866144e+09],\n       [1.6867008e+09],\n       [1.6867872e+09],\n       [1.6868736e+09],\n       [1.6871328e+09],\n       [1.6872192e+09],\n       [1.6873056e+09],\n       [1.6873920e+09],\n       [1.6874784e+09],\n       [1.6877376e+09],\n       [1.6878240e+09],\n       [1.6879104e+09],\n       [1.6880832e+09],\n       [1.6883424e+09],\n       [1.6884288e+09],\n       [1.6885152e+09],\n       [1.6886016e+09],\n       [1.6886880e+09],\n       [1.6889472e+09],\n       [1.6890336e+09],\n       [1.6891200e+09],\n       [1.6892064e+09],\n       [1.6892928e+09],\n       [1.6895520e+09],\n       [1.6896384e+09],\n       [1.6897248e+09],\n       [1.6898112e+09],\n       [1.6898976e+09],\n       [1.6901568e+09],\n       [1.6902432e+09],\n       [1.6903296e+09],\n       [1.6904160e+09],\n       [1.6905024e+09],\n       [1.6907616e+09],\n       [1.6908480e+09],\n       [1.6909344e+09],\n       [1.6910208e+09],\n       [1.6911072e+09],\n       [1.6913664e+09],\n       [1.6914528e+09],\n       [1.6915392e+09],\n       [1.6916256e+09],\n       [1.6917120e+09],\n       [1.6919712e+09],\n       [1.6921440e+09],\n       [1.6922304e+09],\n       [1.6923168e+09],\n       [1.6925760e+09],\n       [1.6926624e+09],\n       [1.6927488e+09],\n       [1.6928352e+09],\n       [1.6929216e+09],\n       [1.6931808e+09],\n       [1.6932672e+09],\n       [1.6933536e+09],\n       [1.6934400e+09],\n       [1.6935264e+09],\n       [1.6937856e+09],\n       [1.6938720e+09],\n       [1.6939584e+09],\n       [1.6940448e+09],\n       [1.6941312e+09],\n       [1.6943904e+09],\n       [1.6944768e+09],\n       [1.6945632e+09],\n       [1.6946496e+09],\n       [1.6947360e+09],\n       [1.6949952e+09],\n       [1.6951680e+09],\n       [1.6952544e+09],\n       [1.6953408e+09],\n       [1.6956000e+09],\n       [1.6956864e+09],\n       [1.6957728e+09],\n       [1.6958592e+09],\n       [1.6959456e+09],\n       [1.6962912e+09],\n       [1.6963776e+09],\n       [1.6964640e+09],\n       [1.6965504e+09],\n       [1.6968096e+09],\n       [1.6968960e+09],\n       [1.6969824e+09],\n       [1.6970688e+09],\n       [1.6971552e+09],\n       [1.6974144e+09],\n       [1.6975008e+09],\n       [1.6975872e+09],\n       [1.6976736e+09],\n       [1.6977600e+09],\n       [1.6980192e+09],\n       [1.6981920e+09],\n       [1.6982784e+09],\n       [1.6983648e+09],\n       [1.6986240e+09],\n       [1.6987104e+09],\n       [1.6987968e+09],\n       [1.6988832e+09],\n       [1.6989696e+09],\n       [1.6992288e+09],\n       [1.6993152e+09],\n       [1.6994016e+09],\n       [1.6994880e+09],\n       [1.6995744e+09],\n       [1.6998336e+09],\n       [1.7000064e+09],\n       [1.7000928e+09],\n       [1.7001792e+09],\n       [1.7004384e+09],\n       [1.7005248e+09],\n       [1.7006112e+09],\n       [1.7006976e+09],\n       [1.7007840e+09],\n       [1.7011296e+09],\n       [1.7012160e+09],\n       [1.7013024e+09],\n       [1.7013888e+09],\n       [1.7016480e+09],\n       [1.7017344e+09],\n       [1.7018208e+09],\n       [1.7019072e+09],\n       [1.7019936e+09],\n       [1.7022528e+09],\n       [1.7023392e+09],\n       [1.7024256e+09],\n       [1.7025120e+09],\n       [1.7025984e+09],\n       [1.7028576e+09],\n       [1.7029440e+09],\n       [1.7030304e+09],\n       [1.7031168e+09],\n       [1.7032032e+09],\n       [1.7035488e+09],\n       [1.7036352e+09],\n       [1.7037216e+09],\n       [1.7038080e+09]]), 'other_features': 10} (of type <class 'dict'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[304], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mother_features\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python310clone\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python310clone\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py:120\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[1;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized data type: x={'epoch_time': array([[1.5807744e+09],\n       [1.5808608e+09],\n       [1.5809472e+09],\n       [1.5810336e+09],\n       [1.5812928e+09],\n       [1.5813792e+09],\n       [1.5814656e+09],\n       [1.5815520e+09],\n       [1.5816384e+09],\n       [1.5818976e+09],\n       [1.5819840e+09],\n       [1.5820704e+09],\n       [1.5821568e+09],\n       [1.5825024e+09],\n       [1.5825888e+09],\n       [1.5826752e+09],\n       [1.5827616e+09],\n       [1.5828480e+09],\n       [1.5831072e+09],\n       [1.5831936e+09],\n       [1.5832800e+09],\n       [1.5833664e+09],\n       [1.5834528e+09],\n       [1.5837120e+09],\n       [1.5838848e+09],\n       [1.5839712e+09],\n       [1.5840576e+09],\n       [1.5843168e+09],\n       [1.5844032e+09],\n       [1.5844896e+09],\n       [1.5845760e+09],\n       [1.5846624e+09],\n       [1.5849216e+09],\n       [1.5850080e+09],\n       [1.5850944e+09],\n       [1.5851808e+09],\n       [1.5852672e+09],\n       [1.5855264e+09],\n       [1.5856128e+09],\n       [1.5856992e+09],\n       [1.5858720e+09],\n       [1.5862176e+09],\n       [1.5863040e+09],\n       [1.5863904e+09],\n       [1.5867360e+09],\n       [1.5869088e+09],\n       [1.5869952e+09],\n       [1.5870816e+09],\n       [1.5873408e+09],\n       [1.5874272e+09],\n       [1.5875136e+09],\n       [1.5876000e+09],\n       [1.5876864e+09],\n       [1.5879456e+09],\n       [1.5880320e+09],\n       [1.5881184e+09],\n       [1.5882048e+09],\n       [1.5885504e+09],\n       [1.5886368e+09],\n       [1.5887232e+09],\n       [1.5888096e+09],\n       [1.5888960e+09],\n       [1.5891552e+09],\n       [1.5892416e+09],\n       [1.5893280e+09],\n       [1.5894144e+09],\n       [1.5895008e+09],\n       [1.5897600e+09],\n       [1.5898464e+09],\n       [1.5899328e+09],\n       [1.5900192e+09],\n       [1.5901056e+09],\n       [1.5904512e+09],\n       [1.5905376e+09],\n       [1.5906240e+09],\n       [1.5907104e+09],\n       [1.5909696e+09],\n       [1.5910560e+09],\n       [1.5911424e+09],\n       [1.5912288e+09],\n       [1.5913152e+09],\n       [1.5915744e+09],\n       [1.5916608e+09],\n       [1.5917472e+09],\n       [1.5918336e+09],\n       [1.5919200e+09],\n       [1.5921792e+09],\n       [1.5922656e+09],\n       [1.5923520e+09],\n       [1.5924384e+09],\n       [1.5925248e+09],\n       [1.5927840e+09],\n       [1.5928704e+09],\n       [1.5929568e+09],\n       [1.5930432e+09],\n       [1.5931296e+09],\n       [1.5933888e+09],\n       [1.5934752e+09],\n       [1.5935616e+09],\n       [1.5936480e+09],\n       [1.5937344e+09],\n       [1.5939936e+09],\n       [1.5940800e+09],\n       [1.5941664e+09],\n       [1.5942528e+09],\n       [1.5943392e+09],\n       [1.5945984e+09],\n       [1.5946848e+09],\n       [1.5947712e+09],\n       [1.5948576e+09],\n       [1.5949440e+09],\n       [1.5952032e+09],\n       [1.5952896e+09],\n       [1.5953760e+09],\n       [1.5954624e+09],\n       [1.5955488e+09],\n       [1.5958080e+09],\n       [1.5958944e+09],\n       [1.5959808e+09],\n       [1.5960672e+09],\n       [1.5961536e+09],\n       [1.5964128e+09],\n       [1.5964992e+09],\n       [1.5965856e+09],\n       [1.5966720e+09],\n       [1.5967584e+09],\n       [1.5970176e+09],\n       [1.5971040e+09],\n       [1.5971904e+09],\n       [1.5972768e+09],\n       [1.5973632e+09],\n       [1.5976224e+09],\n       [1.5977088e+09],\n       [1.5977952e+09],\n       [1.5978816e+09],\n       [1.5979680e+09],\n       [1.5982272e+09],\n       [1.5983136e+09],\n       [1.5984000e+09],\n       [1.5984864e+09],\n       [1.5985728e+09],\n       [1.5988320e+09],\n       [1.5989184e+09],\n       [1.5990048e+09],\n       [1.5990912e+09],\n       [1.5991776e+09],\n       [1.5994368e+09],\n       [1.5995232e+09],\n       [1.5996096e+09],\n       [1.5996960e+09],\n       [1.5997824e+09],\n       [1.6000416e+09],\n       [1.6001280e+09],\n       [1.6002144e+09],\n       [1.6003008e+09],\n       [1.6003872e+09],\n       [1.6006464e+09],\n       [1.6007328e+09],\n       [1.6008192e+09],\n       [1.6009056e+09],\n       [1.6009920e+09],\n       [1.6012512e+09],\n       [1.6013376e+09],\n       [1.6014240e+09],\n       [1.6015104e+09],\n       [1.6018560e+09],\n       [1.6019424e+09],\n       [1.6020288e+09],\n       [1.6021152e+09],\n       [1.6022016e+09],\n       [1.6024608e+09],\n       [1.6025472e+09],\n       [1.6026336e+09],\n       [1.6027200e+09],\n       [1.6028064e+09],\n       [1.6030656e+09],\n       [1.6031520e+09],\n       [1.6032384e+09],\n       [1.6033248e+09],\n       [1.6034112e+09],\n       [1.6036704e+09],\n       [1.6037568e+09],\n       [1.6038432e+09],\n       [1.6039296e+09],\n       [1.6040160e+09],\n       [1.6042752e+09],\n       [1.6043616e+09],\n       [1.6044480e+09],\n       [1.6045344e+09],\n       [1.6046208e+09],\n       [1.6048800e+09],\n       [1.6049664e+09],\n       [1.6050528e+09],\n       [1.6051392e+09],\n       [1.6052256e+09],\n       [1.6053120e+09],\n       [1.6055712e+09],\n       [1.6056576e+09],\n       [1.6057440e+09],\n       [1.6058304e+09],\n       [1.6060896e+09],\n       [1.6061760e+09],\n       [1.6062624e+09],\n       [1.6063488e+09],\n       [1.6064352e+09],\n       [1.6067808e+09],\n       [1.6068672e+09],\n       [1.6069536e+09],\n       [1.6070400e+09],\n       [1.6072992e+09],\n       [1.6073856e+09],\n       [1.6074720e+09],\n       [1.6075584e+09],\n       [1.6076448e+09],\n       [1.6079040e+09],\n       [1.6079904e+09],\n       [1.6080768e+09],\n       [1.6081632e+09],\n       [1.6082496e+09],\n       [1.6085088e+09],\n       [1.6085952e+09],\n       [1.6086816e+09],\n       [1.6087680e+09],\n       [1.6091136e+09],\n       [1.6092000e+09],\n       [1.6092864e+09],\n       [1.6093728e+09],\n       [1.6094592e+09],\n       [1.6097184e+09],\n       [1.6098048e+09],\n       [1.6098912e+09],\n       [1.6099776e+09],\n       [1.6100640e+09],\n       [1.6103232e+09],\n       [1.6104096e+09],\n       [1.6104960e+09],\n       [1.6105824e+09],\n       [1.6106688e+09],\n       [1.6109280e+09],\n       [1.6110144e+09],\n       [1.6111008e+09],\n       [1.6111872e+09],\n       [1.6112736e+09],\n       [1.6115328e+09],\n       [1.6117056e+09],\n       [1.6117920e+09],\n       [1.6118784e+09],\n       [1.6121376e+09],\n       [1.6122240e+09],\n       [1.6123104e+09],\n       [1.6123968e+09],\n       [1.6124832e+09],\n       [1.6127424e+09],\n       [1.6128288e+09],\n       [1.6129152e+09],\n       [1.6130016e+09],\n       [1.6130880e+09],\n       [1.6133472e+09],\n       [1.6134336e+09],\n       [1.6135200e+09],\n       [1.6136064e+09],\n       [1.6136928e+09],\n       [1.6139520e+09],\n       [1.6140384e+09],\n       [1.6141248e+09],\n       [1.6142112e+09],\n       [1.6142976e+09],\n       [1.6145568e+09],\n       [1.6146432e+09],\n       [1.6147296e+09],\n       [1.6148160e+09],\n       [1.6149024e+09],\n       [1.6151616e+09],\n       [1.6152480e+09],\n       [1.6153344e+09],\n       [1.6155072e+09],\n       [1.6157664e+09],\n       [1.6158528e+09],\n       [1.6159392e+09],\n       [1.6160256e+09],\n       [1.6161120e+09],\n       [1.6163712e+09],\n       [1.6164576e+09],\n       [1.6165440e+09],\n       [1.6166304e+09],\n       [1.6167168e+09],\n       [1.6170624e+09],\n       [1.6171488e+09],\n       [1.6172352e+09],\n       [1.6175808e+09],\n       [1.6176672e+09],\n       [1.6177536e+09],\n       [1.6178400e+09],\n       [1.6179264e+09],\n       [1.6181856e+09],\n       [1.6182720e+09],\n       [1.6184448e+09],\n       [1.6185312e+09],\n       [1.6187904e+09],\n       [1.6188768e+09],\n       [1.6190496e+09],\n       [1.6191360e+09],\n       [1.6193952e+09],\n       [1.6194816e+09],\n       [1.6195680e+09],\n       [1.6196544e+09],\n       [1.6197408e+09],\n       [1.6200000e+09],\n       [1.6200864e+09],\n       [1.6201728e+09],\n       [1.6202592e+09],\n       [1.6203456e+09],\n       [1.6206048e+09],\n       [1.6206912e+09],\n       [1.6207776e+09],\n       [1.6209504e+09],\n       [1.6212096e+09],\n       [1.6212960e+09],\n       [1.6213824e+09],\n       [1.6214688e+09],\n       [1.6215552e+09],\n       [1.6218144e+09],\n       [1.6219008e+09],\n       [1.6219872e+09],\n       [1.6220736e+09],\n       [1.6221600e+09],\n       [1.6224192e+09],\n       [1.6225056e+09],\n       [1.6225920e+09],\n       [1.6226784e+09],\n       [1.6227648e+09],\n       [1.6230240e+09],\n       [1.6231104e+09],\n       [1.6231968e+09],\n       [1.6232832e+09],\n       [1.6233696e+09],\n       [1.6236288e+09],\n       [1.6237152e+09],\n       [1.6238016e+09],\n       [1.6238880e+09],\n       [1.6239744e+09],\n       [1.6242336e+09],\n       [1.6243200e+09],\n       [1.6244064e+09],\n       [1.6244928e+09],\n       [1.6245792e+09],\n       [1.6248384e+09],\n       [1.6249248e+09],\n       [1.6250112e+09],\n       [1.6250976e+09],\n       [1.6251840e+09],\n       [1.6254432e+09],\n       [1.6255296e+09],\n       [1.6256160e+09],\n       [1.6257024e+09],\n       [1.6257888e+09],\n       [1.6260480e+09],\n       [1.6261344e+09],\n       [1.6262208e+09],\n       [1.6263072e+09],\n       [1.6263936e+09],\n       [1.6266528e+09],\n       [1.6267392e+09],\n       [1.6269120e+09],\n       [1.6269984e+09],\n       [1.6272576e+09],\n       [1.6273440e+09],\n       [1.6274304e+09],\n       [1.6275168e+09],\n       [1.6276032e+09],\n       [1.6278624e+09],\n       [1.6279488e+09],\n       [1.6280352e+09],\n       [1.6281216e+09],\n       [1.6282080e+09],\n       [1.6284672e+09],\n       [1.6285536e+09],\n       [1.6286400e+09],\n       [1.6287264e+09],\n       [1.6288128e+09],\n       [1.6290720e+09],\n       [1.6291584e+09],\n       [1.6292448e+09],\n       [1.6294176e+09],\n       [1.6296768e+09],\n       [1.6297632e+09],\n       [1.6298496e+09],\n       [1.6299360e+09],\n       [1.6300224e+09],\n       [1.6302816e+09],\n       [1.6303680e+09],\n       [1.6304544e+09],\n       [1.6305408e+09],\n       [1.6306272e+09],\n       [1.6308864e+09],\n       [1.6309728e+09],\n       [1.6310592e+09],\n       [1.6311456e+09],\n       [1.6314912e+09],\n       [1.6315776e+09],\n       [1.6316640e+09],\n       [1.6317504e+09],\n       [1.6318368e+09],\n       [1.6320960e+09],\n       [1.6321824e+09],\n       [1.6322688e+09],\n       [1.6323552e+09],\n       [1.6324416e+09],\n       [1.6327008e+09],\n       [1.6327872e+09],\n       [1.6328736e+09],\n       [1.6329600e+09],\n       [1.6330464e+09],\n       [1.6333056e+09],\n       [1.6333920e+09],\n       [1.6334784e+09],\n       [1.6335648e+09],\n       [1.6336512e+09],\n       [1.6339104e+09],\n       [1.6339968e+09],\n       [1.6340832e+09],\n       [1.6341696e+09],\n       [1.6345152e+09],\n       [1.6346016e+09],\n       [1.6346880e+09],\n       [1.6347744e+09],\n       [1.6348608e+09],\n       [1.6351200e+09],\n       [1.6352064e+09],\n       [1.6352928e+09],\n       [1.6353792e+09],\n       [1.6354656e+09],\n       [1.6357248e+09],\n       [1.6358112e+09],\n       [1.6358976e+09],\n       [1.6359840e+09],\n       [1.6363296e+09],\n       [1.6364160e+09],\n       [1.6365024e+09],\n       [1.6365888e+09],\n       [1.6366752e+09],\n       [1.6369344e+09],\n       [1.6370208e+09],\n       [1.6371072e+09],\n       [1.6371936e+09],\n       [1.6375392e+09],\n       [1.6376256e+09],\n       [1.6377120e+09],\n       [1.6377984e+09],\n       [1.6378848e+09],\n       [1.6381440e+09],\n       [1.6382304e+09],\n       [1.6383168e+09],\n       [1.6384032e+09],\n       [1.6384896e+09],\n       [1.6387488e+09],\n       [1.6388352e+09],\n       [1.6389216e+09],\n       [1.6390080e+09],\n       [1.6390944e+09],\n       [1.6393536e+09],\n       [1.6394400e+09],\n       [1.6395264e+09],\n       [1.6396128e+09],\n       [1.6396992e+09],\n       [1.6399584e+09],\n       [1.6400448e+09],\n       [1.6401312e+09],\n       [1.6402176e+09],\n       [1.6403040e+09],\n       [1.6405632e+09],\n       [1.6406496e+09],\n       [1.6407360e+09],\n       [1.6408224e+09],\n       [1.6409088e+09],\n       [1.6411680e+09],\n       [1.6412544e+09],\n       [1.6413408e+09],\n       [1.6414272e+09],\n       [1.6415136e+09],\n       [1.6417728e+09],\n       [1.6418592e+09],\n       [1.6419456e+09],\n       [1.6420320e+09],\n       [1.6421184e+09],\n       [1.6423776e+09],\n       [1.6424640e+09],\n       [1.6425504e+09],\n       [1.6426368e+09],\n       [1.6427232e+09],\n       [1.6429824e+09],\n       [1.6430688e+09],\n       [1.6432416e+09],\n       [1.6433280e+09],\n       [1.6435872e+09],\n       [1.6436736e+09],\n       [1.6437600e+09],\n       [1.6438464e+09],\n       [1.6439328e+09],\n       [1.6441920e+09],\n       [1.6442784e+09],\n       [1.6443648e+09],\n       [1.6444512e+09],\n       [1.6445376e+09],\n       [1.6447968e+09],\n       [1.6448832e+09],\n       [1.6449696e+09],\n       [1.6450560e+09],\n       [1.6451424e+09],\n       [1.6454016e+09],\n       [1.6454880e+09],\n       [1.6455744e+09],\n       [1.6456608e+09],\n       [1.6457472e+09],\n       [1.6460064e+09],\n       [1.6461792e+09],\n       [1.6462656e+09],\n       [1.6463520e+09],\n       [1.6466112e+09],\n       [1.6466976e+09],\n       [1.6467840e+09],\n       [1.6468704e+09],\n       [1.6469568e+09],\n       [1.6472160e+09],\n       [1.6473024e+09],\n       [1.6473888e+09],\n       [1.6474752e+09],\n       [1.6478208e+09],\n       [1.6479072e+09],\n       [1.6479936e+09],\n       [1.6480800e+09],\n       [1.6481664e+09],\n       [1.6484256e+09],\n       [1.6485120e+09],\n       [1.6485984e+09],\n       [1.6486848e+09],\n       [1.6487712e+09],\n       [1.6490304e+09],\n       [1.6491168e+09],\n       [1.6492032e+09],\n       [1.6492896e+09],\n       [1.6493760e+09],\n       [1.6496352e+09],\n       [1.6497216e+09],\n       [1.6498080e+09],\n       [1.6502400e+09],\n       [1.6503264e+09],\n       [1.6504128e+09],\n       [1.6504992e+09],\n       [1.6505856e+09],\n       [1.6508448e+09],\n       [1.6509312e+09],\n       [1.6510176e+09],\n       [1.6511040e+09],\n       [1.6511904e+09],\n       [1.6514496e+09],\n       [1.6516224e+09],\n       [1.6517088e+09],\n       [1.6517952e+09],\n       [1.6520544e+09],\n       [1.6521408e+09],\n       [1.6522272e+09],\n       [1.6523136e+09],\n       [1.6524000e+09],\n       [1.6526592e+09],\n       [1.6527456e+09],\n       [1.6528320e+09],\n       [1.6529184e+09],\n       [1.6530048e+09],\n       [1.6532640e+09],\n       [1.6533504e+09],\n       [1.6534368e+09],\n       [1.6535232e+09],\n       [1.6536096e+09],\n       [1.6538688e+09],\n       [1.6539552e+09],\n       [1.6540416e+09],\n       [1.6541280e+09],\n       [1.6542144e+09],\n       [1.6544736e+09],\n       [1.6545600e+09],\n       [1.6546464e+09],\n       [1.6547328e+09],\n       [1.6548192e+09],\n       [1.6550784e+09],\n       [1.6551648e+09],\n       [1.6552512e+09],\n       [1.6553376e+09],\n       [1.6554240e+09],\n       [1.6556832e+09],\n       [1.6557696e+09],\n       [1.6558560e+09],\n       [1.6559424e+09],\n       [1.6560288e+09],\n       [1.6562880e+09],\n       [1.6563744e+09],\n       [1.6564608e+09],\n       [1.6565472e+09],\n       [1.6566336e+09],\n       [1.6568928e+09],\n       [1.6569792e+09],\n       [1.6570656e+09],\n       [1.6571520e+09],\n       [1.6572384e+09],\n       [1.6574976e+09],\n       [1.6575840e+09],\n       [1.6576704e+09],\n       [1.6577568e+09],\n       [1.6578432e+09],\n       [1.6581024e+09],\n       [1.6581888e+09],\n       [1.6582752e+09],\n       [1.6583616e+09],\n       [1.6584480e+09],\n       [1.6587072e+09],\n       [1.6587936e+09],\n       [1.6588800e+09],\n       [1.6589664e+09],\n       [1.6590528e+09],\n       [1.6593120e+09],\n       [1.6593984e+09],\n       [1.6594848e+09],\n       [1.6595712e+09],\n       [1.6596576e+09],\n       [1.6599168e+09],\n       [1.6600896e+09],\n       [1.6601760e+09],\n       [1.6602624e+09],\n       [1.6606080e+09],\n       [1.6606944e+09],\n       [1.6607808e+09],\n       [1.6608672e+09],\n       [1.6611264e+09],\n       [1.6612128e+09],\n       [1.6612992e+09],\n       [1.6613856e+09],\n       [1.6614720e+09],\n       [1.6617312e+09],\n       [1.6618176e+09],\n       [1.6619904e+09],\n       [1.6620768e+09],\n       [1.6623360e+09],\n       [1.6624224e+09],\n       [1.6625088e+09],\n       [1.6625952e+09],\n       [1.6626816e+09],\n       [1.6629408e+09],\n       [1.6630272e+09],\n       [1.6631136e+09],\n       [1.6632000e+09],\n       [1.6632864e+09],\n       [1.6635456e+09],\n       [1.6636320e+09],\n       [1.6637184e+09],\n       [1.6638048e+09],\n       [1.6638912e+09],\n       [1.6641504e+09],\n       [1.6642368e+09],\n       [1.6643232e+09],\n       [1.6644096e+09],\n       [1.6644960e+09],\n       [1.6647552e+09],\n       [1.6648416e+09],\n       [1.6650144e+09],\n       [1.6651008e+09],\n       [1.6653600e+09],\n       [1.6654464e+09],\n       [1.6655328e+09],\n       [1.6656192e+09],\n       [1.6657056e+09],\n       [1.6659648e+09],\n       [1.6660512e+09],\n       [1.6661376e+09],\n       [1.6662240e+09],\n       [1.6663104e+09],\n       [1.6665696e+09],\n       [1.6666560e+09],\n       [1.6668288e+09],\n       [1.6669152e+09],\n       [1.6671744e+09],\n       [1.6672608e+09],\n       [1.6673472e+09],\n       [1.6674336e+09],\n       [1.6675200e+09],\n       [1.6677792e+09],\n       [1.6679520e+09],\n       [1.6680384e+09],\n       [1.6681248e+09],\n       [1.6683840e+09],\n       [1.6684704e+09],\n       [1.6685568e+09],\n       [1.6686432e+09],\n       [1.6687296e+09],\n       [1.6689888e+09],\n       [1.6690752e+09],\n       [1.6691616e+09],\n       [1.6692480e+09],\n       [1.6693344e+09],\n       [1.6695936e+09],\n       [1.6696800e+09],\n       [1.6697664e+09],\n       [1.6698528e+09],\n       [1.6699392e+09],\n       [1.6701984e+09],\n       [1.6702848e+09],\n       [1.6703712e+09],\n       [1.6704576e+09],\n       [1.6705440e+09],\n       [1.6708032e+09],\n       [1.6708896e+09],\n       [1.6709760e+09],\n       [1.6710624e+09],\n       [1.6711488e+09],\n       [1.6714080e+09],\n       [1.6714944e+09],\n       [1.6715808e+09],\n       [1.6716672e+09],\n       [1.6717536e+09],\n       [1.6720128e+09],\n       [1.6720992e+09],\n       [1.6721856e+09],\n       [1.6722720e+09],\n       [1.6723584e+09],\n       [1.6726176e+09],\n       [1.6727040e+09],\n       [1.6727904e+09],\n       [1.6728768e+09],\n       [1.6729632e+09],\n       [1.6732224e+09],\n       [1.6733088e+09],\n       [1.6733952e+09],\n       [1.6734816e+09],\n       [1.6735680e+09],\n       [1.6738272e+09],\n       [1.6739136e+09],\n       [1.6740000e+09],\n       [1.6740864e+09],\n       [1.6741728e+09],\n       [1.6744320e+09],\n       [1.6745184e+09],\n       [1.6746048e+09],\n       [1.6747776e+09],\n       [1.6750368e+09],\n       [1.6751232e+09],\n       [1.6752096e+09],\n       [1.6752960e+09],\n       [1.6753824e+09],\n       [1.6756416e+09],\n       [1.6757280e+09],\n       [1.6758144e+09],\n       [1.6759008e+09],\n       [1.6759872e+09],\n       [1.6762464e+09],\n       [1.6763328e+09],\n       [1.6764192e+09],\n       [1.6765056e+09],\n       [1.6765920e+09],\n       [1.6768512e+09],\n       [1.6769376e+09],\n       [1.6770240e+09],\n       [1.6771104e+09],\n       [1.6771968e+09],\n       [1.6774560e+09],\n       [1.6775424e+09],\n       [1.6776288e+09],\n       [1.6777152e+09],\n       [1.6778016e+09],\n       [1.6780608e+09],\n       [1.6782336e+09],\n       [1.6783200e+09],\n       [1.6784064e+09],\n       [1.6786656e+09],\n       [1.6787520e+09],\n       [1.6788384e+09],\n       [1.6789248e+09],\n       [1.6790112e+09],\n       [1.6792704e+09],\n       [1.6793568e+09],\n       [1.6794432e+09],\n       [1.6795296e+09],\n       [1.6796160e+09],\n       [1.6798752e+09],\n       [1.6799616e+09],\n       [1.6800480e+09],\n       [1.6802208e+09],\n       [1.6804800e+09],\n       [1.6806528e+09],\n       [1.6807392e+09],\n       [1.6810848e+09],\n       [1.6811712e+09],\n       [1.6812576e+09],\n       [1.6813440e+09],\n       [1.6816896e+09],\n       [1.6817760e+09],\n       [1.6818624e+09],\n       [1.6819488e+09],\n       [1.6820352e+09],\n       [1.6822944e+09],\n       [1.6823808e+09],\n       [1.6824672e+09],\n       [1.6825536e+09],\n       [1.6826400e+09],\n       [1.6829856e+09],\n       [1.6830720e+09],\n       [1.6831584e+09],\n       [1.6832448e+09],\n       [1.6835040e+09],\n       [1.6835904e+09],\n       [1.6836768e+09],\n       [1.6837632e+09],\n       [1.6838496e+09],\n       [1.6841088e+09],\n       [1.6841952e+09],\n       [1.6842816e+09],\n       [1.6843680e+09],\n       [1.6844544e+09],\n       [1.6847136e+09],\n       [1.6848000e+09],\n       [1.6848864e+09],\n       [1.6849728e+09],\n       [1.6850592e+09],\n       [1.6853184e+09],\n       [1.6854048e+09],\n       [1.6854912e+09],\n       [1.6855776e+09],\n       [1.6856640e+09],\n       [1.6859232e+09],\n       [1.6860096e+09],\n       [1.6860960e+09],\n       [1.6861824e+09],\n       [1.6862688e+09],\n       [1.6865280e+09],\n       [1.6866144e+09],\n       [1.6867008e+09],\n       [1.6867872e+09],\n       [1.6868736e+09],\n       [1.6871328e+09],\n       [1.6872192e+09],\n       [1.6873056e+09],\n       [1.6873920e+09],\n       [1.6874784e+09],\n       [1.6877376e+09],\n       [1.6878240e+09],\n       [1.6879104e+09],\n       [1.6880832e+09],\n       [1.6883424e+09],\n       [1.6884288e+09],\n       [1.6885152e+09],\n       [1.6886016e+09],\n       [1.6886880e+09],\n       [1.6889472e+09],\n       [1.6890336e+09],\n       [1.6891200e+09],\n       [1.6892064e+09],\n       [1.6892928e+09],\n       [1.6895520e+09],\n       [1.6896384e+09],\n       [1.6897248e+09],\n       [1.6898112e+09],\n       [1.6898976e+09],\n       [1.6901568e+09],\n       [1.6902432e+09],\n       [1.6903296e+09],\n       [1.6904160e+09],\n       [1.6905024e+09],\n       [1.6907616e+09],\n       [1.6908480e+09],\n       [1.6909344e+09],\n       [1.6910208e+09],\n       [1.6911072e+09],\n       [1.6913664e+09],\n       [1.6914528e+09],\n       [1.6915392e+09],\n       [1.6916256e+09],\n       [1.6917120e+09],\n       [1.6919712e+09],\n       [1.6921440e+09],\n       [1.6922304e+09],\n       [1.6923168e+09],\n       [1.6925760e+09],\n       [1.6926624e+09],\n       [1.6927488e+09],\n       [1.6928352e+09],\n       [1.6929216e+09],\n       [1.6931808e+09],\n       [1.6932672e+09],\n       [1.6933536e+09],\n       [1.6934400e+09],\n       [1.6935264e+09],\n       [1.6937856e+09],\n       [1.6938720e+09],\n       [1.6939584e+09],\n       [1.6940448e+09],\n       [1.6941312e+09],\n       [1.6943904e+09],\n       [1.6944768e+09],\n       [1.6945632e+09],\n       [1.6946496e+09],\n       [1.6947360e+09],\n       [1.6949952e+09],\n       [1.6951680e+09],\n       [1.6952544e+09],\n       [1.6953408e+09],\n       [1.6956000e+09],\n       [1.6956864e+09],\n       [1.6957728e+09],\n       [1.6958592e+09],\n       [1.6959456e+09],\n       [1.6962912e+09],\n       [1.6963776e+09],\n       [1.6964640e+09],\n       [1.6965504e+09],\n       [1.6968096e+09],\n       [1.6968960e+09],\n       [1.6969824e+09],\n       [1.6970688e+09],\n       [1.6971552e+09],\n       [1.6974144e+09],\n       [1.6975008e+09],\n       [1.6975872e+09],\n       [1.6976736e+09],\n       [1.6977600e+09],\n       [1.6980192e+09],\n       [1.6981920e+09],\n       [1.6982784e+09],\n       [1.6983648e+09],\n       [1.6986240e+09],\n       [1.6987104e+09],\n       [1.6987968e+09],\n       [1.6988832e+09],\n       [1.6989696e+09],\n       [1.6992288e+09],\n       [1.6993152e+09],\n       [1.6994016e+09],\n       [1.6994880e+09],\n       [1.6995744e+09],\n       [1.6998336e+09],\n       [1.7000064e+09],\n       [1.7000928e+09],\n       [1.7001792e+09],\n       [1.7004384e+09],\n       [1.7005248e+09],\n       [1.7006112e+09],\n       [1.7006976e+09],\n       [1.7007840e+09],\n       [1.7011296e+09],\n       [1.7012160e+09],\n       [1.7013024e+09],\n       [1.7013888e+09],\n       [1.7016480e+09],\n       [1.7017344e+09],\n       [1.7018208e+09],\n       [1.7019072e+09],\n       [1.7019936e+09],\n       [1.7022528e+09],\n       [1.7023392e+09],\n       [1.7024256e+09],\n       [1.7025120e+09],\n       [1.7025984e+09],\n       [1.7028576e+09],\n       [1.7029440e+09],\n       [1.7030304e+09],\n       [1.7031168e+09],\n       [1.7032032e+09],\n       [1.7035488e+09],\n       [1.7036352e+09],\n       [1.7037216e+09],\n       [1.7038080e+09]]), 'other_features': 10} (of type <class 'dict'>)"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    {'epoch_time': epoch_times, 'other_features': features}, \n",
    "    targets, \n",
    "    epochs=100, \n",
    "    batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8094b87-8332-4362-a5da-6bbec5ad4902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b9732-15d9-4c8f-9576-4077d806f1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a6f57-1f22-445d-a445-a2385026e32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0014231-76b1-46af-a95c-40fdf1b42bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3999a5-f07c-4d92-bc21-a1fa497ee140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da4c90f1-86e6-4289-a1b2-061a48666cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m enhanced_time2vec \u001b[38;5;241m=\u001b[39m EnhancedTime2Vec(\u001b[43mfeatures\u001b[49m , features)  \u001b[38;5;66;03m# Features can be adjusted\u001b[39;00m\n\u001b[0;32m      2\u001b[0m time2vec_output_train \u001b[38;5;241m=\u001b[39m enhanced_time2vec(torch\u001b[38;5;241m.\u001b[39mtensor(train_sequences,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m      3\u001b[0m time2vec_output_val \u001b[38;5;241m=\u001b[39m enhanced_time2vec(torch\u001b[38;5;241m.\u001b[39mtensor(val_sequences,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "enhanced_time2vec = EnhancedTime2Vec(features , features)  # Features can be adjusted\n",
    "time2vec_output_train = enhanced_time2vec(torch.tensor(train_sequences,dtype=torch.float32))\n",
    "time2vec_output_val = enhanced_time2vec(torch.tensor(val_sequences,dtype=torch.float32))\n",
    "time2vec_output_test = enhanced_time2vec(torch.tensor(test_sequences,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc9730aa-bde2-4e97-aa2e-4228d251bcbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time2vec_output_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtime2vec_output_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(time2vec_output_val\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(time2vec_output_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time2vec_output_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(time2vec_output_train.shape)\n",
    "print(time2vec_output_val.shape)\n",
    "print(time2vec_output_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e06d1-00cd-4d0f-a763-6e4eba740ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0efc7883-a14e-4fdd-8165-1a289796d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vec(layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super(Time2Vec, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.weights_linear = self.add_weight(\n",
    "            name=\"weights_linear\",\n",
    "            shape=(input_shape[-1], 1),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.bias_linear = self.add_weight(\n",
    "            name=\"bias_linear\",\n",
    "            shape=(1,),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.weights_periodic = self.add_weight(\n",
    "            name=\"weights_periodic\",\n",
    "            shape=(input_shape[-1], self.output_dim - 1),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.bias_periodic = self.add_weight(\n",
    "            name=\"bias_periodic\",\n",
    "            shape=(self.output_dim - 1,),\n",
    "            initializer=\"uniform\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        linear_part = tf.matmul(inputs, self.weights_linear) + self.bias_linear\n",
    "        periodic_part = tf.sin(\n",
    "            tf.matmul(inputs, self.weights_periodic) + self.bias_periodic\n",
    "        )\n",
    "        return tf.concat([linear_part, periodic_part], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "52975f3b-2cf4-457c-9776-7ebe1cfe1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, num_heads, key_dim, ff_dim, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation='relu'),\n",
    "            Dense(key_dim)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout)\n",
    "        self.dropout2 = Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        print(f\"Input shape before attention: {inputs.shape}\")\n",
    "        attn_output = self.att(query=inputs, value=inputs, key=inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        print(f\"Attention output shape: {attn_output.shape}\")\n",
    "        out1 = self.layernorm1(inputs + attn_output)  # Add & Normalize\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "232b128e-62a6-419d-8735-7fb35ab6c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformer_model(input_shape, time2vec_dim, transformer_layers, dense_units, dropout_rate):\n",
    "    # Input Layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Time2Vec Layer\n",
    "    time2vec_layer = Time2Vec(output_dim=time2vec_dim)(input_layer)\n",
    "\n",
    "    # Concatenate original input with Time2Vec output\n",
    "    concatenated = Concatenate()([input_layer, time2vec_layer])\n",
    "\n",
    "    # Transformer Encoder Layers\n",
    "    transformer_output = concatenated\n",
    "    for _ in range(transformer_layers):\n",
    "        transformer_layer = TransformerEncoder(\n",
    "           num_heads=num_heads, key_dim=key_dim, ff_dim=ff_dim, dropout=dropout_rate\n",
    "        )\n",
    "        transformer_output = transformer_layer(transformer_output)\n",
    "\n",
    "    # Global Average Pooling\n",
    "    pooled_output = GlobalAveragePooling1D()(transformer_output)\n",
    "\n",
    "    # Dense Layers with Dropout\n",
    "    dense_1 = Dense(dense_units, activation=\"relu\")(pooled_output)\n",
    "    dropout_1 = Dropout(dropout_rate)(dense_1)\n",
    "    dense_2 = Dense(dense_units, activation=\"relu\")(dropout_1)\n",
    "    dropout_2 = Dropout(dropout_rate)(dense_2)\n",
    "\n",
    "    # Output Layer\n",
    "    output_layer = Dense(1, activation=\"linear\")(dropout_2)\n",
    "\n",
    "    # Model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b5ced8be-d70f-4b71-b7c2-87225dc32a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (8, 12)  # Update this based on your dataset\n",
    "transformer_layers = 3\n",
    "time2vec_dim = 10\n",
    "dense_units = 64\n",
    "dropout_rate = 0.2\n",
    "num_heads = 4\n",
    "key_dim = 22\n",
    "ff_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "23e3bac1-22a4-4926-9668-f5b13498f3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape before attention: (None, 8, 22)\n",
      "Attention output shape: (None, 8, 22)\n",
      "Input shape before attention: (None, 8, 22)\n",
      "Attention output shape: (None, 8, 22)\n",
      "Input shape before attention: (None, 8, 22)\n",
      "Attention output shape: (None, 8, 22)\n",
      "Input shape before attention: (None, 8, 22)\n",
      "Attention output shape: (None, 8, 22)\n",
      "Input shape before attention: (None, 8, 22)\n",
      "Attention output shape: (None, 8, 22)\n",
      "Input shape before attention: (None, 8, 22)\n",
      "Attention output shape: (None, 8, 22)\n"
     ]
    }
   ],
   "source": [
    "model = create_transformer_model(input_shape, time2vec_dim, transformer_layers, dense_units, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "27f21f91-645a-4c2a-a33a-8f0e33130568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_20      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time2_vec_16        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ input_layer_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Time2Vec</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ time2_vec_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,900</span> │ concatenate_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,900</span> │ transformer_enco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,900</span> │ transformer_enco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_enco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,472</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_40[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_20      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m12\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time2_vec_16        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m130\u001b[0m │ input_layer_20[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mTime2Vec\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ input_layer_20[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ time2_vec_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │     \u001b[38;5;34m13,900\u001b[0m │ concatenate_16[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │     \u001b[38;5;34m13,900\u001b[0m │ transformer_enco… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │     \u001b[38;5;34m13,900\u001b[0m │ transformer_enco… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ transformer_enco… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,472\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_39          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ dropout_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_40[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,527</span> (185.65 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,527\u001b[0m (185.65 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,527</span> (185.65 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,527\u001b[0m (185.65 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the Model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "204ebefa-9396-4863-ba4f-5c377cf5b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 0.0067 - val_mae: 0.0747\n",
      "Epoch 2/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0151 - val_mae: 0.1179\n",
      "Epoch 3/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0253 - val_mae: 0.1553\n",
      "Epoch 4/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0147 - val_mae: 0.1165\n",
      "Epoch 5/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0082 - val_mae: 0.0837\n",
      "Epoch 6/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 0.0224 - val_mae: 0.1455\n",
      "Epoch 7/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0148 - val_mae: 0.1166\n",
      "Epoch 8/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0157 - val_mae: 0.1204\n",
      "Epoch 9/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - mae: 0.0283 - val_loss: 0.0075 - val_mae: 0.0794\n",
      "Epoch 10/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 0.0157 - val_mae: 0.1205\n",
      "Epoch 11/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0243 - val_mae: 0.1523\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "# Assuming you have train_data, val_data, and test_data already prepared\n",
    "# Replace train_X, train_y, val_X, val_y with your data\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',          # The metric to monitor (could also be 'val_accuracy')\n",
    "    patience=10,                 # Number of epochs with no improvement to wait before stopping\n",
    "    verbose=1,                   # To print messages when stopping early\n",
    "    restore_best_weights=True    # Restore the best weights once training is stopped\n",
    ")\n",
    "\n",
    "history = model.fit(train_sequences,train_targets , validation_data=(val_sequences, val_targets), epochs=150, batch_size=None, callbacks=[early_stopping])\n",
    "\n",
    "# Prediction\n",
    "predictions = model.predict(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "397ab82a-6bff-483f-b41c-2fdcc3c9abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vals = target_scaler.inverse_transform(predictions.reshape(-1,1))\n",
    "\n",
    "pred_new=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "255ed0ac-387e-472d-b5cf-3e96f3724f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3602.7216796875,\n",
       " 3578.542724609375,\n",
       " 3784.390625,\n",
       " 3769.92822265625,\n",
       " 3698.87060546875,\n",
       " 3688.14501953125,\n",
       " 3643.187744140625,\n",
       " 3624.599609375,\n",
       " 3622.995849609375,\n",
       " 3583.226318359375,\n",
       " 3610.47509765625,\n",
       " 3602.1708984375,\n",
       " 3643.98876953125,\n",
       " 3670.82421875,\n",
       " 3690.790771484375,\n",
       " 3671.36962890625,\n",
       " 3678.847900390625,\n",
       " 3679.55078125,\n",
       " 3674.0859375,\n",
       " 3667.71923828125,\n",
       " 3666.971435546875,\n",
       " 3647.97119140625,\n",
       " 3664.310302734375,\n",
       " 3675.1591796875,\n",
       " 3652.282470703125,\n",
       " 3637.224853515625,\n",
       " 3622.930908203125,\n",
       " 3560.21826171875,\n",
       " 3580.907470703125,\n",
       " 3647.89501953125,\n",
       " 3681.94775390625,\n",
       " 3723.316650390625,\n",
       " 3733.94287109375,\n",
       " 3763.587158203125,\n",
       " 3748.053955078125,\n",
       " 3758.122802734375,\n",
       " 3705.71044921875,\n",
       " 3658.901123046875,\n",
       " 3634.68359375,\n",
       " 3537.253173828125,\n",
       " 3534.752197265625,\n",
       " 3487.844482421875,\n",
       " 3489.142822265625,\n",
       " 3548.75732421875,\n",
       " 3609.8447265625,\n",
       " 3564.369140625,\n",
       " 3558.255126953125,\n",
       " 3609.035400390625,\n",
       " 3589.55810546875,\n",
       " 3601.337158203125,\n",
       " 3642.072509765625,\n",
       " 3670.28955078125,\n",
       " 3664.9287109375,\n",
       " 3711.910400390625,\n",
       " 3712.3037109375,\n",
       " 3705.558349609375,\n",
       " 3708.6201171875,\n",
       " 3696.522216796875,\n",
       " 3654.71533203125,\n",
       " 3605.75146484375,\n",
       " 3614.355224609375,\n",
       " 3563.569091796875,\n",
       " 3519.0302734375,\n",
       " 3561.330322265625,\n",
       " 3554.5,\n",
       " 3604.40234375,\n",
       " 3645.779541015625,\n",
       " 3682.212158203125,\n",
       " 3666.546142578125,\n",
       " 3711.84423828125,\n",
       " 3737.095703125,\n",
       " 3721.783935546875,\n",
       " 3729.927978515625,\n",
       " 3730.611328125,\n",
       " 3698.904541015625,\n",
       " 3681.888916015625,\n",
       " 3673.244384765625,\n",
       " 3544.258056640625,\n",
       " 3527.29150390625,\n",
       " 3489.35107421875,\n",
       " 3495.326904296875,\n",
       " 3411.307861328125,\n",
       " 3408.60107421875,\n",
       " 3426.5439453125,\n",
       " 3473.45166015625,\n",
       " 3541.75146484375,\n",
       " 3536.065185546875,\n",
       " 3563.62255859375,\n",
       " 3539.99951171875,\n",
       " 3568.97998046875,\n",
       " 3534.23388671875,\n",
       " 3478.046142578125,\n",
       " 3418.5,\n",
       " 3346.115966796875,\n",
       " 3351.629638671875,\n",
       " 3341.27392578125,\n",
       " 3352.932861328125,\n",
       " 3490.091796875,\n",
       " 3539.017333984375,\n",
       " 3541.858154296875,\n",
       " 3582.761474609375,\n",
       " 3678.96142578125,\n",
       " 3683.508056640625,\n",
       " 3684.620361328125,\n",
       " 3658.643310546875,\n",
       " 3517.0107421875,\n",
       " 3495.70947265625,\n",
       " 3513.80224609375,\n",
       " 3500.5390625,\n",
       " 3432.29345703125]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8c99d856-558e-47f0-be0b-d90c03d11dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 1), dtype=float64)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(pred_new).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "0fceba43-953a-486f-bd19-3ce946492f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3302.7217],\n",
       "       [3278.5427],\n",
       "       [3484.3906],\n",
       "       [3469.9282],\n",
       "       [3398.8706],\n",
       "       [3388.145 ],\n",
       "       [3343.1877],\n",
       "       [3324.5996],\n",
       "       [3322.9958],\n",
       "       [3283.2263],\n",
       "       [3310.475 ],\n",
       "       [3302.171 ],\n",
       "       [3343.9888],\n",
       "       [3370.8242],\n",
       "       [3390.7908],\n",
       "       [3371.3696],\n",
       "       [3378.848 ],\n",
       "       [3379.5508],\n",
       "       [3374.086 ],\n",
       "       [3367.7192],\n",
       "       [3366.9714],\n",
       "       [3347.9712],\n",
       "       [3364.3103],\n",
       "       [3375.1592],\n",
       "       [3352.2825],\n",
       "       [3337.2249],\n",
       "       [3322.931 ],\n",
       "       [3260.2183],\n",
       "       [3280.9075],\n",
       "       [3347.895 ],\n",
       "       [3381.9478],\n",
       "       [3423.3167],\n",
       "       [3433.9429],\n",
       "       [3463.5872],\n",
       "       [3448.054 ],\n",
       "       [3458.1228],\n",
       "       [3405.7104],\n",
       "       [3358.9011],\n",
       "       [3334.6836],\n",
       "       [3237.2532],\n",
       "       [3234.7522],\n",
       "       [3187.8445],\n",
       "       [3189.1428],\n",
       "       [3248.7573],\n",
       "       [3309.8447],\n",
       "       [3264.3691],\n",
       "       [3258.2551],\n",
       "       [3309.0354],\n",
       "       [3289.558 ],\n",
       "       [3301.3372],\n",
       "       [3342.0725],\n",
       "       [3370.2896],\n",
       "       [3364.9287],\n",
       "       [3411.9104],\n",
       "       [3412.3037],\n",
       "       [3405.5583],\n",
       "       [3408.62  ],\n",
       "       [3396.5222],\n",
       "       [3354.7153],\n",
       "       [3305.7515],\n",
       "       [3314.3552],\n",
       "       [3263.569 ],\n",
       "       [3219.0303],\n",
       "       [3261.3303],\n",
       "       [3254.5   ],\n",
       "       [3304.4023],\n",
       "       [3345.7795],\n",
       "       [3382.2122],\n",
       "       [3366.5461],\n",
       "       [3411.8442],\n",
       "       [3437.0957],\n",
       "       [3421.784 ],\n",
       "       [3429.928 ],\n",
       "       [3430.6113],\n",
       "       [3398.9045],\n",
       "       [3381.889 ],\n",
       "       [3373.2444],\n",
       "       [3244.258 ],\n",
       "       [3227.2915],\n",
       "       [3189.351 ],\n",
       "       [3195.327 ],\n",
       "       [3111.3079],\n",
       "       [3108.601 ],\n",
       "       [3126.544 ],\n",
       "       [3173.4517],\n",
       "       [3241.7515],\n",
       "       [3236.0652],\n",
       "       [3263.6226],\n",
       "       [3239.9995],\n",
       "       [3268.98  ],\n",
       "       [3234.234 ],\n",
       "       [3178.0461],\n",
       "       [3118.5   ],\n",
       "       [3046.116 ],\n",
       "       [3051.6296],\n",
       "       [3041.274 ],\n",
       "       [3052.9329],\n",
       "       [3190.0918],\n",
       "       [3239.0173],\n",
       "       [3241.8582],\n",
       "       [3282.7615],\n",
       "       [3378.9614],\n",
       "       [3383.508 ],\n",
       "       [3384.6204],\n",
       "       [3358.6433],\n",
       "       [3217.0107],\n",
       "       [3195.7095],\n",
       "       [3213.8022],\n",
       "       [3200.539 ],\n",
       "       [3132.2935]], dtype=float32)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d56169a6-f51c-4056-8fd3-b0dd1d1ae07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in predicted_vals:\n",
    "    pred_new.append(a[0]+300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ec2cac86-fe0f-41af-b1ae-d05cb4f2274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3687.80004883],\n",
       "       [3689.19995117],\n",
       "       [3589.94995117],\n",
       "       [3594.44995117],\n",
       "       [3535.        ],\n",
       "       [3531.60009766],\n",
       "       [3587.80004883],\n",
       "       [3602.94995117],\n",
       "       [3564.39990234],\n",
       "       [3548.44995117],\n",
       "       [3526.55004883],\n",
       "       [3626.5       ],\n",
       "       [3614.35009766],\n",
       "       [3573.30004883],\n",
       "       [3627.14990234],\n",
       "       [3632.        ],\n",
       "       [3666.10009766],\n",
       "       [3650.05004883],\n",
       "       [3621.10009766],\n",
       "       [3649.35009766],\n",
       "       [3651.60009766],\n",
       "       [3636.55004883],\n",
       "       [3656.19995117],\n",
       "       [3618.5       ],\n",
       "       [3651.44995117],\n",
       "       [3538.05004883],\n",
       "       [3519.44995117],\n",
       "       [3619.14990234],\n",
       "       [3679.89990234],\n",
       "       [3774.94995117],\n",
       "       [3784.64990234],\n",
       "       [3815.        ],\n",
       "       [3779.30004883],\n",
       "       [3665.69995117],\n",
       "       [3528.        ],\n",
       "       [3576.19995117],\n",
       "       [3638.25      ],\n",
       "       [3553.55004883],\n",
       "       [3592.05004883],\n",
       "       [3571.94995117],\n",
       "       [3551.80004883],\n",
       "       [3545.19995117],\n",
       "       [3568.35009766],\n",
       "       [3555.05004883],\n",
       "       [3572.69995117],\n",
       "       [3596.05004883],\n",
       "       [3606.5       ],\n",
       "       [3598.55004883],\n",
       "       [3641.89990234],\n",
       "       [3702.69995117],\n",
       "       [3689.05004883],\n",
       "       [3683.44995117],\n",
       "       [3704.64990234],\n",
       "       [3683.10009766],\n",
       "       [3690.14990234],\n",
       "       [3650.80004883],\n",
       "       [3624.14990234],\n",
       "       [3574.75      ],\n",
       "       [3578.30004883],\n",
       "       [3596.14990234],\n",
       "       [3536.94995117],\n",
       "       [3622.        ],\n",
       "       [3613.        ],\n",
       "       [3662.25      ],\n",
       "       [3695.19995117],\n",
       "       [3730.44995117],\n",
       "       [3683.69995117],\n",
       "       [3793.89990234],\n",
       "       [3787.69995117],\n",
       "       [3791.60009766],\n",
       "       [3793.85009766],\n",
       "       [3762.14990234],\n",
       "       [3705.64990234],\n",
       "       [3675.55004883],\n",
       "       [3653.5       ],\n",
       "       [3497.64990234],\n",
       "       [3493.94995117],\n",
       "       [3468.35009766],\n",
       "       [3532.39990234],\n",
       "       [3487.10009766],\n",
       "       [3460.35009766],\n",
       "       [3482.55004883],\n",
       "       [3555.05004883],\n",
       "       [3551.89990234],\n",
       "       [3532.60009766],\n",
       "       [3570.30004883],\n",
       "       [3577.80004883],\n",
       "       [3585.60009766],\n",
       "       [3511.89990234],\n",
       "       [3455.39990234],\n",
       "       [3442.64990234],\n",
       "       [3326.39990234],\n",
       "       [3340.80004883],\n",
       "       [3380.89990234],\n",
       "       [3408.35009766],\n",
       "       [3622.30004883],\n",
       "       [3626.35009766],\n",
       "       [3574.44995117],\n",
       "       [3574.80004883],\n",
       "       [3645.44995117],\n",
       "       [3646.55004883],\n",
       "       [3660.30004883],\n",
       "       [3628.85009766],\n",
       "       [3591.35009766],\n",
       "       [3547.94995117],\n",
       "       [3526.25      ],\n",
       "       [3542.14990234],\n",
       "       [3505.89990234],\n",
       "       [3483.5       ],\n",
       "       [3603.5       ]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_scaler.inverse_transform(test_targets.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "92aa6e6a-14a9-4876-90ff-110a31d072ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(target_scaler.inverse_transform(test_targets.reshape(-1,1)), label='Actual close price')\n",
    "plt.plot(np.array(pred_new).reshape(-1,1), label='Predicted close price')\n",
    "\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "90678e43-1882-4d36-997f-5cc4fecd1364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_targets, label='Actual close price')\n",
    "plt.plot(pred_new, label='Predicted close price')\n",
    "\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1302662-765d-4bd2-b24f-bd8b241ecd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8745a7e6-4e8b-4c3d-ad84-4771f31e9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_timesteps(array, timesteps=100):\n",
    "    samples, features = array.shape\n",
    "    output = np.zeros((samples, timesteps, features))\n",
    "\n",
    "    for i in range(samples):\n",
    "        start_idx = max(0, i - timesteps + 1)\n",
    "        end_idx = i + 1\n",
    "        window = array[start_idx:end_idx]\n",
    "        output[i, -len(window):] = window\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c3c71ee-e485-4da9-abc2-7fab46e58c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(973, 100, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(215, 100, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps=100\n",
    "X_train = convert_to_timesteps(X_train_scaled, timesteps=timesteps)\n",
    "print(X_train.shape)\n",
    "\n",
    "X_val = convert_to_timesteps(X_val_scaled, timesteps=timesteps)\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38957c8a-811e-4ea6-bb87-00ebe2b1b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = target_scaler.fit_transform(df_train[\"Next_Close\"].values.reshape(-1, 1))\n",
    "y_val=target_scaler.fit_transform(df_val[\"Next_Close\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a68a6aa9-72e3-4bd6-bfea-c58e8bfd9aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#timesteps = 1 \n",
    "#X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], timesteps, X_train_scaled.shape[1]))\n",
    "#X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], timesteps, X_test_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b011320-f670-46df-beb6-f3d660b7341e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(973, 100, 10)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10eabb7-4153-411e-95ff-92a12a2b6ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "322573b5-a4b5-4b11-a2da-204f62928619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter Value is :: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divay Nagpal\\anaconda3\\envs\\python310new1\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6144</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m6,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6144\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> (25.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,528\u001b[0m (25.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,528</span> (25.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,528\u001b[0m (25.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "mse :  4983599.881400151\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_vals=[128]\n",
    "# For 1 layer\n",
    "for filter_val in filter_vals:\n",
    "    print(\"Filter Value is ::\", filter_val)\n",
    "    cnn_model = models.Sequential([\n",
    "    Conv1D(filters=filter_val, kernel_size = 5, activation = 'relu', input_shape = (timesteps, X_train.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    ])\n",
    "    cnn_model.summary()\n",
    "    cnn_features = cnn_model.predict(X_train)\n",
    "    xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "    xgb_model.fit(cnn_features, y_train)\n",
    "    predictions = xgb_model.predict(cnn_model.predict(X_val))\n",
    "    mse = mean_squared_error(target_scaler.inverse_transform(y_val), target_scaler.inverse_transform(predictions.reshape(-1,1)))\n",
    "    print(\"mse : \",mse)\n",
    "    \n",
    "    plt.plot(target_scaler.inverse_transform(y_val), label='Actual close price')\n",
    "    plt.plot(target_scaler.inverse_transform(predictions.reshape(-1,1)), label='Predicted close price')\n",
    "    \n",
    "    plt.title('Actual vs Predicted Prices')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9478e8-af6f-4dc6-8b0f-4eb7f40888ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a735ec-5d1d-4f68-a862-0a84cd2e027d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
